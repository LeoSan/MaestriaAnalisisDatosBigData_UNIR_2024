# Tema 1. Introducción a las tecnologías big data

## 1.2. La sociedad interconectada: la era del cliente
---

## La Sociedad Interconectada: La Era del Cliente y el Auge de Big Data

Imagina que vivimos en un mundo donde casi todo lo que hacemos, decimos o compramos deja una huella digital. Esa huella, que son **datos**, se ha vuelto increíblemente masiva en los últimos años. De hecho, el 90% de toda la información que existe hoy se ha creado ¡solo en los últimos dos años!

¿Por qué es esto importante? Porque esta explosión de datos es la razón principal por la que surgieron las **tecnologías Big Data**. Estas tecnologías son las herramientas que nos permiten manejar, procesar y entender tanta información.

### Tipos de Datos y Sus Fuentes

No todos los datos son iguales, y entender su origen nos ayuda a comprender mejor el Big Data:

* **Datos no estructurados (80%):** Son como una conversación casual, no tienen un formato fijo. Piensa en el texto de un correo electrónico, los comentarios en redes sociales, fotos, audios o videos. La mayoría de estos datos son generados por personas.
    * **Ejemplo:** Cuando publicas una foto en Instagram con un pie de foto y varios hashtags, estás generando datos no estructurados.
* **Datos estructurados (20%):** Son como una tabla con filas y columnas, tienen un formato organizado. Son generados principalmente por máquinas y están diseñados para ser procesados por otras máquinas.
    * **Ejemplo:** La información que registra un sensor de temperatura en una fábrica (fecha, hora, lectura de temperatura) es un dato estructurado.

---

### ¿Cómo se Generan Tantos Datos Hoy en Día?

Hay tres situaciones principales que producen esta avalancha de datos:

1.  **Interacción entre humanos a través de un sistema informático:** Cuando las personas usan plataformas para comunicarse entre sí.
    * **Ejemplo práctico:** Cada vez que envías un mensaje en WhatsApp, participas en un foro online o publicas un tuit, estás generando datos. Estos datos suelen ser **no estructurados** (el texto del mensaje, los emojis, etc.).
2.  **Interacción entre un humano y una máquina:** Cuando una persona usa un servicio digital y la máquina registra su actividad.
    * **Ejemplo práctico:** Cuando navegas por Amazon y buscas un producto, el sitio web registra tus clics, las páginas que visitas y los productos que ves. Si realizas una compra, toda esa transacción también queda registrada. Estos datos suelen ser **estructurados o semiestructurados** (los registros de tu navegación, el detalle de tu compra). Las empresas usan esto para entender tu comportamiento y ofrecerte cosas que te interesen.
3.  **Interacción entre máquinas:** Cuando diferentes dispositivos o sistemas se comunican y comparten información entre sí.
    * **Ejemplo práctico:** En una ciudad inteligente, los sensores de tráfico recopilan datos sobre el flujo de coches y los envían a un sistema central para optimizar los semáforos. O en una pulsera inteligente, esta registra tus pasos, ritmo cardíaco y los envía a tu teléfono. Estos datos son casi siempre **estructurados**, ya que las máquinas están programadas para intercambiar información de una manera específica.

---

### La Transformación Digital: De lo Físico a lo Digital

El texto menciona ejemplos muy interesantes que demuestran lo mucho que ha cambiado el mundo gracias a los datos:

* **Uber** no tiene coches, pero transporta a millones.
* **Airbnb** no tiene hoteles, pero ofrece millones de habitaciones.
* **Spotify** no tiene estudios de grabación, pero vende música.
* **Netflix** no tiene estudios de cine, pero es un gigante del entretenimiento.

¿Qué tienen en común todas estas empresas? Que su valor principal no está en activos físicos, sino en cómo **recolectan, analizan y utilizan los datos** para conectar a personas con servicios.

Cada vez interactuamos más con las empresas de forma digital (compras online, banca móvil, redes sociales). Todas estas interacciones generan datos valiosísimos que permiten a las empresas saber qué queremos y cómo nos comportamos.

---

### El Objetivo de la Transformación Digital Impulsada por Datos

Las empresas tradicionales se están dando cuenta de que necesitan adaptarse a esta "era del cliente" impulsada por los datos. La **transformación digital** busca cerrar la brecha con los gigantes digitales y tiene tres objetivos clave:

1.  **Enfocarse en el cliente:** Poner al cliente en el centro de todo. Esto significa entenderlo a fondo, personalizar su experiencia y mejorar sus interacciones con la empresa. Para lograrlo, es fundamental recolectar y analizar grandes cantidades de datos sobre su comportamiento.
    * **Ejemplo:** Una tienda de ropa online usa tus datos de compra y navegación para recomendarte prendas que te gusten, enviarte ofertas personalizadas o recordarte artículos que dejaste en el carrito.
2.  **Enfocarse en canales digitales (especialmente móviles):** Reconocer que la mayoría de las interacciones y la generación de datos ocurren a través de dispositivos digitales, en particular los teléfonos móviles.
    * **Ejemplo:** Desarrollar aplicaciones móviles intuitivas para que los clientes puedan realizar todas sus gestiones bancarias desde su celular, generando así más datos sobre sus preferencias y hábitos.
3.  **Decisiones guiadas por los datos (Data-Driven):** Dejar de tomar decisiones basadas en la intuición y empezar a basarlas en lo que los datos muestran. Aquí es donde entra la **ciencia de datos (Big Data Science)**, que nos da las herramientas para analizar esos datos y obtener conocimientos valiosos.
    * **Ejemplo:** Una cadena de supermercados analiza los datos de venta para decidir qué productos promocionar en cada tienda, cuándo reponer el inventario o incluso cómo organizar los pasillos para maximizar las ventas.

---

### Puntos Clave para Recordar y Aplicar:

* **El volumen de datos está explotando:** El 90% de la información actual se creó en los últimos dos años, impulsando la necesidad de Big Data.
* **Tipos de datos:**
    * **No estructurados (80%):** Generados por humanos (texto, imágenes, audio). Piensa en contenido de redes sociales.
    * **Estructurados (20%):** Generados por máquinas (sensores, logs). Piensa en registros organizados.
* **Fuentes de datos:** Interacciones entre humanos, entre humanos y máquinas, y entre máquinas.
* **Las empresas digitales son un ejemplo:** Uber, Airbnb, Spotify, Netflix demuestran que el valor hoy está en el **uso estratégico de los datos**, no solo en activos físicos.
* **Transformación Digital:**
    * **Objetivo principal:** Cerrar la brecha entre empresas tradicionales y digitales.
    * **Tres pilares:** Centrarse en el **cliente** (personalizar experiencia), en los **canales digitales** (móviles) y tomar **decisiones basadas en datos** (Data-Driven).

---


## 1.3. Definición de las tecnologías big data

Hasta hace relativamente poco tiempo, las tecnologías que teníamos no eran suficientes para manejar la enorme cantidad de datos que se empezaron a generar en la sociedad interconectada. ¿Por qué? Porque estos nuevos datos tenían características especiales que las herramientas tradicionales no podían procesar.

Estas características son las famosas **tres "V" del Big Data**:

* **Volumen:** Imagina montañas y montañas de datos. Las tecnologías tradicionales simplemente no podían almacenar ni procesar cantidades tan gigantescas.
    * **Ejemplo:** Los miles de millones de transacciones de tarjetas de crédito que ocurren en el mundo cada día. Una base de datos normal colapsaría al intentar manejarlos todos a la vez.
* **Velocidad:** Los datos no solo son muchos, sino que llegan rapidísimo y de forma continua. Piensa en información que llega "en tiempo real" y necesita ser procesada al instante.
    * **Ejemplo:** Los datos de navegación de millones de usuarios en un sitio web, que se actualizan segundo a segundo, o la información que recibe un coche autónomo de sus sensores para tomar decisiones inmediatas.
* **Variedad:** Los datos provienen de muchísimas fuentes diferentes y en formatos muy distintos. Pueden ser datos bien organizados (estructurados) o completamente desorganizados (no estructurados), como textos, imágenes, videos, audios, etc. Necesitamos poder manejarlos y combinarlos.
    * **Ejemplo:** Una empresa quiere analizar no solo las ventas de sus productos (datos estructurados de su base de datos), sino también los comentarios que sus clientes dejan en redes sociales (texto no estructurado) y las imágenes que suben usando sus productos.

---

### ¿Cuándo un Proyecto es "Big Data"?

Un proyecto se considera **Big Data** cuando implica alguna de estas tres "V". Sin embargo, una definición más precisa es:

Un proyecto es Big Data cuando la forma más rápida, eficiente y sencilla de resolverlo implica **usar tecnologías Big Data** porque las herramientas tradicionales no son capaces de afrontar el volumen, la velocidad o la variedad de los datos involucrados.

En resumen, podemos definir **Big Data** como:

Un **conjunto de tecnologías y arquitecturas** diseñadas para **almacenar, mover, acceder y procesar (incluyendo analizar)** datos que antes eran muy difíciles o imposibles de manejar con las tecnologías informáticas convencionales.

---

### ¿Por qué las Tecnologías Tradicionales se Quedan Cortas?

Las causas de esta incapacidad son precisamente las características de los datos:

* **Cantidades ingentes de datos:** Volúmenes de información que eran inimaginables hace unos años.
* **Datos de fuentes diversas y heterogéneas:** Información desordenada, como documentos, imágenes o sonido, que, a pesar de no estar en un formato fácil, necesitamos almacenar y consultar. Esto llevó al desarrollo de bases de datos **NoSQL** (Not Only SQL), que son más flexibles para manejar datos no estructurados.
* **Datos dinámicos (streams):** Información que llega y se procesa continuamente, a medida que se genera.

---

### Big Data NO es lo Mismo que Ciencia de Datos o Inteligencia Artificial

Es crucial entender que las tecnologías Big Data son **herramientas**, no el análisis en sí. El texto resalta un punto muy importante:

Las **herramientas Big Data** (las tecnologías) nos permiten aplicar a datos masivos **técnicas** que ya existían. Es decir, las técnicas de análisis (estadística, matemáticas, ciencia de la computación, inteligencia artificial) son un campo de estudio aparte, muchas de ellas desarrolladas hace décadas.

La **sinergia** está en que las tecnologías Big Data permiten que esas técnicas de análisis que ya conocíamos se puedan usar con **cantidades de datos mucho mayores y más variadas**. Esto resulta en:

* **Resultados más rápidos:** Se procesa más información en menos tiempo.
* **Mucha más calidad:** Al poder cruzar datos de diversas fuentes y usarlos para "entrenar" algoritmos, los modelos predictivos o los análisis son mucho más precisos y profundos.

---

### Puntos Clave para Recordar y Aplicar:

* **Las 3 "V" definen Big Data:**
    * **Volumen:** Demasiados datos para tecnologías tradicionales.
    * **Velocidad:** Datos que llegan y se procesan en tiempo real.
    * **Variedad:** Datos de muchas fuentes y formatos (estructurados, no estructurados).
* **Big Data es una solución tecnológica:** Es un conjunto de **tecnologías y arquitecturas** para almacenar, mover, acceder y procesar datos masivos.
* **No confundir con la ciencia de datos o algoritmos:** Las tecnologías Big Data son las **herramientas** que permiten aplicar técnicas de análisis (que pertenecen a campos como la estadística o la IA) a grandes volúmenes de datos, mejorando la velocidad y calidad de los resultados.
* **Un proyecto es Big Data cuando las tecnologías Big Data son la mejor solución** para sus características de datos (V3).

---

# PLUS Complementario 

## Las 7 V's del Big Data

1.  **Volumen:** (Ya lo vimos) Se refiere a la **enorme cantidad de datos** generados. Estamos hablando de petabytes, exabytes, e incluso zettabytes de información.
    * *Ejemplo:* Todos los datos de uso de una red social como Facebook o TikTok a nivel mundial en un solo día.

2.  **Velocidad:** (Ya lo vimos) La **rapidez con la que se generan y se procesan los datos**. Esto es crucial para análisis en tiempo real y toma de decisiones inmediatas.
    * *Ejemplo:* Las transacciones bursátiles en la bolsa de valores, donde cada milisegundo cuenta para detectar oportunidades o fraudes.

3.  **Variedad:** (Ya lo vimos) La **diversidad de formatos y tipos de datos**. Esto incluye desde bases de datos estructuradas hasta textos, imágenes, videos, audios, datos de sensores, etc.
    * *Ejemplo:* Un sistema de análisis de clientes que combina sus compras (datos estructurados), sus comentarios en encuestas (texto no estructurado) y sus interacciones en el sitio web (datos semiestructurados).

4.  **Veracidad:** Se refiere a la **calidad y confiabilidad de los datos**. En el Big Data, no solo importa la cantidad, sino también si esos datos son precisos, completos y fiables. Datos erróneos pueden llevar a conclusiones equivocadas.
    * *Ejemplo:* Datos de sensores meteorológicos que se usan para predecir el clima. Si los sensores están defectuosos o los datos se registran incorrectamente, la predicción será errónea. Es el famoso "Garbage In, Garbage Out".

5.  **Valor:** Este es, quizás, el objetivo final. El **valor** se refiere a la capacidad de **extraer información útil y accionable** de los datos. De nada sirve tener millones de datos si no se pueden traducir en decisiones o beneficios concretos para una empresa o investigación.
    * *Ejemplo:* Una empresa minorista que analiza el comportamiento de compra de sus clientes para identificar patrones y ofrecer promociones personalizadas que realmente aumenten las ventas. El valor es ese aumento de las ventas gracias al análisis de datos.

6.  **Variabilidad:** Hace referencia a la **inconsistencia que pueden mostrar los datos a lo largo del tiempo o entre diferentes fuentes**. Los datos pueden tener picos estacionales, cambios en tendencias o significados que varían.
    * *Ejemplo:* Las búsquedas en Google de ciertos productos que varían drásticamente según la época del año (ej. búsquedas de abrigos en invierno y trajes de baño en verano). Los algoritmos de análisis deben ser capaces de manejar esta fluctuación.

7.  **Visualización:** La capacidad de **representar los datos de manera clara y comprensible** para que las personas puedan interpretarlos fácilmente y tomar decisiones. Con tantos datos, una buena visualización es clave para comunicar los *insights* (conocimientos) obtenidos.
    * *Ejemplo:* Un tablero de control (dashboard) interactivo que muestra las ventas diarias de una empresa, el tráfico de su sitio web y la actividad en redes sociales en gráficos intuitivos, permitiendo a los gerentes ver rápidamente el rendimiento.

---

Mientras que las **tres V iniciales (Volumen, Velocidad, Variedad)** definen las **características fundamentales** que hacen que un conjunto de datos sea "Big Data" y que requiera tecnologías especiales para su gestión, las **otras V's (Veracidad, Valor, Variabilidad, Visualización)** se enfocan más en los **desafíos y el propósito** de trabajar con esos grandes volúmenes de datos para obtener beneficios reales.

Es importante que las conozcas todas, ya que te darán una visión más completa de lo que implica trabajar en el mundo del Big Data.





## 1.4. Origen de las tecnologías big data

Para entender el Big Data, tenemos que retroceder a los inicios de Internet, específicamente a **Google**. Imagínate, Google necesitaba indexar una cantidad gigantesca y creciente de páginas web para que su buscador funcionara. Las tecnologías tradicionales simplemente no podían con ello.

Aquí es donde entran dos ideas revolucionarias:

### 1. Google File System (GFS) - Almacenamiento Distribuido (2003)

* **El problema:** ¿Cómo almacenar archivos que son más grandes que un solo disco duro o que necesitan ser accedidos por muchos a la vez?
* **La solución de Google:** Desarrollaron **Google File System (GFS)**. La idea era simple pero poderosa: en lugar de usar una supercomputadora carísima, usaron muchas **computadoras normales y corrientes (commodity hardware)** conectadas entre sí formando un **clúster**. Cada una de estas máquinas no era muy potente, pero juntas podían almacenar archivos gigantescos de manera distribuida.
* **Concepto clave:** Si necesitas más almacenamiento o potencia, simplemente agregas más máquinas "baratas" al clúster.
* **Importancia:** GFS fue la base para **HDFS (Hadoop Distributed File System)**, que es fundamental en el ecosistema Big Data actual.

### 2. MapReduce - Procesamiento Distribuido (2004)

* **El problema:** Una vez que tienes los datos almacenados de forma distribuida con GFS, ¿cómo los procesas de manera eficiente usando ese mismo clúster de máquinas?
* **La solución de Google:** Publicaron un nuevo modelo de programación llamado **MapReduce**. Este modelo permitía procesar datos **en paralelo** en todo el clúster.
* **Punto fuerte:** Lo brillante de MapReduce es que **simplificó enormemente** el trabajo del programador. No tenías que preocuparte por los detalles complejos de la red, la comunicación entre las máquinas o cómo distribuir la tarea; el sistema se encargaba de todo eso. El desarrollador solo tenía que centrarse en la lógica de su aplicación.
* **Impacto:** Durante muchos años, MapReduce fue el estándar para desarrollar software Big Data.

---

### La Revolución de Apache Spark (2009)

Aunque MapReduce fue un gran avance, tenía algunas limitaciones, especialmente en ciertas tareas. Esto motivó a un investigador llamado Matei Zaharia a crear **Apache Spark** en 2009.

* **Características:** Spark comparte los principios de MapReduce (ejecutarse en un clúster de *commodity hardware* y simplificar la programación distribuida), pero es **mucho más rápido** porque opera principalmente en la **memoria RAM** de los nodos del clúster, en lugar de depender tanto del disco duro.
* **Estado actual:** Desde 2014, **Apache Spark ha reemplazado completamente a MapReduce** como el motor de procesamiento distribuido dominante. Muchas herramientas que antes usaban MapReduce se han actualizado para usar Spark como su motor.

---

### El Ecosistema Hadoop

La idea principal detrás de estas tecnologías de procesamiento distribuido es:

> Es posible procesar enormes cantidades de datos de forma distribuida en un clúster de máquinas interconectadas (no necesariamente potentes), y si necesitas más capacidad, simplemente añades más máquinas.

Con esta filosofía, y partiendo de GFS (que se convirtió en **HDFS**) y MapReduce, nació un conjunto de herramientas de código abierto llamado el **Ecosistema Hadoop**. Estas herramientas están diseñadas para trabajar juntas y resolver diferentes aspectos del Big Data.

---

### Herramientas Clave del Ecosistema Hadoop (y su evolución)

Aunque el texto menciona varias, estas son las más importantes y las que constituyen el estándar en la mayoría de las empresas hoy en día:

* **HDFS (Hadoop Distributed File System):** Es el **sistema de archivos distribuido** fundamental. Permite almacenar datos de forma fiable y escalable en un clúster de máquinas, distribuyendo la información y creando copias de seguridad automáticamente para evitar pérdidas.
    * *Analogía:* Piensa en HDFS como un gran almacén inteligente donde los productos se guardan en muchas estanterías diferentes, y el sistema sabe exactamente dónde está cada cosa y tiene copias de seguridad por si una estantería falla.
* **Apache Hive:** Permite **acceder y consultar datos almacenados en HDFS (o sistemas similares) usando SQL**, un lenguaje que muchos analistas y desarrolladores ya conocen. Hive traduce esas consultas SQL a trabajos que se ejecutan en un motor de procesamiento distribuido (originalmente MapReduce, ahora principalmente Spark o Apache Tez).
    * *Analogía:* Si HDFS es el almacén, Hive es la herramienta que te permite hacer preguntas al almacén usando un lenguaje que entiendes ("dame todos los productos que vendimos el mes pasado de la categoría X").
* **Apache Spark:** Como ya mencionamos, es el **motor de procesamiento distribuido** de propósito general más popular actualmente. Es muy rápido y versátil, capaz de realizar diversas tareas (procesamiento por lotes, en tiempo real, machine learning, procesamiento de gráficos).
    * *Analogía:* Si HDFS es el almacén y Hive la interfaz de preguntas, Spark es el motor superrápido que va al almacén, encuentra los datos y te da la respuesta a tus preguntas o realiza la tarea que le pidas.
* **Apache Kafka:** Es una **plataforma para manejar eventos y flujos de datos en tiempo real**. Imagina una cola de mensajes distribuida y muy escalable que puede recibir y enviar millones de mensajes por segundo. Es ideal para datos que llegan constantemente y necesitan ser procesados al instante.
    * *Analogía:* Kafka es como una autopista de información donde los datos viajan a gran velocidad en "paquetes" y pueden ser recogidos por diferentes "camiones" (procesos de Spark, por ejemplo) a medida que van llegando.

---

### Las Distribuciones de Hadoop

Instalar y configurar todas estas herramientas de Hadoop por separado puede ser complicado. Por eso, surgieron las **distribuciones de Hadoop**.

* **¿Qué son?** Son paquetes que agrupan varias herramientas del ecosistema Hadoop, ya configuradas y probadas para que funcionen perfectamente juntas. Esto simplifica mucho la instalación y el mantenimiento.
* **Empresas:** Empresas como **Cloudera** y **Hortonworks** (que ahora están fusionadas) o MapR, nacieron para crear estas distribuciones, ofreciendo tanto versiones de código abierto como versiones empresariales con soporte y características adicionales.

---

### Puntos Clave para Recordar y Aplicar:

* **Origen en Google:** La necesidad de Google de indexar la web llevó al desarrollo de GFS y MapReduce.
* **Commodity Hardware + Clúster:** La idea central es usar muchas máquinas baratas trabajando juntas.
* **GFS (base de HDFS):** Sistema de archivos distribuido para almacenar datos gigantes.
* **MapReduce:** Primer modelo de programación para procesamiento paralelo, ahora obsoleto.
* **Apache Spark:** El motor de procesamiento distribuido actual, mucho más rápido que MapReduce.
* **Ecosistema Hadoop:** Un conjunto de herramientas de código abierto (HDFS, Hive, Spark, Kafka, etc.) que trabajan juntas.
* **Distribuciones de Hadoop:** Paquetes que simplifican la instalación y configuración de las herramientas del ecosistema.


## PLUS Complementario 

## ¿Qué es Elasticsearch?

Imagina que tienes una biblioteca gigantesca, con millones de libros, periódicos, revistas, documentos, grabaciones de audio, y videos. Si quieres encontrar algo específico en ese mar de información, necesitas un sistema de búsqueda muy potente y rápido.

**Elasticsearch** es, en esencia, un **motor de búsqueda y análisis distribuido en tiempo real**. Es como ese bibliotecario superinteligente y veloz que no solo sabe dónde está cada cosa, sino que también puede entender el contenido, agruparlo por temas, sugerirte cosas relacionadas y darte resultados en milisegundos, incluso si estás buscando entre terabytes de datos.

Está construido sobre una base llamada Apache Lucene, que es una biblioteca de búsqueda de texto de alto rendimiento.

Aquí algunos puntos clave para entenderlo:

* **Motor de búsqueda:** Su función principal es permitirte buscar información de manera muy rápida y relevante. No solo busca coincidencias exactas, sino que entiende el contexto y puede manejar búsquedas complejas.
* **Análisis distribuido:** Significa que puede manejar enormes volúmenes de datos distribuyéndolos en un **clúster** de servidores (como vimos con HDFS). Si necesitas más capacidad, simplemente añades más servidores.
* **En tiempo real:** Los datos que ingresas están disponibles para búsqueda y análisis casi al instante. No hay que esperar horas para que la información se indexe y esté lista.
* **Basado en documentos:** Almacena la información en un formato llamado JSON (JavaScript Object Notation), que es flexible y fácil de usar para desarrolladores y máquinas. Cada "documento" puede ser cualquier cosa: un log, un artículo de producto, un perfil de usuario, etc.
* **Esquema libre (Schema-less):** No necesitas definir de antemano la estructura exacta de tus datos. Puedes añadir documentos con campos diferentes y Elasticsearch se adapta, lo que lo hace muy flexible para manejar la **variedad** de datos del Big Data.

---

## ¿Para qué se usa Elasticsearch?

Elasticsearch es increíblemente versátil y se utiliza en una gran variedad de escenarios, especialmente en aquellos donde la **búsqueda rápida, el análisis de datos en tiempo real y la escalabilidad** son cruciales. Aquí tienes los usos más comunes:

1.  **Búsqueda en Sitios Web y Aplicaciones:**
    * **Ejemplo:** Cuando buscas un producto en Amazon, un vuelo en una aerolínea, o un documento en la ayuda de una empresa. Elasticsearch es el motor detrás de la barra de búsqueda que te da resultados relevantes al instante. Permite funciones avanzadas como autocompletado, corrección de errores tipográficos y búsqueda por facetas (filtrar por color, tamaño, precio, etc.).

2.  **Análisis de Logs y Métricas (Observabilidad):**
    * **Ejemplo:** Las empresas generan millones de registros (logs) de sus servidores, aplicaciones y dispositivos de red. Elasticsearch se usa para recolectar, almacenar y analizar estos logs en tiempo real. Esto permite a los ingenieros detectar errores, problemas de rendimiento o ataques de seguridad tan pronto como ocurren. Es fundamental para la monitorización de sistemas.

3.  **Análisis de Datos de Seguridad (SIEM):**
    * **Ejemplo:** En un centro de operaciones de seguridad (SOC), Elasticsearch ayuda a analizar enormes volúmenes de eventos de seguridad (intentos de inicio de sesión, actividad de red inusual, etc.) para detectar amenazas, ataques o intrusiones en tiempo real.

4.  **Análisis de Texto y Procesamiento de Lenguaje Natural (NLP):**
    * **Ejemplo:** Analizar millones de comentarios de clientes en redes sociales, correos electrónicos de soporte o reseñas de productos para entender el sentimiento general (positivo, negativo), identificar tendencias, o extraer información clave automáticamente.

5.  **Análisis de Negocio e Inteligencia de Negocios (BI):**
    * **Ejemplo:** Aunque no es una base de datos analítica pura como un *data warehouse*, su capacidad de búsqueda y agregación rápida permite a las empresas explorar grandes conjuntos de datos de negocio para identificar tendencias de ventas, patrones de comportamiento del cliente o rendimiento de campañas de marketing.

6.  **Búsqueda Geoespacial:**
    * **Ejemplo:** Aplicaciones que necesitan buscar lugares cercanos, como restaurantes o taxis en un mapa, o analizar patrones geográficos en los datos.

---

En resumen, si tienes una gran cantidad de datos que necesitan ser **buscados, filtrados, agregados o analizados muy rápidamente**, y esa información puede venir en formatos variados, **Elasticsearch** es una de las principales herramientas del ecosistema Big Data que te permitirá lograrlo. Es parte de una pila de software más grande conocida como la "ELK Stack" (Elasticsearch, Logstash y Kibana), que se usa mucho para la observabilidad y el análisis de logs.


# Tema 2. HDFS y MapReduce

## 2.2. Introducción a HDFS
## 2.3. Arquitectura de HDFS
## 2.4. Comandos de HDFS más frecuentes
## 2.5. Programación distribuida y MapReduce