{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15bfcfc880f2897e6836933d55c7c042",
     "grade": false,
     "grade_id": "cell-570cf80ae1b2c48e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Actividad 1: HDFS, Spark SQL y MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuerda borrar siempre las líneas que dicen `raise NotImplementedError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alumno: Leonard Jose Cuenca Roa\n",
    "Carrera: Analisis y visualización de Datos Big Data \n",
    "Fecha: 13/07/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a238d899b5a6e8c414330ade880233f",
     "grade": false,
     "grade_id": "cell-f4c598b6fd61ee12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lee con detenimiento cada ejercicio. Las variables utilizadas para almacenar las soluciones, al igual que las nuevas columnas creadas, deben llamarse **exactamente** como indica el ejercicio, o de lo contrario los tests fallarán y el ejercicio no puntuará. Debe reemplazarse el valor `None` al que están inicializadas por el código necesario para resolver el ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10cdca7b33ec4328e542f94942371393",
     "grade": false,
     "grade_id": "cell-42368b0202b6ce77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Leemos el fichero flights.csv que hemos subido a HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b86205b9dc8b69adf7aa9ba76518864",
     "grade": false,
     "grade_id": "cell-3202a483f423590a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Indicamos que contiene encabezados (nombres de columnas) y que intente inferir el esquema, aunque después comprobaremos si lo\n",
    "ha inferido correctamente o no. La ruta del archivo en HDFS debería ser /<nombre_alumno>/flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5310bc8c3244ee98391957d26dc91d08",
     "grade": false,
     "grade_id": "lectura-fichero",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema del DataFrame:\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      "\n",
      "\n",
      "Primeras 5 filas del DataFrame:\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|    1|  1|       1|       96|     235|       70|     AS| N508AS|   145|   PDX| ANC|     194|    1542|   0|     1|\n",
      "|2014|    1|  1|       4|       -6|     738|      -23|     US| N195UW|  1830|   SEA| CLT|     252|    2279|   0|     4|\n",
      "|2014|    1|  1|       8|       13|     548|       -4|     UA| N37422|  1609|   PDX| IAH|     201|    1825|   0|     8|\n",
      "|2014|    1|  1|      28|       -2|     800|      -23|     US| N547UW|   466|   PDX| CLT|     251|    2282|   0|    28|\n",
      "|2014|    1|  1|      34|       44|     325|       43|     AS| N762AS|   121|   SEA| ANC|     201|    1448|   0|    34|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: integer (nullable = true)\n",
      " |-- dep_delay: integer (nullable = true)\n",
      " |-- arr_time: integer (nullable = true)\n",
      " |-- arr_delay: double (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      "\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|    1|  1|       1|       96|     235|     70.0|     AS| N508AS|   145|   PDX| ANC|     194|    1542|   0|     1|\n",
      "|2014|    1|  1|       4|       -6|     738|    -23.0|     US| N195UW|  1830|   SEA| CLT|     252|    2279|   0|     4|\n",
      "|2014|    1|  1|       8|       13|     548|     -4.0|     UA| N37422|  1609|   PDX| IAH|     201|    1825|   0|     8|\n",
      "|2014|    1|  1|      28|       -2|     800|    -23.0|     US| N547UW|   466|   PDX| CLT|     251|    2282|   0|    28|\n",
      "|2014|    1|  1|      34|       44|     325|     43.0|     AS| N762AS|   121|   SEA| ANC|     201|    1448|   0|    34|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MiPrimeraAppSpark\").getOrCreate()\n",
    "\n",
    "ruta_hdfs = \"/CuencaRoaLeonardJose/flights.csv\"\n",
    "# Descomentar estas líneas\n",
    "flightsDF = spark.read.csv(ruta_hdfs, header=\"true\", inferSchema=\"true\")\n",
    "\n",
    "# 1. Imprimo el esquema del DataFrame para revisar los tipos de datos\n",
    "print(\"Esquema del DataFrame:\")\n",
    "flightsDF.printSchema()\n",
    "\n",
    "# 2. Muestro las primeras 5 filas para inspeccionar los datos\n",
    "print(\"\\nPrimeras 5 filas del DataFrame:\")\n",
    "flightsDF.show(5)\n",
    "\n",
    "# 3. Mostramos el número de filas que tiene el DataFrame para hacernos una idea de su tamaño:\n",
    "flightsDF.count()\n",
    "\n",
    "# 4. Vamos a averiguar cuántas filas tienen el valor \"NA\" (como string) en la columna dep_time:\n",
    "cuantos_NA = flightsDF\\\n",
    "                .where(F.col(\"dep_time\") == \"NA\")\\\n",
    "                .count()\n",
    "cuantos_NA\n",
    "\n",
    "# 5. En nuestro caso, como tenemos un número considerable de filas, vamos a quitar todas las filas donde hay un NA en cualquiera de las columnas.\n",
    "columnas_limpiar = [\"dep_time\", \"dep_delay\", \"arr_time\", \"arr_delay\", \"air_time\", \"hour\", \"minute\"]\n",
    "\n",
    "flightsLimpiado = flightsDF\n",
    "for nombreColumna in columnas_limpiar:  # para cada columna, nos quedamos con las filas que no tienen NA en esa columna\n",
    "    flightsLimpiado = flightsLimpiado.where(F.col(nombreColumna) != \"NA\")\n",
    "\n",
    "flightsLimpiado.cache()\n",
    "\n",
    "# 6. Si ahora mostramos el número de filas que tiene el DataFrame flightsLimpiado tras eliminar todas esas filas, vemos que ha disminuido ligeramente pero sigue siendo un número considerable como para realizar analítica y sacar conclusiones sobre estos datos\n",
    "flightsLimpiado.count()\n",
    "\n",
    "# 7.  Una vez que hemos eliminado los NA, vamos a convertir a tipo entero cada una de esas columnas que eran de tipo string.\n",
    "\n",
    "flightsConvertido = flightsLimpiado\n",
    "\n",
    "for c in columnas_limpiar:\n",
    "    # método que crea una columna o reemplaza una existente\n",
    "    flightsConvertido = flightsConvertido.withColumn(c, F.col(c).cast(IntegerType())) \n",
    "\n",
    "flightsConvertido = flightsConvertido.withColumn(\"arr_delay\", F.col(\"arr_delay\").cast(DoubleType()))\n",
    "flightsConvertido.cache()\n",
    "\n",
    "flightsConvertido.printSchema()\n",
    "\n",
    "flightsConvertido.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5810b869bd7baccabe0a2952dd0baae1",
     "grade": false,
     "grade_id": "cell-c0cfdd1db1edaa7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Partiendo del DataFrame `flightsConvertido` que ya tiene los tipos correctos en las columnas, se pide: \n",
    "\n",
    "* Crear un nuevo DataFrame llamado `aeropuertosOrigenDF` que tenga una columna `origin` y que tenga tantas filas como aeropuertos distintos de *origen* existan. ¿Cuántas filas tiene? Almacenar dicho recuento en la variable entera `n_origen`.\n",
    "* Crear un nuevo DataFrame llamado `rutasDistintasDF` que tenga dos columnas `origin`, `dest` y que tenga tantas filas como rutas diferentes existan (es decir, como combinaciones distintas haya entre un origen y un destino). Una vez creado, contar cuántas combinaciones hay, almacenando dicho recuento en la variable entera `n_rutas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fb2ec5d49ff84edae4833eca797068b",
     "grade": false,
     "grade_id": "ejercicio-1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de aeropuertos de origen distintos: 2\n",
      "+------+\n",
      "|origin|\n",
      "+------+\n",
      "|   SEA|\n",
      "|   PDX|\n",
      "+------+\n",
      "\n",
      "Número de rutas distintas: 115\n",
      "+------+----+\n",
      "|origin|dest|\n",
      "+------+----+\n",
      "|   SEA| RNO|\n",
      "|   SEA| DTW|\n",
      "|   SEA| CLE|\n",
      "|   SEA| LAX|\n",
      "|   PDX| SEA|\n",
      "|   SEA| BLI|\n",
      "|   PDX| IAH|\n",
      "|   PDX| PHX|\n",
      "|   SEA| SLC|\n",
      "|   SEA| SBA|\n",
      "|   SEA| BWI|\n",
      "|   PDX| IAD|\n",
      "|   PDX| SFO|\n",
      "|   SEA| KOA|\n",
      "|   SEA| JAC|\n",
      "|   PDX| MCI|\n",
      "|   SEA| SJC|\n",
      "|   SEA| ABQ|\n",
      "|   SEA| SAT|\n",
      "|   PDX| ONT|\n",
      "+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contar aeropuertos de origen distintos\n",
    "aeropuertosOrigenDF = flightsConvertido.select(\"origin\").distinct()\n",
    "n_origen = aeropuertosOrigenDF.count()\n",
    "print(f\"Número de aeropuertos de origen distintos: {n_origen}\")\n",
    "aeropuertosOrigenDF.show()\n",
    "\n",
    "# Contar rutas distintas (combinaciones de origen y destino)\n",
    "rutasDistintasDF  = flightsConvertido.select(\"origin\", \"dest\").distinct()\n",
    "n_rutas = rutasDistintasDF.count()\n",
    "\n",
    "print(f\"Número de rutas distintas: {n_rutas}\")\n",
    "rutasDistintasDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f02d6e47bb3cc84e97f31cce091f80b3",
     "grade": true,
     "grade_id": "ejercicio-1-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(n_origen == 2)\n",
    "assert(n_rutas == 115)\n",
    "assert(aeropuertosOrigenDF.count() == n_origen)\n",
    "assert(rutasDistintasDF.count() == n_rutas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9229f0b48ed644e35a731b404738edf2",
     "grade": false,
     "grade_id": "cell-2b5f0dea18728fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "* Partiendo de nuevo de `flightsConvertido`, se pide calcular, *sólo para los vuelos que llegan con* ***retraso positivo***, el retraso medio a la llegada de dichos vuelos, para cada aeropuerto de destino. La nueva columna con el retraso medio a la llegada debe llamarse `retraso_medio`. El DF resultante debe estar **ordenado de mayor a menor retraso medio**. El código que calcule esto debería ir encapsulado en una función de Python llamada `retrasoMedio` que reciba como argumento un DataFrame y devuelva como resultado el DataFrame con el cálculo descrito anteriormente.\n",
    "\n",
    "* Una vez hecha la función, invocarla pasándole como argumento `flightsConvertido` y almacenar el resultado devuelto en la variable `retrasoMedioDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "097436083d0007a7d99d5108e1a504c9",
     "grade": false,
     "grade_id": "ejercicio-2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def retrasoMedio(df):\n",
    "    # 1. Primero Filtro vuelos con retraso positivo\n",
    "    vuelos_con_retraso_positivo = df.where(F.col(\"arr_delay\") > 0)\n",
    "\n",
    "    # 2. Segundo: Agrupo por aeropuerto de destino y \n",
    "    # 3. Tercero: Calculo el retraso medio\n",
    "    # 4. Cuarto: Renombro la columna del retraso medio\n",
    "    retraso_medio_df = vuelos_con_retraso_positivo.groupBy(\"dest\") \\\n",
    "                                                  .agg(F.avg(\"arr_delay\").alias(\"retraso_medio\"))\n",
    "\n",
    "    # 5. Quinto: Ordeno el DataFrame resultante de mayor a menor retraso medio\n",
    "    df_final_ordenado = retraso_medio_df.orderBy(F.col(\"retraso_medio\").desc())\n",
    "\n",
    "    return df_final_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12aa19d467a0c50adface20495b6cf35",
     "grade": true,
     "grade_id": "ejercicio-2-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lista = retrasoMedio(flightsConvertido).take(3)\n",
    "assert((lista[0].retraso_medio == 64.75) & (lista[0].dest == \"BOI\"))\n",
    "assert((lista[1].retraso_medio == 46.8) & (lista[1].dest == \"HDN\"))\n",
    "assert((round(lista[2].retraso_medio, 2) == 41.19) & (lista[2].dest == \"SFO\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora invocamos a nuestra función `retrasoMedio` pasándole como argumento `flightsConvertido`. ¿Cuáles son los tres aeropuertos con mayor retraso medio? ¿Cuáles son sus retrasos medios en minutos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los tres aeropuertos con mayor retraso medio y sus retrasos:\n",
      "+----+------------------+\n",
      "|dest|     retraso_medio|\n",
      "+----+------------------+\n",
      "| BOI|             64.75|\n",
      "| HDN|              46.8|\n",
      "| SFO|41.193768844221104|\n",
      "+----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invocar la función con tu DataFrame flightsConvertido\n",
    "retrasoMedioDF = retrasoMedio(flightsConvertido)\n",
    "\n",
    "# Mostrar los tres primeros resultados como esta ordenado podremos mostrar los primeros tres de esta manera\n",
    "print(\"Los tres aeropuertos con mayor retraso medio y sus retrasos:\")\n",
    "retrasoMedioDF.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa9ed55cd86eb0958e150d6a918db1af",
     "grade": false,
     "grade_id": "cell-e577747d4427e32b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Ajustar un modelo de DecisionTree de Spark para predecir si un vuelo vendrá o no con retraso (problema de clasificación binaria), utilizando como variables predictoras el mes, el día del mes, la hora de partida `dep_time`, la hora de llegada `arr_time`, el tipo de avión (`carrier`), la distancia y el tiempo que permanece en el aire. Para ello, sigue los siguientes pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4405b7db7180445df5cacc66d82db53",
     "grade": false,
     "grade_id": "cell-e577747d4427e32a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notemos que en estos datos hay variables numéricas y variables categóricas que ahora mismo están tipadas como numéricas, como por ejemplo el mes del año (`month`), que es en realidad categórica. Debemos indicar a Spark cuáles son categóricas e indexarlas. Para ello se pide: \n",
    "\n",
    "* Crear un `StringIndexer` llamado `indexerMonth` y otro llamado `indexerCarrier` sobre las variables categóricas `month` y `carrier` (tipo de avión). El nombre de las columnas indexadas que se crearán debe ser, respectivamente, `monthIndexed` y `carrierIndexed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb039584cd14e6bc3434e5be930341e6",
     "grade": false,
     "grade_id": "string-indexer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área bajo la curva ROC (AUC) = 0.4876462417378798\n",
      "+-----+----------+--------------------+---------------+---------+\n",
      "|label|prediction|         probability|  rawPrediction|arr_delay|\n",
      "+-----+----------+--------------------+---------------+---------+\n",
      "|    0|       0.0|[0.73400176938956...|[7467.0,2706.0]|     -4.0|\n",
      "|    1|       0.0|[0.73400176938956...|[7467.0,2706.0]|    219.0|\n",
      "|    1|       1.0|[0.48260869565217...|  [444.0,476.0]|     24.0|\n",
      "|    0|       0.0|[0.73400176938956...|[7467.0,2706.0]|     -6.0|\n",
      "|    0|       0.0|[0.65965814551505...|[8722.0,4500.0]|    -25.0|\n",
      "+-----+----------+--------------------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 0. Preparo la columna 'label' \n",
    "flights_con_label = flightsConvertido.withColumn(\"label\", F.when(F.col(\"arr_delay\") > 0, 1).otherwise(0))\n",
    "\n",
    "# 1. Defino los StringIndexers\n",
    "indexerMonth = StringIndexer(inputCol=\"month\", outputCol=\"monthIndexed\")\n",
    "indexerCarrier = StringIndexer(inputCol=\"carrier\", outputCol=\"carrierIndexed\")\n",
    "\n",
    "# 2. Defino las columnas a usar en el VectorAssembler (incluyendo las indexadas)\n",
    "feature_cols = [\"monthIndexed\", \"day\", \"dep_time\", \"arr_time\", \"carrierIndexed\", \"distance\", \"air_time\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# 3. Defino el modelo Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", seed=42)\n",
    "\n",
    "# 4. Genero el Pipeline (orden de ejecución: indexers -> assembler -> dt)\n",
    "pipeline = Pipeline(stages=[indexerMonth, indexerCarrier, assembler, dt])\n",
    "\n",
    "# 5. Divido los datos (antes de fit_pipeline si el pipeline incluye el modelo)\n",
    "train_data, test_data = flights_con_label.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 6. Ajusto y entreno el Pipeline completo con los datos de entrenamiento\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# 7. Realizo las predicciones en el conjunto de prueba\n",
    "prediciones = model.transform(test_data)\n",
    "\n",
    "# 8. Evaluo el modelo\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(prediciones)\n",
    "\n",
    "# Muestro las prediciones \n",
    "print(f\"Área bajo la curva ROC (AUC) = {auc}\")\n",
    "prediciones.select(\"label\", \"prediction\", \"probability\", \"rawPrediction\", \"arr_delay\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c96c7c7d5836922dd549b358b897b781",
     "grade": true,
     "grade_id": "string-indexer-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(indexerMonth, StringIndexer))\n",
    "assert(isinstance(indexerCarrier, StringIndexer))\n",
    "assert(indexerMonth.getInputCol() == \"month\")\n",
    "assert(indexerMonth.getOutputCol() == \"monthIndexed\")\n",
    "assert(indexerCarrier.getInputCol() == \"carrier\")\n",
    "assert(indexerCarrier.getOutputCol() == \"carrierIndexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69e024b0baeeb36bb74d136c7e113372",
     "grade": false,
     "grade_id": "cell-e577747d4427e323",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recordemos también que Spark requiere que todas las variables estén en una única columna de tipo vector, por lo que después de indexar estas dos variables, tendremos que fusionar en una columna de tipo vector todas ellas, utilizando un `VectorAssembler`. Se pide:\n",
    "\n",
    "* Crear en una variable llamada `vectorAssembler` un `VectorAssembler` que reciba como entrada una lista de todas las variables de entrada (y que no debe incluir `arr_delay`) que serán las que formarán parte del modelo. Crear primero esta lista de variables (lista de strings) en la variable `columnas_ensamblar` y pasar dicha variable como argumento al crear el `VectorAssembler`. Como es lógico, en el caso de las columnas `month` y `carrier`, no usaremos las variables originales sino las indexadas en el apartado anterior. La columna de tipo vector creada con las características ensambladas debe llamarse `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44623471d64d0605fcbcd4bbcc3c2a0d",
     "grade": false,
     "grade_id": "vector-assembler",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "['monthIndexed', 'day', 'dep_time', 'arr_time', 'carrierIndexed', 'distance', 'air_time']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Paso 1: Crear la lista de variables de entrada (strings)\n",
    "# Asegúrate de usar las columnas indexadas para 'month' y 'carrier'\n",
    "columnas_ensamblar = [\n",
    "    \"monthIndexed\",   # Columna indexada\n",
    "    \"day\",\n",
    "    \"dep_time\",\n",
    "    \"arr_time\",\n",
    "    \"carrierIndexed\", # Columna indexada\n",
    "    \"distance\",\n",
    "    \"air_time\"\n",
    "]\n",
    "\n",
    "# Paso 2: Crear el VectorAssembler\n",
    "# La columna de salida se llamará \"features\"\n",
    "vectorAssembler = VectorAssembler(inputCols=columnas_ensamblar, outputCol=\"features\")\n",
    "\n",
    "print(vectorAssembler.getOutputCol())\n",
    "print(vectorAssembler.getInputCols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d17b2fa1d8a4bd02b89952429ba1552",
     "grade": true,
     "grade_id": "vector-assembler-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(vectorAssembler, VectorAssembler))\n",
    "assert(vectorAssembler.getOutputCol() == \"features\")\n",
    "input_cols = vectorAssembler.getInputCols()\n",
    "assert(len(input_cols) == 7)\n",
    "assert(\"arr_delay\" not in input_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8eeb3a3f0b15e8b374789706cd9bce49",
     "grade": false,
     "grade_id": "cell-e577747d4427e32dsdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finalmente, vemos que la columna `arr_delay` es continua, y no binaria como requiere un problema de clasificación con dos clases. Vamos a convertirla en binaria. Para ello se pide:\n",
    "\n",
    "* Utilizar un binarizador de Spark, fijando a 15 el umbral, y guardarlo en la variable `delayBinarizer`. Consideramos retrasado un vuelo que ha llegado con más de 15 minutos de retraso, y no retrasado en caso contrario. La nueva columna creada con la variable binaria debe llamarse `arr_delay_binary` y debe ser interpretada como la columna target para nuestro algoritmo. Por ese motivo, esta columna **no** se incluyó en el apartado anterior entre las columnas que se ensamblan para formar las features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f33c493a3c3dd83fb6a39a7acefca5c",
     "grade": false,
     "grade_id": "binarizer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|arr_delay|arr_delay_binary|\n",
      "+---------+----------------+\n",
      "|     70.0|             1.0|\n",
      "|    -23.0|             0.0|\n",
      "|     -4.0|             0.0|\n",
      "|    -23.0|             0.0|\n",
      "|     43.0|             1.0|\n",
      "+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Definó la variable delayBinarizer\n",
    "# inputCol: La columna original de retraso ('arr_delay').\n",
    "# outputCol: El nombre de la nueva columna binaria ('arr_delay_binary').\n",
    "# hreshold: El umbral. Valores > threshold serán 1.0, valores <= threshold serán 0.0.\n",
    "delayBinarizer = Binarizer(inputCol=\"arr_delay\", outputCol=\"arr_delay_binary\", threshold=15.0)\n",
    "\n",
    "# Aplicamos el Binarizer en el DataFrame flightsConvertido solo para validarlo \n",
    "\n",
    "df_con_binario = delayBinarizer.transform(flightsConvertido)\n",
    "df_con_binario.select(\"arr_delay\", \"arr_delay_binary\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ec408ab263c0378526f96bb5d374704",
     "grade": true,
     "grade_id": "binarizer-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(delayBinarizer, Binarizer))\n",
    "assert(delayBinarizer.getThreshold() == 15)\n",
    "assert(delayBinarizer.getInputCol() == \"arr_delay\")\n",
    "assert(delayBinarizer.getOutputCol() == \"arr_delay_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5aed16d7ed0219fe1d8741848f594319",
     "grade": false,
     "grade_id": "cell-25a7793978ee7d05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Por último, crearemos el modelo de clasificación.\n",
    "\n",
    "* Crear en una variable `decisionTree` un árbol de clasificación de Spark (`DecisionTreeClassifier` del paquete `pyspark.ml.classification`)\n",
    "* Indicar como columna de entrada la nueva columna creada por el `VectorAssembler` creado en un apartado anterior.\n",
    "* Indicar como columna objetivo (target) la nueva columna creada por el `Binarizer` del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e785136d6d06691c003ff9542027e03d",
     "grade": false,
     "grade_id": "decision-tree",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Información del Estimador DecisionTreeClassifier ---\n",
      "El objeto 'decisionTree' es un estimador listo para aprender.\n",
      "Está configurado con los siguientes parámetros:\n",
      "DecisionTreeClassifier_8609ed56dd78\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Por aprendizaje de otras materias en el uso de arbol de decisiones usare semillas para evitar un poco el sesgo \n",
    "\n",
    "decisionTree = DecisionTreeClassifier(\n",
    "     featuresCol=\"features\",\n",
    "     labelCol=\"arr_delay_binary\",\n",
    "     seed=42\n",
    ")\n",
    "\n",
    "print(\"--- Información del Estimador DecisionTreeClassifier ---\")\n",
    "print(\"El objeto 'decisionTree' es un estimador listo para aprender.\")\n",
    "print(\"Está configurado con los siguientes parámetros:\")\n",
    "print(decisionTree)\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b03b48f304b5b34cd06eeec49e001fd",
     "grade": true,
     "grade_id": "decision-tree-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(decisionTree, DecisionTreeClassifier))\n",
    "assert(decisionTree.getFeaturesCol() == \"features\")\n",
    "assert(decisionTree.getLabelCol() == \"arr_delay_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "728da91edabbac5b62baf31bdd0a707e",
     "grade": false,
     "grade_id": "cell-e577747d4427e32d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ahora vamos a encapsular todas las fases en un sólo pipeline y procederemos a entrenarlo. Se pide:\n",
    "\n",
    "* Crear en una variable llamada `pipeline` un objeto `Pipeline` de Spark con las etapas anteriores en el orden adecuado para poder entrenar un modelo. \n",
    "\n",
    "* Entrenarlo invocando sobre ella al método `fit` y guardar el pipeline entrenado devuelto por dicho método en una variable llamada `pipelineModel`. \n",
    "\n",
    "* Aplicar el pipeline entrenado para transformar (predecir) el DataFrame `flightsConvertido`, guardando las predicciones devueltas en la variable `flightsPredictions` que será un DataFrame. Nótese que estamos prediciendo los propios datos de entrenamiento y que, por simplicidad, no habíamos hecho (aunque habría sido lo correcto) ninguna división de nuestros datos originales en subconjuntos distintos de entrenamiento y test antes de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edbdb627305d03efa41a88426330e160",
     "grade": false,
     "grade_id": "pipeline",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :D Pipeline creado exitosamente.\n",
      "Etapas del Pipeline: ['StringIndexer_e27bd83795fc', 'StringIndexer_e2107eca14cf', 'Binarizer_78bc66501f35', 'VectorAssembler_52fdc2a0d99c', 'DecisionTreeClassifier_8609ed56dd78']\n",
      "\n",
      " :D Pipeline entrenado (ajustado a los datos) con éxito.\n",
      "El objeto 'pipelineModel' ahora contiene todos los transformadores ajustados y el modelo de clasificación entrenado.\n",
      "\n",
      " :D  Predicciones generadas y guardadas en 'flightsPredictions' DataFrame.\n",
      "Este DataFrame ahora incluye las columnas de las características ensambladas,\n",
      "la etiqueta real ('arr_delay_binary'), la predicción ('prediction'),\n",
      "y las probabilidades ('probability') del modelo para cada clase.\n",
      "\n",
      "--- Primeras 5 filas del DataFrame de Predicciones ---\n",
      "+---------+----------------+----------+----------------------------------------+--------------------------------------+\n",
      "|arr_delay|arr_delay_binary|prediction|probability                             |features                              |\n",
      "+---------+----------------+----------+----------------------------------------+--------------------------------------+\n",
      "|70.0     |1.0             |1.0       |[0.3,0.7]                               |[10.0,1.0,1.0,235.0,0.0,1542.0,194.0] |\n",
      "|-23.0    |0.0             |0.0       |[0.9140647187557427,0.08593528124425734]|[10.0,1.0,4.0,738.0,6.0,2279.0,252.0] |\n",
      "|-4.0     |0.0             |0.0       |[0.9140647187557427,0.08593528124425734]|[10.0,1.0,8.0,548.0,4.0,1825.0,201.0] |\n",
      "|-23.0    |0.0             |0.0       |[0.9140647187557427,0.08593528124425734]|[10.0,1.0,28.0,800.0,6.0,2282.0,251.0]|\n",
      "|43.0     |1.0             |1.0       |[0.3,0.7]                               |[10.0,1.0,34.0,325.0,0.0,1448.0,201.0]|\n",
      "+---------+----------------+----------+----------------------------------------+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: genero el objeto Pipeline\n",
    "# Se encadeno todas las etapas en el orden lógico de procesamiento:\n",
    "# StringIndexer -> Binarizer (para la etiqueta) -> VectorAssembler -> DecisionTreeClassifier\n",
    "pipeline = Pipeline(stages=[\n",
    "    indexerMonth,\n",
    "    indexerCarrier,\n",
    "    delayBinarizer,\n",
    "    vectorAssembler,\n",
    "    decisionTree\n",
    "])\n",
    "\n",
    "print(\" :D Pipeline creado exitosamente.\")\n",
    "print(f\"Etapas del Pipeline: {[stage.uid for stage in pipeline.getStages()]}\")\n",
    "\n",
    "# Paso 2: :D Se Entrenó el Pipeline\n",
    "# Se invoco el método 'fit()' sobre el pipeline, pasándole el DataFrame de entrenamiento.\n",
    "# En este caso, por simplicidad, usamos el DataFrame completo 'flightsConvertido' como entrenamiento.\n",
    "pipelineModel = pipeline.fit(flightsConvertido)\n",
    "\n",
    "print(\"\\n :D Pipeline entrenado (ajustado a los datos) con éxito.\")\n",
    "print(\"El objeto 'pipelineModel' ahora contiene todos los transformadores ajustados y el modelo de clasificación entrenado.\")\n",
    "\n",
    "\n",
    "# Paso 3: :D Aplicar el Pipeline entrenado para transformar (predecir) los datos\n",
    "# Se invoco el método 'transform()' sobre el pipelineModel para generar predicciones.\n",
    "flightsPredictions = pipelineModel.transform(flightsConvertido)\n",
    "\n",
    "print(\"\\n :D  Predicciones generadas y guardadas en 'flightsPredictions' DataFrame.\")\n",
    "print(\"Este DataFrame ahora incluye las columnas de las características ensambladas,\")\n",
    "print(\"la etiqueta real ('arr_delay_binary'), la predicción ('prediction'),\")\n",
    "print(\"y las probabilidades ('probability') del modelo para cada clase.\")\n",
    "\n",
    "# Paso 4: XD Mostrar algunas de las columnas relevantes para verificar las predicciones\n",
    "print(\"\\n--- Primeras 5 filas del DataFrame de Predicciones ---\")\n",
    "flightsPredictions.select(\"arr_delay\", \"arr_delay_binary\", \"prediction\", \"probability\", \"features\").show(5, truncate=False)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "107b5ec260550eb4235ffecff655289a",
     "grade": true,
     "grade_id": "pipeline-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "assert(isinstance(pipeline, Pipeline))\n",
    "assert(len(pipeline.getStages()) == 5)\n",
    "assert(isinstance(pipelineModel, PipelineModel))\n",
    "assert(\"probability\" in flightsPredictions.columns)\n",
    "assert(\"prediction\" in flightsPredictions.columns)\n",
    "assert(\"rawPrediction\" in flightsPredictions.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c531953abf18cfb3b67571ddde7a57d",
     "grade": false,
     "grade_id": "cell-61156fe5938763f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Vamos a mostrar la matriz de confusión (este apartado no es evaluable). Agrupamos por la variable que tiene la clase verdadera y la que tiene la clase predicha, para ver en cuántos casos coinciden y en cuántos difieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75f98ae39b827e75c3f0b4b2aaa6b0db",
     "grade": false,
     "grade_id": "cell-896752beb71cb455",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+------+\n",
      "|arr_delay_binary|prediction| count|\n",
      "+----------------+----------+------+\n",
      "|             1.0|       1.0|   752|\n",
      "|             0.0|       1.0|   181|\n",
      "|             1.0|       0.0| 23497|\n",
      "|             0.0|       0.0|136318|\n",
      "+----------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsPredictions.groupBy(\"arr_delay_binary\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
