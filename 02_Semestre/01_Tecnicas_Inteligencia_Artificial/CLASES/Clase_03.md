# Primera Clase 
> 09 Mayo 2025 - Presencial - Grabada 

- Profesora: Adriana Cervantes Castillo 

# Resumen de Clase de IA: T√©cnica de Reglas 

Los sistemas basados en reglas son una de las metodolog√≠as m√°s utilizadas para la representaci√≥n del conocimiento. Se caracterizan por su capacidad de almacenar y procesar informaci√≥n en forma de reglas "Si-Entonces" (If-Then), lo que los hace ideales para la toma de decisiones y la automatizaci√≥n de procesos l√≥gicos.


**Caracteristicas**
- Estamos hablando que nos topamos a diarios es buscar patrones y asociaciones en distintos 
- Los sistemas basados en reglas son senillos y facil de entender
- Existen reglas de clasifiacion y de asociacion 
- Son modulares ya que nos permiten tomar decisiones de manera facil 
- no todas las reglas son necesariamente son buenas
- quien define si una regla es buena o no lo define el dominio es es el conocimiento que tengas del mismo dominio 
- no se tiene que mezclarse las conjunciones y disyunciones
- Tenemos confianza en las reglas 
- Tenemos Soporte en las reglas 

## Guia de pasos 
- Cuando trabajamos con reglas primero es calcular el soporte 
- Pero tenemos la exepci√≥n que iniciar con soporte no nos puede decir mucho ya que necesitamos que la premisa para un soporte este ejecutandose ese patron frecuentemente tener mas mayor coincidencias 
- Calcular la confianza 


**Ventajas clave de los sistemas basados en reglas:**

- Modularidad: Permiten descomponer el conocimiento en reglas individuales y manejables. Esto facilita la adici√≥n, modificaci√≥n o eliminaci√≥n de reglas sin afectar otras partes del sistema.

- Separaci√≥n entre control y conocimiento: Distinguen claramente entre el motor de inferencia (el "control" que aplica las reglas) y la base de conocimiento (las "reglas" mismas). Esto mejora la flexibilidad y el mantenimiento del sistema.

- F√°cil de entender: La estructura de las reglas (Si [condici√≥n] Entonces [acci√≥n/conclusi√≥n]) es intuitiva y se asemeja al razonamiento humano, lo que las hace comprensibles incluso para no expertos.

- Gesti√≥n del conocimiento: Proveen un marco estructurado para organizar, almacenar y recuperar el conocimiento de un dominio espec√≠fico, facilitando su administraci√≥n y evoluci√≥n.

- Toma de decisiones: Son altamente efectivos para modelar procesos de decisi√≥n, permitiendo al sistema llegar a conclusiones o ejecutar acciones basadas en las condiciones presentes.

**Como se hace**

Sintaxis b√°sica:
Una regla fundamental se expresa como:
SI <antecedente>
ENTONCES <consecuente>

- Antecedente (Condici√≥n): Es la parte de la regla que establece una o m√°s condiciones que deben ser verdaderas para que la regla se dispare. Piensa en esto como la "causa" o la "situaci√≥n" que se eval√∫a.

- Consecuente (Acci√≥n/Conclusi√≥n): Es la parte de la regla que especifica la acci√≥n a realizar o la conclusi√≥n a la que se llega si el antecedente es verdadero. Es el "efecto" o la "consecuencia".
Ejemplo simple:
SI "hay sol"
ENTONCES "ir a la playa"

Reglas con conjunciones y disyunciones:
Las reglas pueden tener antecedentes m√°s complejos que involucran m√∫ltiples condiciones.

- Conjunciones (AND): Significa que todas las condiciones en el antecedente deben ser verdaderas.
SI <antecedente 1>
AND <antecedente 2>
AND <antecedente 3>
ENTONCES <consecuente 1>
<consecuente 2>

En este caso, para que la regla se active y se produzcan los consecuentes 1 y 2, tanto el antecedente 1, como el antecedente 2, como el antecedente 3 deben ser verdaderos.

- Disyunciones (OR): No se muestra expl√≠citamente en la imagen, pero funcionar√≠a as√≠: SI <antecedente A> OR <antecedente B> ENTONCES <consecuente>. Significa que al menos una de las condiciones debe ser verdadera.

Advertencia importante: La imagen menciona que "No es recomendable mezclar conjunciones y disyunciones en una sola regla." Esto se debe a que mezclar AND y OR en el mismo nivel sin par√©ntesis expl√≠citos puede llevar a ambig√ºedades y hacer que la l√≥gica de la regla sea dif√≠cil de entender y mantener. Es mejor dividir reglas complejas con AND y OR mixtos en reglas m√°s simples o usar par√©ntesis para clarificar la precedencia, aunque generalmente se prefiere mantener la simplicidad.

## Reglas de Clasificaci√≥n y de Asociaci√≥n: Explicaci√≥n Ampliada
 Dos tipos fundamentales de reglas utilizadas en el √°mbito de la miner√≠a de datos y el aprendizaje autom√°tico: Reglas de Clasificaci√≥n y Reglas de Asociaci√≥n. Aunque ambas utilizan la estructura "SI... ENTONCES...", su prop√≥sito y aplicaci√≥n son diferentes.

 1. Reglas de Clasificaci√≥n
Definici√≥n de la imagen: "Las reglas de clasificaci√≥n predicen la clase."

**Contexto ampliado:**

- Objetivo: El objetivo principal de las reglas de clasificaci√≥n es asignar una etiqueta de clase predefinida a una nueva observaci√≥n o dato. Es decir, buscan construir un modelo que pueda predecir a qu√© categor√≠a o grupo pertenece un elemento.

- Estructura: T√≠picamente tienen la forma SI [condiciones sobre atributos] ENTONCES [pertenece a la Clase X]. El consecuente (la parte "ENTONCES") es siempre una de las clases posibles en el conjunto de datos.

- Entrenamiento: Se entrenan a partir de un conjunto de datos donde las clases ya son conocidas (datos etiquetados). El algoritmo aprende los patrones en los atributos que conducen a cada clase.

- Aplicaciones comunes:
Diagn√≥stico m√©dico: SI [s√≠ntoma A] AND [s√≠ntoma B] ENTONCES [Diagn√≥stico: Gripe].

    - Clasificaci√≥n de correos electr√≥nicos: SI [contiene palabras "oferta" OR "gratis"] ENTONCES [Clase: Spam].

    - Aprobaci√≥n de cr√©dito: SI [ingresos > X] AND [deuda < Y] ENTONCES [Clase: Cr√©dito Aprobado].

    - Evaluaci√≥n: Su rendimiento se mide por m√©tricas como la precisi√≥n, la exhaustividad, la puntuaci√≥n F1 y la matriz de confusi√≥n, que eval√∫an qu√© tan bien predicen la clase correcta.

Relaci√≥n con otros algoritmos: Son el resultado de algoritmos como C4.5, CART, m√°quinas de vectores de soporte (SVM) cuando se usan para clasificaci√≥n, o incluso redes neuronales convolucionales (CNN) para clasificaci√≥n de im√°genes. Los √°rboles de decisi√≥n son una fuente muy com√∫n de reglas de clasificaci√≥n.


2. Reglas de Asociaci√≥n
Las reglas de asociaci√≥n predicen valores de atributos, combinaciones de valores de atributos, o la propia clase." Y "El inter√©s de las reglas de asociaci√≥n es descubrir combinaciones de pares atributo-valor que ocurren con frecuencia en un conjunto de datos."

- Objetivo: El objetivo principal de las reglas de asociaci√≥n es descubrir relaciones o dependencias interesantes y ocultas entre √≠tems (atributos y sus valores) en grandes conjuntos de datos. No buscan predecir una clase espec√≠fica, sino encontrar qu√© √≠tems tienden a aparecer juntos.
Estructura: Tambi√©n tienen la forma SI [conjunto de √≠tems] ENTONCES [otro conjunto de √≠tems]. Los √≠tems pueden ser cualquier par atributo-valor (por ejemplo, "producto=leche", "d√≠a=martes", "m√©todo_pago=tarjeta").
Conceptos clave:

- Soporte (Support): Mide la frecuencia con la que aparecen juntos el antecedente y el consecuente en el conjunto de datos. Indica la popularidad de la regla.

- Confianza (Confidence): Mide la probabilidad de que el consecuente ocurra dado que el antecedente ha ocurrido. Indica la fiabilidad de la inferencia de la regla.

- Lift: Mide qu√© tan relevante es la asociaci√≥n m√°s all√° de lo que se esperar√≠a por azar. Un valor de Lift > 1 indica una asociaci√≥n positiva.

- Algoritmos comunes: El algoritmo m√°s conocido para generar reglas de asociaci√≥n es Apriori. Otros incluyen Eclat y FP-Growth.
Aplicaciones comunes (An√°lisis de Cesta de la Compra - Market Basket Analysis):

- Recomendaci√≥n de productos: SI [compra pa√±ales] ENTONCES [probablemente compra toallitas h√∫medas]. (¬°El cl√°sico ejemplo de "cerveza y pa√±ales"!)

-   Optimizaci√≥n de distribuci√≥n en tiendas: Identificar qu√© productos deber√≠an estar cerca unos de otros.

- Detecci√≥n de fraudes: SI [transacci√≥n en pa√≠s X] AND [cantidad > Y] ENTONCES [posiblemente fraudulento]. (Aqu√≠ la "clase" fraudulento podr√≠a ser el consecuente, mostrando c√≥mo pueden superponerse en la predicci√≥n de clases).

- An√°lisis web: SI [visita p√°gina A] AND [visita p√°gina B] ENTONCES [probablemente visita p√°gina C].

- Enfoque: Se centran en encontrar patrones frecuentes y relaciones de co-ocurrencia, no necesariamente en predecir un resultado espec√≠fico predefinido.


Estas dos m√©tricas son fundamentales en el √°mbito de las reglas de asociaci√≥n (y a veces tambi√©n en clasificaci√≥n, aunque con matices) para determinar la "relevancia" y el "inter√©s" de una regla descubierta en un conjunto de datos. No basta con que una regla sea l√≥gicamente v√°lida; debe ser estad√≠sticamente significativa.

1. Confianza (Confidence)
"La confianza es la probabilidad condicional de que dado un evento A se produzca un evento B."

F√≥rmula (notaci√≥n probabil√≠stica): Confianza(A‚ÜíB)=P(B‚à£A)= 
P(A)P(A‚à©B)
‚ÄãDonde:
A‚ÜíB representa la regla "SI A ENTONCES B".
P(B‚à£A) es la probabilidad de que B ocurra dado que A ha ocurrido.
P(A‚à©B) es la probabilidad de que A y B ocurran juntos (la intersecci√≥n).
P(A) es la probabilidad de que A ocurra.

Explicaci√≥n en el contexto de reglas: "Al hablar de reglas, la confianza se puede expresar como el porcentaje de ejemplos que satisfacen el antecedente y consecuente de la regla entre aquellos que satisfacen el antecedente."

Imagina que tienes una regla: SI (compra Pan) ENTONCES (compra Leche).
Para calcular la confianza, contar√≠as:
El n√∫mero de transacciones donde se compra Pan Y Leche (esto es A‚à©B).
El n√∫mero de transacciones donde solo se compra Pan (esto es A).
La confianza ser√≠a:  N√∫mero¬†de¬†transacciones¬†con¬†Pan Numero¬†de¬†transacciones¬†con¬†Pan¬†y¬†Leche
‚Äã
¬øQu√© mide? La confianza mide la fiabilidad o la precisi√≥n predictiva de la regla. Indica qu√© tan probable es que el consecuente sea verdadero si el antecedente es verdadero. Un valor de confianza alto sugiere que la implicaci√≥n de la regla es fuerte. Por ejemplo, una confianza del 80% significa que en el 80% de los casos donde se cumple el antecedente, tambi√©n se cumple el consecuente.

2. Soporte (Support)
"El soporte se refiere al cociente del n√∫mero de ejemplos que cumplen el antecedente y el consecuente de la regla entre el n√∫mero total de ejemplos."

F√≥rmula (notaci√≥n probabil√≠stica): Soporte(A‚ÜíB)=P(A‚à™B) (Nota: la imagen tiene un error aqu√≠, deber√≠a ser P(A‚à©B), no P(A‚à™B))

Correcci√≥n: El soporte para una regla A‚ÜíB se define como la probabilidad de que ambos el antecedente (A) y el consecuente (B) ocurran juntos en el conjunto de datos. Es decir, la frecuencia con la que la regla entera se cumple en todo el dataset.
La f√≥rmula correcta deber√≠a ser: Soporte(A‚ÜíB)=P(A‚à©B).

Explicaci√≥n en el contexto de reglas:
Usando el mismo ejemplo SI (compra Pan) ENTONCES (compra Leche).
Para calcular el soporte, contar√≠as:
El n√∫mero de transacciones donde se compra Pan Y Leche (esto es A‚à©B).
El n√∫mero total de transacciones en tu conjunto de datos.
El soporte ser√≠a:   Numero¬†total¬†de¬†transacciones 
                    Numero¬†de¬†transacciones¬†con¬†Pan¬†y¬†Leche
‚Äã
 
¬øQu√© mide? El soporte mide la frecuencia o la popularidad de la regla en el conjunto de datos. Un soporte alto indica que la combinaci√≥n de √≠tems en la regla (antecedente y consecuente juntos) aparece con mucha frecuencia en el dataset. Esto es crucial porque una regla con alta confianza pero bajo soporte podr√≠a ser estad√≠sticamente insignificante (se cumple muy bien, pero en muy pocos casos).

Importancia conjunta de Confianza y Soporte
La √∫ltima frase de la imagen es clave:

"Detectar aquellas reglas que, aunque se cumplen en alg√∫n caso y aunque puedan tener alta confianza, no son relevantes porque cubren casos poco frecuentes."

¬øPor qu√© ambos son necesarios?

Imagina una regla SI (compra oro y diamantes) ENTONCES (compra yate). Podr√≠a tener una confianza del 100% (cada vez que alguien compra oro y diamantes, tambi√©n compra un yate en tus datos). Sin embargo, si solo ha habido 2 transacciones en tu historial de miles donde alguien compr√≥ oro y diamantes, el soporte ser√≠a baj√≠simo. Esta regla es "confiable" pero no "relevante" porque se basa en una muestra min√∫scula y no representa un patr√≥n generalizado.

Por otro lado, una regla con alto soporte pero baja confianza tampoco es √∫til. Por ejemplo, SI (compra pan) ENTONCES (compra cualquier cosa). El soporte de "pan y cualquier cosa" podr√≠a ser alto, pero la confianza ser√≠a baja si comprar pan no lleva de forma consistente a comprar algo espec√≠fico.

Umbrales: En la miner√≠a de reglas de asociaci√≥n (como con el algoritmo Apriori), se suelen definir umbrales m√≠nimos de soporte y confianza para filtrar las reglas. Solo las reglas que superen ambos umbrales se consideran "interesantes" o "relevantes".


##  Que es el LIFT explicado con mis propias palabras 

- Es una tecnica que nos permite medir la relaci√≥n entre un atencedente y un consecuente usando probabilidad, permite validar nuestras reglas su nivel de confianza o relaci√≥n. 

**Validaci√≥n LIFT**
1. Si Lift=1: El hecho A es independiente del hecho B, quiere decir que no impacta la informaci√≥n nueva tanto un antecendente como una consecuencia no tiene un impacto en la regla generada, 

2. Si Lift>1: Existe correlaci√≥n positiva entre A y B. A y B tienden a ocurrir juntos. Es un caso de exito ya que es una relaci√≥n util por lo que el hecho A aumenta en mucho que suceda el hecho B. 

3. Si Lift<1: Existe correlaci√≥n negativa entre A y B. 
            A y B se comportan de forma opuesta, o A disminuye la probabilidad de B


## Algoritmo Apriori 
> Es una tecnica que podemos usar para generar reglas ya que genera conjuntos de item-set que podemos usar como un m√©todo de aprendizaje de reglas de asociaci√≥n.


El algoritmo Apriori es un m√©todo de dos pasos para encontrar patrones interesantes en los datos, espec√≠ficamente en forma de reglas de asociaci√≥n:

- Primero: Encuentra los conjuntos de √≠tems que aparecen juntos con suficiente frecuencia (fase de √≠tem-sets frecuentes o "miner√≠a de conjuntos frecuentes").

- Segundo: A partir de esos conjuntos frecuentes, deriva reglas de tipo "SI... ENTONCES..." que son suficientemente fiables y potencialmente interesantes (fase de generaci√≥n de reglas).

## Para que las usamos 
- Asociaciones entre art√≠culos de la cesta de la compra
- An√°lisis de sentimiento en texto
- Diagn√≥stico m√©dico a trav√©s de s√≠ntomas
- Conocer los h√°bitos de usuarios de un gran centro deportivo
- Asociaciones entre lugares visitados por turistas

## como hacemos esto Python 

# Pasos 

- Paso 1: 
> El algoritmo Apriori espera que los datos de entrada est√©n en un formato de codificaci√≥n One-Hot (tambi√©n conocido como formato "boolean sparse" o "dataframe disperso booleano"). Esto significa que cada columna representa un √≠tem √∫nico, y cada fila es una transacci√≥n.

- Paso 2: pip install mlxtend pandas

- Paso 3: An√°lisis Ejemplo 

Imagina que tienes una lista de listas, donde cada sublista representa una transacci√≥n y contiene los √≠tems comprados:

```Python
transactions = [
    ['leche', 'pan', 'mantequilla'],
    ['pan', 'mantequilla', 'cerveza', 'pa√±ales'],
    ['leche', 'pan', 'cerveza', 'coca-cola'],
    ['leche', 'mantequilla', 'coca-cola'],
    ['pan', 'cerveza', 'pa√±ales']
]
```

Transformar los datos a formato One-Hot

```Python

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder

# Tus datos de transacciones
transactions = [
    ['leche', 'pan', 'mantequilla'],
    ['pan', 'mantequilla', 'cerveza', 'pa√±ales'],
    ['leche', 'pan', 'cerveza', 'coca-cola'],
    ['leche', 'mantequilla', 'coca-cola'],
    ['pan', 'cerveza', 'pa√±ales']
]

# Inicializar y ajustar el TransactionEncoder
te = TransactionEncoder()
te_array = te.fit(transactions).transform(transactions)

# Convertir el array resultante en un DataFrame de pandas
df_encoded = pd.DataFrame(te_array, columns=te.columns_)

print("DataFrame en formato One-Hot:")
print(df_encoded)


Salida del df_encoded:

DataFrame en formato One-Hot:
      cerveza  coca-cola   leche  mantequilla    pan  pa√±ales
0     False      False    True         True   True    False
1      True      False   False         True   True     True
2      True       True    True        False   True    False
3     False       True    True         True  False    False
4      True      False   False        False   True     True

```
- Paso 3: Aplicar el algoritmo Apriori (Fase 1: Encontrar Itemsets Frecuentes)
> Ahora que los datos est√°n en el formato correcto, puedes usar la funci√≥n apriori de mlxtend. Necesitas especificar un min_support (soporte m√≠nimo) como umbral.
```Python

from mlxtend.frequent_patterns import apriori

# Aplicar el algoritmo Apriori
# min_support: el umbral de soporte m√≠nimo (ej. 0.5 significa que el itemset debe aparecer en al menos el 50% de las transacciones)
# use_colnames=True: para que el resultado use los nombres de los √≠tems en lugar de √≠ndices de columna
frequent_itemsets = apriori(df_encoded, min_support=0.5, use_colnames=True)

print("\nItemsets Frecuentes:")
print(frequent_itemsets)

Salida del frequent_itemsets:

Itemsets Frecuentes:
   support                 itemsets
0      0.6                 (cerveza)
1      0.6                   (leche)
2      0.6             (mantequilla)
3      0.8                     (pan)
4      0.6      (cerveza, pan)
5      0.6       (leche, mantequilla)

En este resultado:

support: Es el soporte del √≠tem-set (su frecuencia en las transacciones).
itemsets: Es el √≠tem-set en s√≠ (un frozenset de Python).
```

- Paso 4: Generar Reglas de Asociaci√≥n (Fase 2: Crear Reglas)
> Una vez que tienes los √≠tem-sets frecuentes, puedes usar la funci√≥n association_rules de mlxtend para generar las reglas de asociaci√≥n. Aqu√≠ necesitas especificar una m√©trica (por ejemplo, "confidence" o "lift") y un min_threshold (umbral m√≠nimo para esa m√©trica).

```Python
from mlxtend.frequent_patterns import association_rules

# Generar reglas de asociaci√≥n
# metric="confidence": Usaremos la confianza como m√©trica principal para filtrar reglas
# min_threshold=0.7: Solo reglas con una confianza del 70% o m√°s
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)

print("\nReglas de Asociaci√≥n (basadas en confianza):")
print(rules)

Salida de las rules (ejemplo):

Reglas de Asociaci√≥n (basadas en confianza):
  antecedents consequents  antecedent support  consequent support  support  confidence      lift  leverage  conviction
0   (cerveza)        (pan)                0.6                 0.8      0.6         1.0  1.250000       0.12        inf
1  (mantequilla)    (leche)                0.6                 0.6      0.6         1.0  1.666667       0.24        inf


Explicaci√≥n de las columnas en el DataFrame de reglas:

antecedents: Los √≠tems en el "SI" de la regla.
consequents: Los √≠tems en el "ENTONCES" de la regla.
antecedent support: El soporte del antecedente (frecuencia de los √≠tems en el "SI").
consequent support: El soporte del consecuente (frecuencia de los √≠tems en el "ENTONCES").
support: El soporte de la regla completa (A‚à©B).
confidence: La confianza de la regla (P(B‚à£A)).
lift: El Lift de la regla (correlaci√≥n).
leverage: Otra m√©trica que mide la diferencia entre la frecuencia observada de A y B juntos y la que se esperar√≠a si fueran independientes. Un valor de 0 indica independencia.
conviction: Otra m√©trica que compara la probabilidad de que A aparezca sin B, si A y B fueran independientes.
```

- Paso 5: Filtrar y ordenar reglas
> Puedes filtrar y ordenar las reglas para encontrar las m√°s interesantes. Por ejemplo, reglas con un alto lift (mayor que 1) y una alta confidence
```Python
# Filtrar reglas con lift > 1 y confianza > 0.8
strong_rules = rules[(rules['lift'] > 1) & (rules['confidence'] > 0.8)]

print("\nReglas de Asociaci√≥n Fuertes (Lift > 1, Confianza > 0.8):")
print(strong_rules.sort_values(by="lift", ascending=False))

```


# Tabla Comparativa de T√©cnicas de Preprocesamiento de Datos

| T√©cnica                                 | Concepto                                                                                                         | ¬øCu√°ndo usar?                                                                                                                                                                                                                                                                                                         | Ventajas                                                                                                  | Desventajas                                                                                                                                                                                                                                                                                                     |
| :-------------------------------------- | :--------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **I. T√©cnicas de Codificaci√≥n de Variables Categ√≥ricas** |                                                                                                                  |                                                                                                                                                                                                                                                                                                                       |                                                                                                           |                                                                                                                                                                                                                                                                                                                   |
| **1. Codificaci√≥n One-Hot** | Crea una nueva columna binaria (0 o 1) para cada categor√≠a √∫nica en la variable original.                       | Cuando las categor√≠as son **nominales** (sin orden) y el n√∫mero de categor√≠as no es excesivamente grande. Ideal para algoritmos que asumen independencia de caracter√≠sticas (ej., regresi√≥n lineal, SVM).                                                                                                              | Evita asumir un orden o relaci√≥n num√©rica artificial. F√°cil de entender. Compatible con la mayor√≠a de los algoritmos. | Puede generar un gran n√∫mero de columnas (alta dimensionalidad) si hay muchas categor√≠as. Aumenta la complejidad computacional y de almacenamiento. |
| **2. Codificaci√≥n Dummy** | Similar a One-Hot, pero crea `N-1` columnas para `N` categor√≠as. Una categor√≠a es la de referencia (inferida).  | Para evitar la **multicolinealidad perfecta** en modelos sensibles como la regresi√≥n lineal o log√≠stica, mientras se manejan categor√≠as nominales.                                                                                                                                                                      | Resuelve el problema de multicolinealidad. Mantiene las ventajas de One-Hot para categor√≠as nominales.   | A√∫n puede generar muchas columnas.                                                                                                                                                                                                                                                                    |
| **3. Codificaci√≥n Ordinal** | Asigna un n√∫mero entero a cada categor√≠a basado en un orden predefinido por el usuario.                         | Cuando las categor√≠as tienen un **orden intr√≠nseco o jerarqu√≠a** (variables ordinales).                                                                                                                                                                                                                               | Reduce la dimensionalidad a una sola columna. Mantiene la informaci√≥n del orden si es significativo.    | Si las categor√≠as no tienen un orden real, impone uno artificial que puede confundir al modelo (implicando distancias num√©ricas arbitrarias). |
| **4. LabelEncoder** | Asigna un valor num√©rico entero secuencial √∫nico a cada categor√≠a √∫nica en la variable. (Es una forma de Codificaci√≥n Ordinal arbitraria). | Principalmente para codificar la **variable objetivo (y)** en clasificaci√≥n. Tambi√©n para caracter√≠sticas (X) si el n√∫mero de categor√≠as es peque√±o y el algoritmo puede manejar el orden artificial (ej., √°rboles de decisi√≥n, Random Forest, GBT) o si hay un orden real. | Simple y f√°cil de usar. Reduce la dimensionalidad a una sola columna.                                     | Impone un orden num√©rico arbitrario a las categor√≠as, lo que puede ser problem√°tico para algoritmos que interpretan distancias (ej., K-NN, SVM, regresi√≥n lineal).                                                                                                                                     |
| **5. Codificaci√≥n por Frecuencia/Conteo** | Reemplaza cada categor√≠a con la frecuencia (o el conteo) de su aparici√≥n en el conjunto de datos.                  | Cuando la frecuencia de una categor√≠a es un predictor potencialmente importante para el modelo. Para variables categ√≥ricas con alta cardinalidad.                                                                                                                                                              | Reduce la dimensionalidad a una sola columna. Captura informaci√≥n sobre la popularidad de la categor√≠a.   | Categor√≠as con la misma frecuencia reciben el mismo valor, perdiendo su distinci√≥n. No es √∫til si la frecuencia no es relevante para la predicci√≥n. |
| **6. Codificaci√≥n por Media/Objetivo** | Reemplaza cada categor√≠a con la media de la variable objetivo (o alguna otra estad√≠stica) para esa categor√≠a.       | Para variables categ√≥ricas con **alta cardinalidad** en problemas de regresi√≥n o clasificaci√≥n.                                                                                                                                                                                                                       | Reduce la dimensionalidad dr√°sticamente. Captura informaci√≥n predictiva directamente de la variable objetivo. | Puede introducir *data leakage* (fuga de datos) si no se implementa cuidadosamente (usar solo datos de entrenamiento). Susceptible a *overfitting* en categor√≠as con pocos ejemplos. Necesita t√©cnicas de suavizado. |
| **7. Codificaci√≥n Hash** | Transforma categor√≠as en un espacio de dimensiones m√°s bajas usando una funci√≥n hash, mapeando a un √≠ndice fijo.     | Para variables con **cardinalidad muy alta** donde One-Hot no es factible. En escenarios donde la eficiencia computacional y de memoria son cr√≠ticas.                                                                                                                                                            | Dimensionalidad fija y controlable. No requiere almacenar el mapeo. Puede manejar categor√≠as nuevas.       | Posibilidad de **colisiones** (diferentes categor√≠as mapeadas al mismo √≠ndice), lo que puede reducir el rendimiento. No es reversible.                                                                                                                                              |
| **8. Codificaci√≥n Binaria** | Convierte categor√≠as a n√∫meros enteros, luego esos enteros a su representaci√≥n binaria, creando una columna para cada bit. | Cuando el n√∫mero de categor√≠as es grande, pero no tan extremo como para necesitar hashing, buscando un compromiso entre One-Hot y Ordinal.                                                                                                                                                                    | Reduce la dimensionalidad en comparaci√≥n con One-Hot.                                                     | Las nuevas columnas tienen una relaci√≥n artificial que el modelo debe aprender. Menos interpretable que One-Hot.                                                                                                                                                                    |
| **II. Otras T√©cnicas de Preprocesamiento de Datos Relevantes** |                                                                                                                  |                                                                                                                                                                                                                                                                                                                       |                                                                                                           |                                                                                                                                                                                                                                                                                                                   |
| **1. Escalado de Caracter√≠sticas** | Ajusta la escala de las caracter√≠sticas num√©ricas para que tengan un rango similar.                                | Para algoritmos sensibles a la escala de las caracter√≠sticas (ej., K-NN, SVM, redes neuronales, regresi√≥n, clustering basado en distancia).                                                                                                                                                                          | Mejora el rendimiento y la estabilidad de muchos algoritmos. Acelera la convergencia de algoritmos basados en gradientes. | Puede dificultar la interpretabilidad directa de las caracter√≠sticas originales.                                                                                                                                                                                                    |
| **2. Manejo de Valores Faltantes** | Rellena los valores ausentes (NaN) en el conjunto de datos.                                                    | Siempre que haya valores faltantes en el dataset, ya que la mayor√≠a de los algoritmos no pueden procesarlos directamente.                                                                                                                                                                                             | Permite usar el dataset completo sin eliminar filas o columnas.                                           | Una imputaci√≥n incorrecta puede introducir sesgos o distorsiones en los datos. La elecci√≥n del m√©todo de imputaci√≥n es crucial.                                                                                                                                              |
| **3. Discretizaci√≥n / Binning** | Convierte variables num√©ricas continuas en categor√≠as o "bins" (intervalos).                                      | Para algoritmos que prefieren datos categ√≥ricos o rangos (ej., algunas implementaciones de √°rboles de decisi√≥n, reglas de asociaci√≥n para datos num√©ricos). Para reducir el ruido en datos continuos.                                                                                                             | Puede mejorar la robustez a los outliers. Permite usar t√©cnicas de miner√≠a de reglas en datos continuos.   | P√©rdida de informaci√≥n detallada de la variable num√©rica. La elecci√≥n de los l√≠mites de los bins puede ser arbitrante o cr√≠tica.                                                                                                                                          |
| **4. Reducci√≥n de Dimensionalidad** | Reduce el n√∫mero de caracter√≠sticas (columnas), conservando la mayor cantidad de informaci√≥n posible.             | Cuando hay un n√∫mero excesivo de caracter√≠sticas (especialmente despu√©s de One-Hot Encoding), para combatir la "maldici√≥n de la dimensionalidad", reducir el tiempo de entrenamiento y mejorar el rendimiento.                                                                                                | Reduce la complejidad del modelo. Acelera el entrenamiento. Puede mejorar la interpretabilidad (si las componentes son claras). | Puede llevar a una p√©rdida de informaci√≥n (aunque se busca minimizarla). Las nuevas caracter√≠sticas (componentes) a menudo son menos interpretables que las originales.                                                                                                     |
| **5. Generaci√≥n de Caracter√≠sticas (Feature Engineering)** | Crea nuevas caracter√≠sticas a partir de las existentes que pueden ayudar al modelo a aprender patrones.                      | Siempre que se pueda extraer informaci√≥n adicional relevante de los datos brutos que no sea directamente evidente para el modelo.                                                                                                                                                                           | Puede mejorar significativamente el rendimiento del modelo. Aporta conocimiento de dominio al proceso.   | Requiere creatividad, conocimiento del dominio y a menudo es un proceso iterativo y que consume mucho tiempo. Puede introducir *overfitting* si no se valida bien.                                                                                                        |

Fundamentos de Machine Learning
1. Regresi√≥n Lineal con Python
üîó https://youtu.be/1CGbP0l0iqo?si=DZnQW4ClqyZaOJhJ
üìå Explicaci√≥n de la regresi√≥n lineal y su implementaci√≥n en Python.

2. Codificaci√≥n de Datos Categ√≥ricos
https://youtu.be/KUEsLv8EaVY?si=ER1EN3ZutSwN9kCx
üìå M√©todos para transformar variables categ√≥ricas en datos num√©ricos para modelos de ML.

3. Escalamiento, Normalizaci√≥n y Estandarizaci√≥n de Datos
https://youtu.be/-VuR14Qyl7E?si=sfjLg1Zg4rlXXn6q
üìå T√©cnicas para preparar datos antes de alimentar un modelo de aprendizaje autom√°tico.


Algoritmos de Aprendizaje Autom√°tico
4. Random Forest (Bosque Aleatorio
https://youtu.be/yOCJQLf_YFI?si=qj_tImJhBxBLxHI1
üìå Explicaci√≥n de este m√©todo de ensamblado basado en √°rboles de decisi√≥n.

5. Entrop√≠a en √Årboles de Decisi√≥n
https://youtu.be/GWX2YcnaELg?si=KrWBYM5uRI1EHKyk
üìå Concepto clave en la divisi√≥n de nodos dentro de √°rboles de decisi√≥n.

6. Impureza GINI en √Årboles de Decisi√≥n
https://youtu.be/PFn31_hzQ2Y?si=ZUOD5-ejUK3zICWB
üìå Otro criterio fundamental en la construcci√≥n de √°rboles de decisi√≥n.

Evaluaci√≥n y Optimizaci√≥n de Modelos
7. Matriz de Confusi√≥n: Precisi√≥n, Accuracy, Recall y F1-Score
https://youtu.be/uaGMk43XTOw?si=EdxWX8czQOzQpaQR
üìå C√≥mo evaluar el rendimiento de los modelos de clasificaci√≥n.

8. Curva ROC y AUC
https://youtu.be/Uyfcqn3Nidc?si=1ubow-pNmcaQlEB5
üìå An√°lisis de la capacidad discriminativa de un modelo de clasificaci√≥n.

9. Optimizaci√≥n de Modelos: Hiperpar√°metros
https://youtu.be/YAfS8-BXp8Q?si=wmuqpBY0sCIkGfqD
üìå T√©cnicas para mejorar el rendimiento de los modelos de ML mediante el ajuste de hiperpar√°metros.
