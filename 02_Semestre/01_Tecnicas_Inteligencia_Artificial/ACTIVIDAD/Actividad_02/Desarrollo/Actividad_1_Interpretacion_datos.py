import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,
                           ConfusionMatrixDisplay, precision_recall_fscore_support)
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de estilo para grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

def main():
    # PASO 0: IMPORTACIÃ“N DEL DATASET
    print("\nðŸŽ¯ Paso 0: ----------------- Importamos el DataSet VehÃ­culos :------------------ ðŸŽ¯")

    try:
        url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1jY1JAwakImo53OxBA0oiJTlAH9G5vi3d'
        df = pd.read_csv(url_descarga_directa, sep=';')
        print("âœ… Dataset cargado exitosamente")
    except Exception as e:
        print(f"âŒ Error al cargar el dataset: {e}")
        return

    # CaracterizaciÃ³n inicial del dataset
    print("\nðŸ“‹ Primeras 5 filas del dataset:")
    print(df.head())

    print("\nðŸ“‹ INFORMACIÃ“N DETALLADA:")
    print(df.info())

    # PASO 1: PREPROCESAMIENTO DE DATOS
    print("\nðŸŽ¯ Paso 1: ------------ Preprocesamiento de Datos ------------------------ ðŸŽ¯")

    df_encoded = df.copy()
    features = ['Buying', 'Maintenance', 'Doors', 'Person', 'lug_boot', 'safety']
    target = 'class'

    # Diccionario para almacenar los encoders
    encoders = {}

    # Aplicamos LabelEncoder a cada columna categÃ³rica
    for col in features + [target]:
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col])
        encoders[col] = le  # Guardamos el encoder para uso posterior
        print(f"ðŸ” Mapeo de {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}")

    print("\nðŸ“‹ Primeras 5 filas del dataset codificado:")
    print(df_encoded.head())

    # PASO 2: CARACTERIZACIÃ“N DEL DATASET
    print("\nðŸŽ¯ Paso 2: ------------ CaracterizaciÃ³n del Dataset ------------------------ ðŸŽ¯")

    print(f"\nðŸ“‹ NÃºmero total de instancias: {df_encoded.shape[0]}")
    print(f"ðŸ“‹ NÃºmero de atributos de entrada: {df_encoded.shape[1] - 1}")
    print(f"ðŸ“‹ Dataset VehÃ­culos con {df_encoded.shape[0]} filas y {df_encoded.shape[1]} columnas")

    # DescripciÃ³n mejorada de atributos
    column_desc = {
        "Buying": "Precio de compra del vehÃ­culo, clasificado en categorÃ­as como vhigh (muy alto), high (alto), med (medio) y low (bajo).",
        "Maintenance": "Costo de mantenimiento del vehÃ­culo, con la misma categorizaciÃ³n que buying.",
        "Doors": "NÃºmero de puertas del automÃ³vil, expresado en valores numÃ©ricos como '2', '3', '4', o '5more' (5 o mÃ¡s).",
        "Person": "Capacidad de ocupantes del automÃ³vil, con valores como '2', '4' y 'more' (mÃ¡s de 4).",
        "lug_boot": "TamaÃ±o del maletero, categorizado como small (pequeÃ±o), med (medio) o big (grande)",
        "safety": "Nivel de seguridad del automÃ³vil, clasificado como low (bajo), med (medio) o high (alto)"
    }

    print("\nðŸ“‹ DescripciÃ³n de atributos de entrada y su tipo:")
    for col in features:
        print(f"ðŸ” Atributo: {col}")
        print(f"   DescripciÃ³n: {column_desc[col]}")
        print(f"   Tipo: categÃ³rico")
        print(f"   Valores Ãºnicos: {sorted(df[col].unique())}")
        print()

    # InformaciÃ³n de la clase objetivo
    print("ðŸ“‹ InformaciÃ³n de la clase objetivo:")
    print(f"- Columna de clase: '{target}'")
    print(f"- NÃºmero de clases: {df_encoded[target].nunique()}")

    print("\nðŸ“‹ DistribuciÃ³n de las clases:")
    class_counts = df[target].value_counts()
    class_percentages = (class_counts / len(df) * 100).round(2)

    for clase, count in class_counts.items():
        percentage = class_percentages[clase]
        print(f"   {clase}: {count} instancias ({percentage}%)")

    # Verificar valores nulos
    print("\nðŸ“‹ Valores nulos por columna:")
    null_counts = df_encoded.isnull().sum()
    if null_counts.sum() == 0:
        print("âœ… No hay valores nulos en el dataset")
    else:
        print(null_counts)

    print("\nðŸ“‹ ESTADÃSTICAS DESCRIPTIVAS:")
    print(df_encoded.describe(include='all'))


    # PASO 3: VISUALIZACIÃ“N DE DATOS
    print("\nðŸŽ¯ Paso 3: ------------ DescripciÃ³n GrÃ¡fica datos originales ------------------------ ðŸŽ¯")

    # Crear figura con subplots mejorados
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('AnÃ¡lisis Exploratorio del Dataset de VehÃ­culos', fontsize=16, fontweight='bold')

    # DistribuciÃ³n de la clase objetivo
    sns.countplot(data=df, x=target, ax=axes[0, 0])
    axes[0, 0].set_title('DistribuciÃ³n de Clases de Aceptabilidad')
    axes[0, 0].set_xlabel('Clase')
    axes[0, 0].set_ylabel('Conteo')
    axes[0, 0].tick_params(axis='x', rotation=45)

    # Distribuciones de caracterÃ­sticas
    characteristics = ['Buying', 'Maintenance', 'Doors', 'safety', 'lug_boot']

    for i, char in enumerate(characteristics):
        row = (i + 1) // 3
        col = (i + 1) % 3
        sns.countplot(data=df, x=char, ax=axes[row, col])
        axes[row, col].set_title(f'DistribuciÃ³n de {char}')
        axes[row, col].tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

    # PASO 4: PREPARACIÃ“N PARA MODELADO
    print("\nðŸŽ¯ Paso 4: ------------ PreparaciÃ³n del dataset para modelado ------------------------ ðŸŽ¯")

    # Definir caracterÃ­sticas y variable objetivo
    X = df_encoded[features]
    y = df_encoded[target]

    # DivisiÃ³n del dataset con validaciÃ³n
    X_train, X_test, y_train, y_test = train_test_split(
        X,      #   CaracterÃ­sticas de entrada
        y,      #   Variable objetivo
        test_size=0.3,      # 30% para prueba
        random_state=42,    # Para reproducibilidad
        stratify=y          # Mantener proporciÃ³n de clases
    )

    print("ðŸ“‹ DivisiÃ³n del dataset completada:")
    print(f"âœ… Dimensiones de X_train: {X_train.shape}")
    print(f"âœ… Dimensiones de X_test: {X_test.shape}")
    print(f"âœ… ProporciÃ³n de entrenamiento: {X_train.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}")
    print(f"âœ… ProporciÃ³n de prueba: {X_test.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}")


    # PASO 5: ENTRENAMIENTO DE MODELOS
    print("\nðŸŽ¯ Paso 5: ------------ Entrenamiento de Modelos ------------------------ ðŸŽ¯")

    # Decision Tree con parÃ¡metros optimizados
    print("ðŸŒ³ Entrenando Arbol de DecisiÃ³n...")
    dt_model = DecisionTreeClassifier(
        random_state=42,         # Semilla para reproducibilidad
        max_depth=10,            # Profundidad mÃ¡xima del Ã¡rbol
        min_samples_split=5,     # MÃ­nimo de muestras para dividir un nodo
        min_samples_leaf=2,      # MÃ­nimo de muestras en una hoja
        criterion='gini'         # Criterio de divisiÃ³n
    )
    dt_model.fit(X_train, y_train)
    y_pred_dt = dt_model.predict(X_test)

    # Random Forest
    print("ðŸŒ² Entrenando Bosque Aleatorio...")
    rf_model = RandomForestClassifier(
        n_estimators=100,    # NÃºmero de Ã¡rboles en el bosque
        random_state=42,     # Semilla para reproducibilidad
        max_depth=10,        # Profundidad mÃ¡xima de los Ã¡rboles
        min_samples_split=5, # MÃ­nimo de muestras para dividir un nodo
        min_samples_leaf=2   # MÃ­nimo de muestras en una hoja
    )
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)


    # PASO 6: EVALUACIÃ“N DE MODELOS
    print("\nðŸŽ¯ Paso 6: ------------ EvaluaciÃ³n de Modelos ------------------------ ðŸŽ¯")

    # FunciÃ³n para evaluar modelo
    def evaluate_model(y_true, y_pred, model_name, encoder):
        """FunciÃ³n para evaluar un modelo de clasificaciÃ³n"""
        print(f"\nðŸ§  ------- EvaluaciÃ³n del Modelo {model_name} -------")

        # efectividad
        efectividad = accuracy_score(y_true, y_pred)
        print(f"ðŸŽ¯ Efectividad: {efectividad:.4f} ({efectividad*100:.2f}%)")


        # Instancias correctas e incorrectas
        correct = int(efectividad * len(y_true))
        incorrect = len(y_true) - correct
        print(f"âœ… Instancias clasificadas correctamente: {correct}")
        print(f"âŒ Instancias clasificadas incorrectamente: {incorrect}")

        # Matriz de confusiÃ³n
        cm = confusion_matrix(y_true, y_pred)
        print(f"\nðŸ“Š Matriz de ConfusiÃ³n:")
        print(cm)

        # Reporte de clasificaciÃ³n
        class_names = encoder.inverse_transform(sorted(np.unique(y_true)))
        print(f"\nðŸ“ˆ Reporte de ClasificaciÃ³n:")
        print(classification_report(y_true, y_pred, target_names=class_names))

        return efectividad, cm, class_names

    # Evaluar ambos modelos
    target_encoder = encoders[target]

    dt_efectividad, dt_cm, class_names = evaluate_model(y_test, y_pred_dt, "Ãrbol decisiÃ³n", target_encoder)
    rf_efectividad, rf_cm, class_names = evaluate_model(y_test, y_pred_rf, "Bosque Aleatorio", target_encoder)


    # PASO 7: COMPARACIÃ“N Y VISUALIZACIÃ“N DE RESULTADOS
    print("\nðŸŽ¯ Paso 7: ------------ ComparaciÃ³n de Resultados ------------------------ ðŸŽ¯")

    # ComparaciÃ³n de accuracies
    models = ['Ãrbol decisiÃ³n', 'Bosque Aleatorio']
    accuracies = [dt_efectividad, rf_efectividad]

    # GrÃ¡fico de comparaciÃ³n
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # ComparaciÃ³n de efectividad
    bars = axes[0].bar(models, accuracies, color=['skyblue', 'red'])
    axes[0].set_title('ComparaciÃ³n de efectividad entre Modelos', fontweight='bold')
    axes[0].set_ylabel('efectividad')
    axes[0].set_ylim(0, 1)

    # Agregar valores en las barras
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

    # Matrices de confusiÃ³n
    sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],
                xticklabels=class_names, yticklabels=class_names)
    axes[1].set_title('Matriz de ConfusiÃ³n: Ãrbol decisiÃ³n', fontweight='bold')
    axes[1].set_xlabel('Predicho')
    axes[1].set_ylabel('Real')

    sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Reds', ax=axes[2],
                xticklabels=class_names, yticklabels=class_names)
    axes[2].set_title('Matriz de ConfusiÃ³n: Bosque Aleatorio', fontweight='bold')
    axes[2].set_xlabel('Predicho')
    axes[2].set_ylabel('Real')

    plt.tight_layout()
    plt.show()

    # Resumen final
    print("\nðŸ† RESUMEN FINAL:")
    print("=" * 50)
    print(f"ðŸŒ³ Ãrbol decisiÃ³n - efectividad: {dt_efectividad:.4f} ({dt_efectividad*100:.2f}%)")
    print(f"ðŸŒ² Bosque Aleatorio - efectividad: {rf_efectividad:.4f} ({rf_efectividad*100:.2f}%)")

    best_model = "Bosque Aleatorio" if rf_efectividad > dt_efectividad else "Ãrbol decisiÃ³n"
    best_efectividad = max(rf_efectividad, dt_efectividad)
    print(f"\nðŸ¥‡ Mejor modelo: {best_model} con {best_efectividad:.4f} de efectividad")

    # Importancia de caracterÃ­sticas para Bosque Aleatorio
    if rf_efectividad >= dt_efectividad:
        print(f"\nðŸ“Š Importancia de caracterÃ­sticas ({best_model}):")
        feature_importance = pd.DataFrame({
            'feature': features,
            'importance': rf_model.feature_importances_
        }).sort_values('importance', ascending=False)

        for _, row in feature_importance.iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")

if __name__ == "__main__":
    main()
