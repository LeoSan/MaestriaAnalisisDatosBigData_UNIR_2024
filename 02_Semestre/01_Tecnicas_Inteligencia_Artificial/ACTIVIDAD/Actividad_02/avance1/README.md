# Pasos para la actividad Avance Version 1 

## Configuracion 
- Creamos nuestro entorno  con el siguiente comandi ¬¥python3 -m venv <nombre>¬¥
- luego activamos ¬¥source ./nombreEntorno/bin/activate¬¥
- Instalamos librerias 
    - pip install pandas
    - pip install seabron
    - pip install scikit-learn
    - pip install tensorflow 


## Iniciamos avance 
    - Buscamos un dataset para aplicar los conocimientos 
    - creamos un archivo llamado main.py que contendra el script 
    - activamos entorno asi -> ¬¥source ./avance2/bin/activate¬¥
    - Ejecutamos as√≠ ¬¥python3 main.py¬¥ estando en el directorio -> ~/Documents/Dev/python/maestria

# Parte  1 Descripci√≥n del Dataset

- Nombre del Dataset: 'LifeExpectancyData.csv'.
- Fuente: Se extrajo el dataset de la plataforma Kaggle cuyo enlace publico se consigue en el siguiente enlace p√∫blico  'https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who/suggestions'

- Hip√≥tesis: Se desea predecir la esperanza de vida de M√©xico usando un dataset con informaci√≥n de otros pa√≠ses para el 2030. 

- Contexto: Se tomaran las siguientes variables para validar la hipotesis y aplicar el conocimiento adquirido durante las clases las variables son: 

    - Adult Mortality (Mortalidad Adulta): Es una de las variables m√°s directamente relacionadas con la esperanza de vida Menor mortalidad adulta deber√≠a implicar mayor esperanza de vida.

    - infant deaths (Muertes Infantiles): Similar a la mortalidad adulta, una reducci√≥n en las muertes infantiles contribuye directamente al aumento de la esperanza de vida de una poblaci√≥n.

    - Schooling (Escolaridad): Un mayor nivel de escolaridad suele correlacionarse con una mayor conciencia sobre la salud, mejores trabajos, ingresos y acceso a atenci√≥n m√©dica, lo que se traduce en mayor esperanza de vida. 

    - GDP (Producto Interno Bruto): Representa la salud econ√≥mica de un pa√≠s. Un PIB m√°s alto generalmente implica mejores infraestructuras de salud, nutrici√≥n y condiciones de vida.

    - HIV/AIDS (VIH/SIDA): La prevalencia de enfermedades cr√≥nicas y pandemias tiene un impacto directo y negativo en la esperanza de vida. Esta variable captura un aspecto importante de la salud p√∫blica.

    - Income composition of resources (Composici√≥n de los recursos de ingresos): Esta variable suele ser un √≠ndice que combina GNI per c√°pita, a√±os de escolaridad y esperanza de vida. tomamos esta variables como un buen indicador compuesto del desarrollo humano y es probable que tenga una fuerte correlaci√≥n con la esperanza de vida.

    - Year: Por ultima variables pero no menos importante el a√±o esto nos ayudar√° en establecer la predicci√≥n para a√±os a futuros. 

    - Country (Pais): El total de paises que se realiz√≥ el estudio previo. 

    - Status: 

- Variables Clave: (Life expectancy) consideramos esta variable num√©rica continua y es el objetivo de la predicci√≥n, lo que la hace la variable de salida perfecta para un problema de regresi√≥n y nos apoya para resolver la problem√°tica de estudio.
 
- T√©cnicas de Preprocesamiento de Datos: Usaremos 'Codificaci√≥n One-Hot'
Porque validando las variables nos encontramos con categiorias nominales y el n√∫mero de categorias no es muy grande y el OneHotEncoder para las variables categ√≥ricas, que es lo m√°s adecuado para este caso, y c√≥mo manejar las variables num√©ricas sin aplicarles codificaci√≥n inapropiada.Consideramos que el dataset LifeExpectancyData.csv las variables que t√≠picamente ser√≠an categ√≥ricas y se beneficiar√≠an del One-Hot Encoding son 'Country' y 'Status'. Las dem√°s variables que se mencionan como ('Adult Mortality', 'infant deaths', 'Schooling', 'GDP', 'HIV/AIDS', 'Income composition of resources', 'Year', y 'Life expectancy') son num√©ricas y deben tratarse como tal, posiblemente con escalado si es necesario para el modelo, pero no con codificaci√≥n que altere su significado num√©rico.

## Variables clave que vamos a caracterizar:

- Variable Objetivo (Target): life_expectancy

- Variables Num√©ricas (Features): adult_mortality, infant_deaths, alcohol, percentage_expenditure, hepatitis_b, measles, bmi, under_five_deaths, polio, total_expenditure, diphtheria, hiv/aids, gdp, population, thinness__1_19_years, thinness_5_9_years, income_composition_of_resources, schooling, year.

- Variables Categ√≥ricas (Features): country, status

## Definici√≥n de Graficas 
Se discuci√≥n con el equipo y se us√≥ las siguientes graficas por su amplia demostraci√≥n de los datos: 

a) Histogramas para Variables Num√©ricas:
Muestran la distribuci√≥n de una sola variable. Nos ayud√≥ a ver si la distribuci√≥n es normal, sesgada, bimodal, Para life_expectancy entre otras caracter√≠sticas num√©ricas importantes: GDP, Schooling, Adult Mortality, HIV/AIDS, etc.

b) Diagramas de Dispersi√≥n (Scatter Plots) para Relaciones  Num√©ricas:
Nos mostr√≥ la visualizaci√≥n y la relaci√≥n entre dos variables num√©ricas. fue excelente ya que nos permiti√≥ identificar correlaciones, tendencias y posibles valores at√≠picos.

Comparaci√≥n 
- life_expectancy vs. GDP: ¬øMayor PIB significa mayor esperanza de vida?
- life_expectancy vs. Schooling: ¬øM√°s a√±os de escolaridad se relacionan con mayor esperanza de vida?
- life_expectancy vs. Adult Mortality: ¬øMayor mortalidad adulta se relaciona con menor esperanza de vida? (esperar√≠amos una correlaci√≥n negativa).
- life_expectancy vs. HIV/AIDS: ¬øRelaci√≥n con la prevalencia de VIH/SIDA?

c) Diagramas de Cajas y Bigotes (Box Plots):
Nos permiti√≥ visualizar la distribuci√≥n de una variable num√©rica en funci√≥n de una variable categ√≥rica. Muestra la mediana, los cuartiles y la presencia de valores at√≠picos.

Comparaci√≥n 
- life_expectancy por Status (Developing/Developed): ¬øHay diferencias claras en la esperanza de vida entre pa√≠ses desarrollados y en desarrollo?

d) Mapa de Calor de Correlaci√≥n (Heatmap):
Nos permiti√≥ ver la representaci√≥n visual de la matriz de correlaci√≥n, haciendo que sea muy f√°cil identificar relaciones fuertes (positivas o negativas) en un par de vistazos.

Consideramos estas como las mas utiles y faciles de comprender y de desarrollar, sabemos que existe una gran variedad de graficas y de extender mas la comprensi√≥n de la data, debemos nosotros como futuros analistas ampliar nuestra experiencia y adquirir mas criterios de analisis y de curiosidad para mejorar en este mundo de la big data. 

## Modelo de Regresi√≥n No Neuronal:

Para este caso usaremos el random forest regression por ser muy robusto y vers√°til para tareas de regresi√≥n, tomando en cuenta sus ventajas muy claras como **Alta Precisi√≥n**, Tiende a producir resultados muy precisos, especialmente en datasets complejos con relaciones no lineales. **Manejo de Multicolinealidad**  nos permite tener menos sensibilidad a la multicolinealidad entre caracter√≠sticas en comparaci√≥n con la regresi√≥n lineal, **Robustez a Outliers** es bastante robusto a los valores at√≠picos (outliers) y al ruido en los datos, **Manejo de Datos Faltantes** lo bueno de esta ventaja es que si tenemos una gesti√≥n para datos imputados, los √°rboles de decisi√≥n que componen el **Random Forest** pueden manejar bien algunos tipos de datos con patrones de valores faltantes, aunque ya los estemos imputamos, es una ventaja general del m√©todo. 




import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de estilo para gr√°ficos
plt.style.use('default')
sns.set_palette("husl")

def main():
    # PASO 0: IMPORTACI√ìN DEL DATASET
    print("\nüéØ Paso 0: ----------------- Importamos el DataSet de Esperanza de Vida:------------------ üéØ")
    
    try:
        # URL de descarga directa para LifeExpectancyData.csv
        url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1EFa-JqAtrXtL1BrYP_mfxFVgAsADd_jn'
        df = pd.read_csv(url_descarga_directa, sep=',')
        print("‚úÖ Dataset cargado exitosamente")
        print("\nüìã Depurando: DF despu√©s de pd.read_csv - Forma:", df.shape)
        print("üìã Depurando: DF despu√©s de pd.read_csv - Columnas (primeras 5):", df.columns.tolist()[:20], "...")
    except Exception as e:
        print(f"‚ùå Error al cargar el dataset: {e}")
        return

    # PASO 1: PREPROCESAMIENTO DE DATOS (Incluyendo imputaci√≥n)
    print("\nüéØ Paso 1: ------------ Preprocesamiento de Datos (para caracterizaci√≥n) ------------------------ üéØ")
    # Limpiamos los nombres de las columnas
	df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace('.', '', regex=False).str.lower()    

    # Identificamos columnas categ√≥ricas y num√©ricas
    # Incluimos todas las num√©ricas relevantes, incluyendo 'life_expectancy' para la caracterizaci√≥n
    numerical_cols_for_eda = [
        'life_expectancy', 'adult_mortality', 'infant_deaths', 'alcohol', 
        'percentage_expenditure', 'hepatitis_b', 'measles', 'bmi', 
        'under_five_deaths', 'polio', 'total_expenditure', 'diphtheria', 
        'hiv/aids', 'gdp', 'population', 'thinness__1_19_years', 
        'thinness_5_9_years', 'income_composition_of_resources', 'schooling', 'year'
    ]
    categorical_cols_for_eda = ['country', 'status']

    # Imputamos los valores faltantes para poder realizar la caracterizaci√≥n
    imputer_numerical = SimpleImputer(strategy='mean')
    imputer_categorical = SimpleImputer(strategy='most_frequent')

    for col in numerical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna num√©rica para EDA: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]])

    for col in categorical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categ√≥rica para EDA: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]])

    print("\nüìã Depurando: Primeras 5 filas del dataset despu√©s de limpieza de columnas:")
    print(df.head())

    print("\nüìã Depurando: INFORMACI√ìN DETALLADA DESPU√âS DE LIMPIEZA DE COLUMNAS:")
    print(df.info())    

    print("\nüìã Depurando: Nombres de columnas despu√©s de la limpieza:")
    print(df.columns.tolist())
    print("\nüìã Depurando: Forma del DataFrame despu√©s de la limpieza:", df.shape)

    # --- INICIO: APARTADO A - CARACTERIZACI√ìN DEL DATASET ---
    print("\nüéØ Paso 2: ------------ Gr√°ficas ------------------------ üéØ")
    print("\nüéØ Apartado A: ------------ Caracterizaci√≥n del Dataset ------------------------ üéØ")

    # 1. Iniciamos Caracterizaci√≥n en Modo Texto
    print("\n--- 1.1: Estad√≠sticas Descriptivas de Variables Num√©ricas ---")
    print(df[numerical_cols_for_eda].describe().round(2))

    print("\n--- 1.2: Estad√≠sticas Descriptivas de Variables Categ√≥ricas ---")
    print(df[categorical_cols_for_eda].describe())

    print("\n--- 1.3: Conteo de Valores √önicos para 'Status' ---")
    print(df['status'].value_counts())
    print(f"\nN√∫mero total de pa√≠ses √∫nicos: {df['country'].nunique()}")

    print("\n--- 1.4: Matriz de Correlaci√≥n (primeras 5x5 columnas) ---")
    # Se muestra el valor de las correlaciones con la variable objetivo o un subconjunto relevante
    correlation_matrix = df[numerical_cols_for_eda].corr()
    print(correlation_matrix.head(5).iloc[:, :5].round(2)) # Muestra solo un subconjunto para no saturar la memoria

    # Se muestra la correlaci√≥n de todas las features con 'life_expectancy'
    print("\n--- 1.5: Correlaci√≥n de Features Num√©ricas con 'life_expectancy' ---")
    print(correlation_matrix['life_expectancy'].sort_values(ascending=False).round(2))

    # 2. Inicia Caracterizaci√≥n Gr√°fica
    print("\n--- 2.1: Histogramas para variables clave ---")
    plt.figure(figsize=(15, 10))
    
    plt.subplot(2, 2, 1)
    sns.histplot(df['life_expectancy'], kde=True)
    plt.title('Distribuci√≥n de la Esperanza de Vida')
    plt.xlabel('Esperanza de Vida')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 2)
    sns.histplot(df['gdp'], kde=True)
    plt.title('Distribuci√≥n del PIB')
    plt.xlabel('PIB')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 3)
    sns.histplot(df['schooling'], kde=True)
    plt.title('Distribuci√≥n de A√±os de Escolaridad')
    plt.xlabel('A√±os de Escolaridad')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 4)
    sns.histplot(df['adult_mortality'], kde=True)
    plt.title('Distribuci√≥n de Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Frecuencia')
    
    plt.tight_layout()
    plt.show()

    print("\n--- 2.2: Diagramas de Dispersi√≥n (Scatter Plots) con Esperanza de Vida ---")
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    sns.scatterplot(x='gdp', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. PIB')
    plt.xlabel('PIB')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 2)
    sns.scatterplot(x='schooling', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Escolaridad')
    plt.xlabel('A√±os de Escolaridad')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 3)
    sns.scatterplot(x='adult_mortality', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 4)
    sns.scatterplot(x='hiv/aids', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. HIV/AIDS')
    plt.xlabel('Prevalencia HIV/AIDS')
    plt.ylabel('Esperanza de Vida')

    plt.tight_layout()
    plt.show()

    print("\n--- 2.3: Diagrama de Cajas y Bigotes para Esperanza de Vida por Status ---")
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='status', y='life_expectancy', data=df)
    plt.title('Esperanza de Vida por Estado de Desarrollo del Pa√≠s')
    plt.xlabel('Estado del Pa√≠s')
    plt.ylabel('Esperanza de Vida')
    plt.show()

    print("\n--- 2.4: Mapa de Calor de Correlaci√≥n ---")
    plt.figure(figsize=(12, 10))
    # Selecciona un subconjunto de columnas si el heatmap es demasiado grande
    cols_for_heatmap = ['life_expectancy', 'adult_mortality', 'infant_deaths', 'gdp', 'schooling', 
                        'hiv/aids', 'income_composition_of_resources', 'bmi', 'alcohol']
    sns.heatmap(df[cols_for_heatmap].corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Mapa de Calor de Correlaci√≥n de Caracter√≠sticas Seleccionadas')
    plt.show()

    print("\nüéØ Paso 3: ------------ Aplicacando T√©cnica de Preprocesamiento de Datos Usaremos 'Codificaci√≥n One-Hot ------------------------ üéØ")

    # Identificamos las columnas categ√≥ricas y num√©ricas para nuestro estudio 
    categorical_features = ['country', 'status']
    numerical_features = ['adult_mortality', 'infant_deaths', 'schooling', 'gdp', 'hiv/aids', 'income_composition_of_resources', 'year'] 
    
    # Validamos que las columnas existen en el DataFrame
    print("\nüìã Depurando: Verificando existencia de columnas para preprocesamiento:")
    for col_list_name, col_list in [("Categorical Features", categorical_features), ("Numerical Features", numerical_features)]:
        missing_cols = [col for col in col_list if col not in df.columns]
        if missing_cols:
            print(f"‚ùå Faltan columnas en {col_list_name}: {missing_cols}")
            print(f"üìã Columnas disponibles: {df.columns.tolist()}")
            return  # Salir si faltan columnas cr√≠ticas
        else:
            print(f"‚úÖ Todas las columnas en {col_list_name} existen en el DataFrame.")

    for col in numerical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna num√©rica: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]]).flatten()

    for col in categorical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categ√≥rica: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]]).flatten()
    
    # Definir la variable objetivo
    target_column = 'life_expectancy' 
    
    # Aplicamos transformaci√≥n OneHotEncoder    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ],
        remainder='drop',
        sparse_threshold=0  # Esto fuerza la salida a ser un array denso
    )

    print("\nüìã Depurando: Antes de aplicar ColumnTransformer:")
    print("Columnas que se pasar√°n al OneHotEncoder:", categorical_features)
    print("Columnas que se pasar√°n como num√©ricas (passthrough):", numerical_features)
    print("Forma del DataFrame df antes de ColumnTransformer.fit_transform:", df.shape)
    
    # Verificar que las columnas categ√≥ricas tienen datos
    for col in categorical_features:
        print(f"üìã Depurando: Valores √∫nicos en {col}: {df[col].nunique()}")
        print(f"üìã Depurando: Primeros 3 valores √∫nicos en {col}: {df[col].unique()[:3]}")

    # Aplicar las transformaciones al DataFrame
    df_processed_array = preprocessor.fit_transform(df)

    print("\nüìã Depurando: Despu√©s de aplicar ColumnTransformer:")
    print("Forma de df_processed_array:", df_processed_array.shape)
    print("Tipo de df_processed_array:", type(df_processed_array))

    #Verificamos si es un array sparse y convertirlo
    if hasattr(df_processed_array, 'toarray'):
        df_processed_array = df_processed_array.toarray()
        print("üìã Depurando: Convertido de sparse a array denso")
        print("üìã Depurando: Nueva forma despu√©s de toarray():", df_processed_array.shape)

    # Obtener los nombres de las nuevas columnas
    try:
        one_hot_features_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
        all_feature_names = list(one_hot_features_names) + numerical_features
        
        print("üìã Depurando: N√∫mero de columnas One-Hot generadas:", len(one_hot_features_names))
        print("üìã Depurando: N√∫mero total de columnas esperadas:", len(all_feature_names))
        print("üìã Depurando: Forma final del array procesado:", df_processed_array.shape)
        
        # Verificamos coherencia de dimensiones
        if df_processed_array.shape[1] != len(all_feature_names):
            print(f"‚ùå ERROR: Dimensiones no coinciden!")
            print(f"   Array tiene {df_processed_array.shape[1]} columnas")
            print(f"   Nombres de columnas: {len(all_feature_names)}")
            return
        
        # Creamos el DataFrame final
        df_encoded = pd.DataFrame(df_processed_array, columns=all_feature_names)
        
        print("\n‚úÖ DataFrame codificado creado exitosamente!")
        print("üìã Primeras 5 filas del dataset codificado con One-Hot Encoding:")
        print(df_encoded.head())
        print(f"\nüìã Dimensiones del nuevo DataFrame codificado: {df_encoded.shape}")
        
    except Exception as e:
        print(f"‚ùå Error al crear los nombres de columnas o el DataFrame: {e}")
        print("üìã Depurando: Intentando diagn√≥stico adicional...")
        print("üìã Transformadores disponibles:", list(preprocessor.named_transformers_.keys()))
        return

    #Anexamos la variable objetivo en el DataFrame final
    if target_column in df.columns:
        df_final = pd.concat([df_encoded, df[target_column].reset_index(drop=True)], axis=1)
        print("\nüìã DataFrame final con variable objetivo creado:")
        print(f"   Dimensiones: {df_final.shape}")
    else:
        print(f"\nAdvertencia: La columna objetivo '{target_column}' no se encontr√≥ en el DataFrame original.")
        df_final = df_encoded

if __name__ == "__main__":
    main()



