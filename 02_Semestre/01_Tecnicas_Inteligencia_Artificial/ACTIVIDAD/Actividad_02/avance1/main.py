import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de estilo para grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

def main():
    # PASO 0: IMPORTACIÃ“N DEL DATASET
    print("\nğŸ¯ Paso 0: ----------------- Importamos el DataSet de Esperanza de Vida:------------------ ğŸ¯")
    
    try:
        # URL de descarga directa para LifeExpectancyData.csv
        url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1EFa-JqAtrXtL1BrYP_mfxFVgAsADd_jn'
        df = pd.read_csv(url_descarga_directa, sep=',')
        print("âœ… Dataset cargado exitosamente")
        print("\nğŸ“‹ Depurando: DF despuÃ©s de pd.read_csv - Forma:", df.shape)
        print("ğŸ“‹ Depurando: DF despuÃ©s de pd.read_csv - Columnas (primeras 5):", df.columns.tolist()[:20], "...")
    except Exception as e:
        print(f"âŒ Error al cargar el dataset: {e}")
        return
    
    # PASO 1: PREPROCESAMIENTO DE DATOS
    print("\nğŸ¯ Paso 1: ------------ Preprocesamiento de Datos ------------------------ ğŸ¯")
    # Limpiamos los nombres de las columnas
    df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace('.', '', regex=False).str.lower()

    print("\nğŸ“‹ Primeras 5 filas del dataset despuÃ©s de limpieza de columnas:")
    print(df.head())

    print("\nğŸ“‹ INFORMACIÃ“N DETALLADA DESPUÃ‰S DE LIMPIEZA DE COLUMNAS:")
    print(df.info())    

    print("\nğŸ“‹ Depurando: Nombres de columnas despuÃ©s de la limpieza:")
    print(df.columns.tolist())
    print("\nğŸ“‹ Depurando: Forma del DataFrame despuÃ©s de la limpieza:", df.shape)

    # Identificamos las columnas categÃ³ricas y numÃ©ricas
    categorical_features = ['country', 'status']
    numerical_features = ['adult_mortality', 'infant_deaths', 'schooling', 'gdp', 'hiv/aids', 'income_composition_of_resources', 'year'] 
    
    # Validamos que las columnas existen en el DataFrame
    print("\nğŸ“‹ Depurando: Verificando existencia de columnas para preprocesamiento:")
    for col_list_name, col_list in [("Categorical Features", categorical_features), ("Numerical Features", numerical_features)]:
        missing_cols = [col for col in col_list if col not in df.columns]
        if missing_cols:
            print(f"âŒ Faltan columnas en {col_list_name}: {missing_cols}")
            print(f"ğŸ“‹ Columnas disponibles: {df.columns.tolist()}")
            return  # Salir si faltan columnas crÃ­ticas
        else:
            print(f"âœ… Todas las columnas en {col_list_name} existen en el DataFrame.")

    # Paso 1.1: ImputaciÃ³n de valores faltantes
    imputer_numerical = SimpleImputer(strategy='mean')
    imputer_categorical = SimpleImputer(strategy='most_frequent')

    for col in numerical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna numÃ©rica: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]]).flatten()

    for col in categorical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categÃ³rica: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]]).flatten()
    
    # Definir la variable objetivo
    target_column = 'life_expectancy' 
    
    # Aplicamos transformaciÃ³n OneHotEncoder    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ],
        remainder='drop',
        sparse_threshold=0  # Esto fuerza la salida a ser un array denso
    )

    print("\nğŸ“‹ Depurando: Antes de aplicar ColumnTransformer:")
    print("Columnas que se pasarÃ¡n al OneHotEncoder:", categorical_features)
    print("Columnas que se pasarÃ¡n como numÃ©ricas (passthrough):", numerical_features)
    print("Forma del DataFrame df antes de ColumnTransformer.fit_transform:", df.shape)
    
    # Verificar que las columnas categÃ³ricas tienen datos
    for col in categorical_features:
        print(f"ğŸ“‹ Depurando: Valores Ãºnicos en {col}: {df[col].nunique()}")
        print(f"ğŸ“‹ Depurando: Primeros 3 valores Ãºnicos en {col}: {df[col].unique()[:3]}")

    # Aplicar las transformaciones al DataFrame
    df_processed_array = preprocessor.fit_transform(df)

    print("\nğŸ“‹ Depurando: DespuÃ©s de aplicar ColumnTransformer:")
    print("Forma de df_processed_array:", df_processed_array.shape)
    print("Tipo de df_processed_array:", type(df_processed_array))

    #Verificamos si es un array sparse y convertirlo
    if hasattr(df_processed_array, 'toarray'):
        df_processed_array = df_processed_array.toarray()
        print("ğŸ“‹ Depurando: Convertido de sparse a array denso")
        print("ğŸ“‹ Depurando: Nueva forma despuÃ©s de toarray():", df_processed_array.shape)

    # Obtener los nombres de las nuevas columnas
    try:
        one_hot_features_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
        all_feature_names = list(one_hot_features_names) + numerical_features
        
        print("ğŸ“‹ Depurando: NÃºmero de columnas One-Hot generadas:", len(one_hot_features_names))
        print("ğŸ“‹ Depurando: NÃºmero total de columnas esperadas:", len(all_feature_names))
        print("ğŸ“‹ Depurando: Forma final del array procesado:", df_processed_array.shape)
        
        # Verificamos coherencia de dimensiones
        if df_processed_array.shape[1] != len(all_feature_names):
            print(f"âŒ ERROR: Dimensiones no coinciden!")
            print(f"   Array tiene {df_processed_array.shape[1]} columnas")
            print(f"   Nombres de columnas: {len(all_feature_names)}")
            return
        
        # Creamos el DataFrame final
        df_encoded = pd.DataFrame(df_processed_array, columns=all_feature_names)
        
        print("\nâœ… DataFrame codificado creado exitosamente!")
        print("ğŸ“‹ Primeras 5 filas del dataset codificado con One-Hot Encoding:")
        print(df_encoded.head())
        print(f"\nğŸ“‹ Dimensiones del nuevo DataFrame codificado: {df_encoded.shape}")
        
    except Exception as e:
        print(f"âŒ Error al crear los nombres de columnas o el DataFrame: {e}")
        print("ğŸ“‹ Depurando: Intentando diagnÃ³stico adicional...")
        print("ğŸ“‹ Transformadores disponibles:", list(preprocessor.named_transformers_.keys()))
        return

    #Anexamos la variable objetivo en el DataFrame final
    if target_column in df.columns:
        df_final = pd.concat([df_encoded, df[target_column].reset_index(drop=True)], axis=1)
        print("\nğŸ“‹ DataFrame final con variable objetivo creado:")
        print(f"   Dimensiones: {df_final.shape}")
    else:
        print(f"\nAdvertencia: La columna objetivo '{target_column}' no se encontrÃ³ en el DataFrame original.")
        df_final = df_encoded

if __name__ == "__main__":
    main()