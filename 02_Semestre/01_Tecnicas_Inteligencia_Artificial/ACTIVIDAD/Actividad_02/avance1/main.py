import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de estilo para gr√°ficos
plt.style.use('default')
sns.set_palette("husl")

def main():
    # PASO 0: IMPORTACI√ìN DEL DATASET
    print("\nüéØ Paso 0: ----------------- Importamos el DataSet de Esperanza de Vida:------------------ üéØ")
    
    try:
        # URL de descarga directa para LifeExpectancyData.csv
        url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1EFa-JqAtrXtL1BrYP_mfxFVgAsADd_jn'
        df = pd.read_csv(url_descarga_directa, sep=',')
        print("‚úÖ Dataset cargado exitosamente")
        print("\nüìã Depurando: DF despu√©s de pd.read_csv - Forma:", df.shape)
        print("üìã Depurando: DF despu√©s de pd.read_csv - Columnas (primeras 5):", df.columns.tolist()[:20], "...")
    except Exception as e:
        print(f"‚ùå Error al cargar el dataset: {e}")
        return

    # PASO 1: PREPROCESAMIENTO DE DATOS (Incluyendo imputaci√≥n)
    print("\nüéØ Paso 1: ------------ Preprocesamiento de Datos (para caracterizaci√≥n) ------------------------ üéØ")
    # Limpiamos los nombres de las columnas
	df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace('.', '', regex=False).str.lower()    

    # Identificamos columnas categ√≥ricas y num√©ricas
    # Incluimos todas las num√©ricas relevantes, incluyendo 'life_expectancy' para la caracterizaci√≥n
    numerical_cols_for_eda = [
        'life_expectancy', 'adult_mortality', 'infant_deaths', 'alcohol', 
        'percentage_expenditure', 'hepatitis_b', 'measles', 'bmi', 
        'under_five_deaths', 'polio', 'total_expenditure', 'diphtheria', 
        'hiv/aids', 'gdp', 'population', 'thinness__1_19_years', 
        'thinness_5_9_years', 'income_composition_of_resources', 'schooling', 'year'
    ]
    categorical_cols_for_eda = ['country', 'status']

    # Imputamos los valores faltantes para poder realizar la caracterizaci√≥n
    imputer_numerical = SimpleImputer(strategy='mean')
    imputer_categorical = SimpleImputer(strategy='most_frequent')

    for col in numerical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna num√©rica para EDA: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]])

    for col in categorical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categ√≥rica para EDA: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]])

    print("\nüìã Depurando: Primeras 5 filas del dataset despu√©s de limpieza de columnas:")
    print(df.head())

    print("\nüìã Depurando: INFORMACI√ìN DETALLADA DESPU√âS DE LIMPIEZA DE COLUMNAS:")
    print(df.info())    

    print("\nüìã Depurando: Nombres de columnas despu√©s de la limpieza:")
    print(df.columns.tolist())
    print("\nüìã Depurando: Forma del DataFrame despu√©s de la limpieza:", df.shape)

    # --- INICIO: APARTADO A - CARACTERIZACI√ìN DEL DATASET ---
    print("\nüéØ Paso 2: ------------ Gr√°ficas ------------------------ üéØ")
    print("\nüéØ Apartado A: ------------ Caracterizaci√≥n del Dataset ------------------------ üéØ")

    # 1. Iniciamos Caracterizaci√≥n en Modo Texto
    print("\n--- 1.1: Estad√≠sticas Descriptivas de Variables Num√©ricas ---")
    print(df[numerical_cols_for_eda].describe().round(2))

    print("\n--- 1.2: Estad√≠sticas Descriptivas de Variables Categ√≥ricas ---")
    print(df[categorical_cols_for_eda].describe())

    print("\n--- 1.3: Conteo de Valores √önicos para 'Status' ---")
    print(df['status'].value_counts())
    print(f"\nN√∫mero total de pa√≠ses √∫nicos: {df['country'].nunique()}")

    print("\n--- 1.4: Matriz de Correlaci√≥n (primeras 5x5 columnas) ---")
    # Se muestra el valor de las correlaciones con la variable objetivo o un subconjunto relevante
    correlation_matrix = df[numerical_cols_for_eda].corr()
    print(correlation_matrix.head(5).iloc[:, :5].round(2)) # Muestra solo un subconjunto para no saturar la memoria

    # Se muestra la correlaci√≥n de todas las features con 'life_expectancy'
    print("\n--- 1.5: Correlaci√≥n de Features Num√©ricas con 'life_expectancy' ---")
    print(correlation_matrix['life_expectancy'].sort_values(ascending=False).round(2))

    # 2. Inicia Caracterizaci√≥n Gr√°fica
    print("\n--- 2.1: Histogramas para variables clave ---")
    plt.figure(figsize=(15, 10))
    
    plt.subplot(2, 2, 1)
    sns.histplot(df['life_expectancy'], kde=True)
    plt.title('Distribuci√≥n de la Esperanza de Vida')
    plt.xlabel('Esperanza de Vida')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 2)
    sns.histplot(df['gdp'], kde=True)
    plt.title('Distribuci√≥n del PIB')
    plt.xlabel('PIB')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 3)
    sns.histplot(df['schooling'], kde=True)
    plt.title('Distribuci√≥n de A√±os de Escolaridad')
    plt.xlabel('A√±os de Escolaridad')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 4)
    sns.histplot(df['adult_mortality'], kde=True)
    plt.title('Distribuci√≥n de Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Frecuencia')
    
    plt.tight_layout()
    plt.show()

    print("\n--- 2.2: Diagramas de Dispersi√≥n (Scatter Plots) con Esperanza de Vida ---")
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    sns.scatterplot(x='gdp', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. PIB')
    plt.xlabel('PIB')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 2)
    sns.scatterplot(x='schooling', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Escolaridad')
    plt.xlabel('A√±os de Escolaridad')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 3)
    sns.scatterplot(x='adult_mortality', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 4)
    sns.scatterplot(x='hiv/aids', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. HIV/AIDS')
    plt.xlabel('Prevalencia HIV/AIDS')
    plt.ylabel('Esperanza de Vida')

    plt.tight_layout()
    plt.show()

    print("\n--- 2.3: Diagrama de Cajas y Bigotes para Esperanza de Vida por Status ---")
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='status', y='life_expectancy', data=df)
    plt.title('Esperanza de Vida por Estado de Desarrollo del Pa√≠s')
    plt.xlabel('Estado del Pa√≠s')
    plt.ylabel('Esperanza de Vida')
    plt.show()

    print("\n--- 2.4: Mapa de Calor de Correlaci√≥n ---")
    plt.figure(figsize=(12, 10))
    # Selecciona un subconjunto de columnas si el heatmap es demasiado grande
    cols_for_heatmap = ['life_expectancy', 'adult_mortality', 'infant_deaths', 'gdp', 'schooling', 
                        'hiv/aids', 'income_composition_of_resources', 'bmi', 'alcohol']
    sns.heatmap(df[cols_for_heatmap].corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Mapa de Calor de Correlaci√≥n de Caracter√≠sticas Seleccionadas')
    plt.show()

    print("\nüéØ Paso 3: ------------ Aplicacando T√©cnica de Preprocesamiento de Datos Usaremos 'Codificaci√≥n One-Hot ------------------------ üéØ")

    # Identificamos las columnas categ√≥ricas y num√©ricas para nuestro estudio 
    categorical_features = ['country', 'status']
    numerical_features = ['adult_mortality', 'infant_deaths', 'schooling', 'gdp', 'hiv/aids', 'income_composition_of_resources', 'year'] 
    
    # Validamos que las columnas existen en el DataFrame
    print("\nüìã Depurando: Verificando existencia de columnas para preprocesamiento:")
    for col_list_name, col_list in [("Categorical Features", categorical_features), ("Numerical Features", numerical_features)]:
        missing_cols = [col for col in col_list if col not in df.columns]
        if missing_cols:
            print(f"‚ùå Faltan columnas en {col_list_name}: {missing_cols}")
            print(f"üìã Columnas disponibles: {df.columns.tolist()}")
            return  # Salir si faltan columnas cr√≠ticas
        else:
            print(f"‚úÖ Todas las columnas en {col_list_name} existen en el DataFrame.")

    for col in numerical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna num√©rica: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]]).flatten()

    for col in categorical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categ√≥rica: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]]).flatten()
    
    # Definir la variable objetivo
    target_column = 'life_expectancy' 
    
    # Aplicamos transformaci√≥n OneHotEncoder    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ],
        remainder='drop',
        sparse_threshold=0  # Esto fuerza la salida a ser un array denso
    )

    print("\nüìã Depurando: Antes de aplicar ColumnTransformer:")
    print("Columnas que se pasar√°n al OneHotEncoder:", categorical_features)
    print("Columnas que se pasar√°n como num√©ricas (passthrough):", numerical_features)
    print("Forma del DataFrame df antes de ColumnTransformer.fit_transform:", df.shape)
    
    # Verificar que las columnas categ√≥ricas tienen datos
    for col in categorical_features:
        print(f"üìã Depurando: Valores √∫nicos en {col}: {df[col].nunique()}")
        print(f"üìã Depurando: Primeros 3 valores √∫nicos en {col}: {df[col].unique()[:3]}")

    # Aplicar las transformaciones al DataFrame
    df_processed_array = preprocessor.fit_transform(df)

    print("\nüìã Depurando: Despu√©s de aplicar ColumnTransformer:")
    print("Forma de df_processed_array:", df_processed_array.shape)
    print("Tipo de df_processed_array:", type(df_processed_array))

    #Verificamos si es un array sparse y convertirlo
    if hasattr(df_processed_array, 'toarray'):
        df_processed_array = df_processed_array.toarray()
        print("üìã Depurando: Convertido de sparse a array denso")
        print("üìã Depurando: Nueva forma despu√©s de toarray():", df_processed_array.shape)

    # Obtener los nombres de las nuevas columnas
    try:
        one_hot_features_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
        all_feature_names = list(one_hot_features_names) + numerical_features
        
        print("üìã Depurando: N√∫mero de columnas One-Hot generadas:", len(one_hot_features_names))
        print("üìã Depurando: N√∫mero total de columnas esperadas:", len(all_feature_names))
        print("üìã Depurando: Forma final del array procesado:", df_processed_array.shape)
        
        # Verificamos coherencia de dimensiones
        if df_processed_array.shape[1] != len(all_feature_names):
            print(f"‚ùå ERROR: Dimensiones no coinciden!")
            print(f"   Array tiene {df_processed_array.shape[1]} columnas")
            print(f"   Nombres de columnas: {len(all_feature_names)}")
            return
        
        # Creamos el DataFrame final
        df_encoded = pd.DataFrame(df_processed_array, columns=all_feature_names)
        
        print("\n‚úÖ DataFrame codificado creado exitosamente!")
        print("üìã Primeras 5 filas del dataset codificado con One-Hot Encoding:")
        print(df_encoded.head())
        print(f"\nüìã Dimensiones del nuevo DataFrame codificado: {df_encoded.shape}")
        
    except Exception as e:
        print(f"‚ùå Error al crear los nombres de columnas o el DataFrame: {e}")
        print("üìã Depurando: Intentando diagn√≥stico adicional...")
        print("üìã Transformadores disponibles:", list(preprocessor.named_transformers_.keys()))
        return

    #Anexamos la variable objetivo en el DataFrame final
    if target_column in df.columns:
        df_final = pd.concat([df_encoded, df[target_column].reset_index(drop=True)], axis=1)
        print("\nüìã DataFrame final con variable objetivo creado:")
        print(f"   Dimensiones: {df_final.shape}")
    else:
        print(f"\nAdvertencia: La columna objetivo '{target_column}' no se encontr√≥ en el DataFrame original.")
        df_final = df_encoded

if __name__ == "__main__":
    main()
