import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de estilo para grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

def main():
    # PASO 0: IMPORTACIÃ“N DEL DATASET
    print("\nğŸ¯ Paso 0: ----------------- Importamos el DataSet de Esperanza de Vida:------------------ ğŸ¯")
    
    try:
        # URL de descarga directa para LifeExpectancyData.csv
        url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1EFa-JqAtrXtL1BrYP_mfxFVgAsADd_jn'
        df = pd.read_csv(url_descarga_directa, sep=',')
        print("âœ… Dataset cargado exitosamente")
        print("\nğŸ“‹ Depurando: DF despuÃ©s de pd.read_csv - Forma:", df.shape)
        print("ğŸ“‹ Depurando: DF despuÃ©s de pd.read_csv - Columnas (primeras 5):", df.columns.tolist()[:20], "...")
    except Exception as e:
        print(f"âŒ Error al cargar el dataset: {e}")
        return

    # PASO 1: PREPROCESAMIENTO DE DATOS (Incluyendo imputaciÃ³n)
    print("\nğŸ¯ Paso 1: ------------ Preprocesamiento de Datos (para caracterizaciÃ³n) ------------------------ ğŸ¯")
    # Limpiamos los nombres de las columnas
	df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace('.', '', regex=False).str.lower()    

    # Identificamos columnas categÃ³ricas y numÃ©ricas
    # Incluimos todas las numÃ©ricas relevantes, incluyendo 'life_expectancy' para la caracterizaciÃ³n
    numerical_cols_for_eda = [
        'life_expectancy', 'adult_mortality', 'infant_deaths', 'alcohol', 
        'percentage_expenditure', 'hepatitis_b', 'measles', 'bmi', 
        'under_five_deaths', 'polio', 'total_expenditure', 'diphtheria', 
        'hiv/aids', 'gdp', 'population', 'thinness__1_19_years', 
        'thinness_5_9_years', 'income_composition_of_resources', 'schooling', 'year'
    ]
    categorical_cols_for_eda = ['country', 'status']

    # Imputamos los valores faltantes para poder realizar la caracterizaciÃ³n
    imputer_numerical = SimpleImputer(strategy='mean')
    imputer_categorical = SimpleImputer(strategy='most_frequent')

    for col in numerical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna numÃ©rica para EDA: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]])

    for col in categorical_cols_for_eda:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categÃ³rica para EDA: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]])

    print("\nğŸ“‹ Depurando: Primeras 5 filas del dataset despuÃ©s de limpieza de columnas:")
    print(df.head())

    print("\nğŸ“‹ Depurando: INFORMACIÃ“N DETALLADA DESPUÃ‰S DE LIMPIEZA DE COLUMNAS:")
    print(df.info())    

    print("\nğŸ“‹ Depurando: Nombres de columnas despuÃ©s de la limpieza:")
    print(df.columns.tolist())
    print("\nğŸ“‹ Depurando: Forma del DataFrame despuÃ©s de la limpieza:", df.shape)

    # --- INICIO: APARTADO A - CARACTERIZACIÃ“N DEL DATASET ---
    print("\nğŸ¯ Paso 2: ------------ GrÃ¡ficas ------------------------ ğŸ¯")
    print("\nğŸ¯ Apartado A: ------------ CaracterizaciÃ³n del Dataset ------------------------ ğŸ¯")

    # 1. Iniciamos CaracterizaciÃ³n en Modo Texto
    print("\n--- 1.1: EstadÃ­sticas Descriptivas de Variables NumÃ©ricas ---")
    print(df[numerical_cols_for_eda].describe().round(2))

    print("\n--- 1.2: EstadÃ­sticas Descriptivas de Variables CategÃ³ricas ---")
    print(df[categorical_cols_for_eda].describe())

    print("\n--- 1.3: Conteo de Valores Ãšnicos para 'Status' ---")
    print(df['status'].value_counts())
    print(f"\nNÃºmero total de paÃ­ses Ãºnicos: {df['country'].nunique()}")

    print("\n--- 1.4: Matriz de CorrelaciÃ³n (primeras 5x5 columnas) ---")
    # Se muestra el valor de las correlaciones con la variable objetivo o un subconjunto relevante
    correlation_matrix = df[numerical_cols_for_eda].corr()
    print(correlation_matrix.head(5).iloc[:, :5].round(2)) # Muestra solo un subconjunto para no saturar la memoria

    # Se muestra la correlaciÃ³n de todas las features con 'life_expectancy'
    print("\n--- 1.5: CorrelaciÃ³n de Features NumÃ©ricas con 'life_expectancy' ---")
    print(correlation_matrix['life_expectancy'].sort_values(ascending=False).round(2))

    # 2. Inicia CaracterizaciÃ³n GrÃ¡fica
    print("\n--- 2.1: Histogramas para variables clave ---")
    plt.figure(figsize=(15, 10))
    
    plt.subplot(2, 2, 1)
    sns.histplot(df['life_expectancy'], kde=True)
    plt.title('DistribuciÃ³n de la Esperanza de Vida')
    plt.xlabel('Esperanza de Vida')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 2)
    sns.histplot(df['gdp'], kde=True)
    plt.title('DistribuciÃ³n del PIB')
    plt.xlabel('PIB')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 3)
    sns.histplot(df['schooling'], kde=True)
    plt.title('DistribuciÃ³n de AÃ±os de Escolaridad')
    plt.xlabel('AÃ±os de Escolaridad')
    plt.ylabel('Frecuencia')

    plt.subplot(2, 2, 4)
    sns.histplot(df['adult_mortality'], kde=True)
    plt.title('DistribuciÃ³n de Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Frecuencia')
    
    plt.tight_layout()
    plt.show()

    print("\n--- 2.2: Diagramas de DispersiÃ³n (Scatter Plots) con Esperanza de Vida ---")
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    sns.scatterplot(x='gdp', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. PIB')
    plt.xlabel('PIB')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 2)
    sns.scatterplot(x='schooling', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Escolaridad')
    plt.xlabel('AÃ±os de Escolaridad')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 3)
    sns.scatterplot(x='adult_mortality', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. Mortalidad Adulta')
    plt.xlabel('Mortalidad Adulta')
    plt.ylabel('Esperanza de Vida')

    plt.subplot(2, 2, 4)
    sns.scatterplot(x='hiv/aids', y='life_expectancy', data=df, alpha=0.6)
    plt.title('Esperanza de Vida vs. HIV/AIDS')
    plt.xlabel('Prevalencia HIV/AIDS')
    plt.ylabel('Esperanza de Vida')

    plt.tight_layout()
    plt.show()

    print("\n--- 2.3: Diagrama de Cajas y Bigotes para Esperanza de Vida por Status ---")
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='status', y='life_expectancy', data=df)
    plt.title('Esperanza de Vida por Estado de Desarrollo del PaÃ­s')
    plt.xlabel('Estado del PaÃ­s')
    plt.ylabel('Esperanza de Vida')
    plt.show()

    print("\n--- 2.4: Mapa de Calor de CorrelaciÃ³n ---")
    plt.figure(figsize=(12, 10))
    # Selecciona un subconjunto de columnas si el heatmap es demasiado grande
    cols_for_heatmap = ['life_expectancy', 'adult_mortality', 'infant_deaths', 'gdp', 'schooling', 
                        'hiv/aids', 'income_composition_of_resources', 'bmi', 'alcohol']
    sns.heatmap(df[cols_for_heatmap].corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Mapa de Calor de CorrelaciÃ³n de CaracterÃ­sticas Seleccionadas')
    plt.show()

    print("\nğŸ¯ Paso 3: ------------ Aplicacando TÃ©cnica de Preprocesamiento de Datos Usaremos 'CodificaciÃ³n One-Hot ------------------------ ğŸ¯")

    # Identificamos las columnas categÃ³ricas y numÃ©ricas para nuestro estudio 
    categorical_features = ['country', 'status']
    numerical_features = ['adult_mortality', 'infant_deaths', 'schooling', 'gdp', 'hiv/aids', 'income_composition_of_resources', 'year'] 
    
    # Validamos que las columnas existen en el DataFrame
    print("\nğŸ“‹ Depurando: Verificando existencia de columnas para preprocesamiento:")
    for col_list_name, col_list in [("Categorical Features", categorical_features), ("Numerical Features", numerical_features)]:
        missing_cols = [col for col in col_list if col not in df.columns]
        if missing_cols:
            print(f"âŒ Faltan columnas en {col_list_name}: {missing_cols}")
            print(f"ğŸ“‹ Columnas disponibles: {df.columns.tolist()}")
            return  # Salir si faltan columnas crÃ­ticas
        else:
            print(f"âœ… Todas las columnas en {col_list_name} existen en el DataFrame.")

    for col in numerical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna numÃ©rica: {col}")
            df[col] = imputer_numerical.fit_transform(df[[col]]).flatten()

    for col in categorical_features:
        if col in df.columns and df[col].isnull().any():
            print(f"Imputando valores nulos en columna categÃ³rica: {col}")
            df[col] = imputer_categorical.fit_transform(df[[col]]).flatten()
    
    # Definir la variable objetivo
    target_column = 'life_expectancy' 
    
    # Aplicamos transformaciÃ³n OneHotEncoder    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ],
        remainder='drop',
        sparse_threshold=0  # Esto fuerza la salida a ser un array denso
    )

    print("\nğŸ“‹ Depurando: Antes de aplicar ColumnTransformer:")
    print("Columnas que se pasarÃ¡n al OneHotEncoder:", categorical_features)
    print("Columnas que se pasarÃ¡n como numÃ©ricas (passthrough):", numerical_features)
    print("Forma del DataFrame df antes de ColumnTransformer.fit_transform:", df.shape)
    
    # Verificar que las columnas categÃ³ricas tienen datos
    for col in categorical_features:
        print(f"ğŸ“‹ Depurando: Valores Ãºnicos en {col}: {df[col].nunique()}")
        print(f"ğŸ“‹ Depurando: Primeros 3 valores Ãºnicos en {col}: {df[col].unique()[:3]}")

    # Aplicar las transformaciones al DataFrame
    df_processed_array = preprocessor.fit_transform(df)

    print("\nğŸ“‹ Depurando: DespuÃ©s de aplicar ColumnTransformer:")
    print("Forma de df_processed_array:", df_processed_array.shape)
    print("Tipo de df_processed_array:", type(df_processed_array))

    #Verificamos si es un array sparse y convertirlo
    if hasattr(df_processed_array, 'toarray'):
        df_processed_array = df_processed_array.toarray()
        print("ğŸ“‹ Depurando: Convertido de sparse a array denso")
        print("ğŸ“‹ Depurando: Nueva forma despuÃ©s de toarray():", df_processed_array.shape)

    # Obtener los nombres de las nuevas columnas
    try:
        one_hot_features_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
        all_feature_names = list(one_hot_features_names) + numerical_features
        
        print("ğŸ“‹ Depurando: NÃºmero de columnas One-Hot generadas:", len(one_hot_features_names))
        print("ğŸ“‹ Depurando: NÃºmero total de columnas esperadas:", len(all_feature_names))
        print("ğŸ“‹ Depurando: Forma final del array procesado:", df_processed_array.shape)
        
        # Verificamos coherencia de dimensiones
        if df_processed_array.shape[1] != len(all_feature_names):
            print(f"âŒ ERROR: Dimensiones no coinciden!")
            print(f"   Array tiene {df_processed_array.shape[1]} columnas")
            print(f"   Nombres de columnas: {len(all_feature_names)}")
            return
        
        # Creamos el DataFrame final
        df_encoded = pd.DataFrame(df_processed_array, columns=all_feature_names)
        
        print("\nâœ… DataFrame codificado creado exitosamente!")
        print("ğŸ“‹ Primeras 5 filas del dataset codificado con One-Hot Encoding:")
        print(df_encoded.head())
        print(f"\nğŸ“‹ Dimensiones del nuevo DataFrame codificado: {df_encoded.shape}")
        
    except Exception as e:
        print(f"âŒ Error al crear los nombres de columnas o el DataFrame: {e}")
        print("ğŸ“‹ Depurando: Intentando diagnÃ³stico adicional...")
        print("ğŸ“‹ Transformadores disponibles:", list(preprocessor.named_transformers_.keys()))
        return

    #Anexamos la variable objetivo en el DataFrame final
    if target_column in df.columns:
        df_final = pd.concat([df_encoded, df[target_column].reset_index(drop=True)], axis=1)
        print("\nğŸ“‹ DataFrame final con variable objetivo creado:")
        print(f"   Dimensiones: {df_final.shape}")
    else:
        print(f"\nAdvertencia: La columna objetivo '{target_column}' no se encontrÃ³ en el DataFrame original.")
        df_final = df_encoded

if __name__ == "__main__":
    main()
