# Tema 1: Introducción Inteligencia Artificial 

1. Indica cuáles de las siguientes afirmaciones son correctas:
A. La escuela de la Inteligencia Artificial Fuerte defiende que las máquinas pueden llegar a tener conciencia.
B. La escuela de la Inteligencia Artificial Débil no defiende que los procesos cerebrales puedan ser simulados en un computador.
C. El juego de imitación de Turing consiste en que una máquina consiga mantener una conversación tal y como lo haría un humano. -> **Correcto**
D. Las técnicas de aprendizaje automático no forman parte del campo de la inteligencia artificial.

2. Indica cuál de las siguientes afirmaciones no es correcta:
A. La minería de datos utiliza técnicas de aprendizaje automático para descubrir patrones en grandes cantidades de datos.
B. La minería de datos tiene un objetivo fundamentalmente teórico. -> **Correcto**
C. Existe una fase en los procedimientos KDD que consiste en ejecutar técnicas de inteligencia artificial.
D. En los procedimientos KDD, previo a la fase de minería de datos, se dan otras fases de selección y transformación de los datos.

3. Indica cuál de las siguientes afirmaciones no es correcta respecto a la
experiencia en el aprendizaje de conceptos. La experiencia:
A. Consiste en un conjunto de objetos específicos denominados instancias.
B. Consiste en una serie de ejemplos y no-ejemplos.
C. Consiste en una serie de instancias con atributos de entrada y de salida.
D. Consiste en un conjunto de datos denominado datos de prueba. -> **Correcto**

4. Identificar la clase de una instancia desconocida en base a sus atributos, que se
presentan comunes a ejemplos previos encontrados de esa clase es una tarea de:
A. Discriminación.
B. Generalización.
C. Clasificación. -> **Correcto**
D. Descripción.

5. Una tarea de aprendizaje consiste en descubrir los síntomas comunes de un
grupo de pacientes que presentan una enfermedad bien conocida. Se trata de un
problema de aprendizaje de tipo:
A. Supervisado.  -> **Correcto**
B. No-supervisado.

6. Una tarea de aprendizaje consiste en descubrir los síntomas comunes de un
grupo de pacientes con diagnóstico desconocido. Se trata de un problema de
aprendizaje de tipo:
A. Supervisado.
B. No-supervisado.  -> **Correcto**

7. Indica cuál de las siguientes afirmaciones no es cierta, respecto al
descubrimiento de conocimiento en bases de datos:
A. Es un procedimiento completo necesario para extraer conocimiento a partir
de los datos de una base de datos.
B. Sea cual sea el procedimiento KDD las fases siempre son las mismas. -> **Correcto**
C. La interpretación de los resultados forma parte del procedimiento KDD.
D. Es un proceso que puede ser iterativo.

8. Indica cuál de las siguientes afirmaciones no es correcta:
A. Los datos de entrenamiento son un conjunto de instancias.
B. Los datos de entrenamiento pueden contener no-ejemplos.
C. Los atributos son denominados también ejemplos.  -> **Correcto**
D. Al concepto que se aprende se le llama también clase.
E. El concepto es un conjunto de instancias.

9. Indica cuáles de las siguientes afirmaciones son correctas respecto al
aprendizaje de conceptos:
A. Los problemas de aprendizaje se resuelven a veces como una búsqueda
en un espacio de hipótesis. -> **Correcto**
B. Siempre se aplican las técnicas de búsqueda de la mejor hipótesis sobre el
espacio completo de posibles hipótesis.
C. El tamaño de los datos de entrenamiento no influye en el resultado del
aprendizaje.
D. Se pueden encontrar en la práctica distintas descripciones de un concepto.
E. El sobreajuste consiste en generalizar demasiado. -> **Correcto**

10. Indica cuál de las siguientes frases no es correcta respecto a un sistema
experto:
A. Se incorpora en el sistema el conocimiento de un experto humano.
B. Raramente se ha aplicado un sistema experto a un problema real con éxito. -> **Correcto**
C. Suele estar limitado a un dominio de conocimiento.
D. Puede ser complementado con técnicas de aprendizaje automático como
las redes neuronales para obtener reglas a partir de grandes cantidades de
datos que el experto humano es incapaz de obtener.

## Videoclase 1. IA y el poder del dato
- ¿Qué relación existe entre Inteligencia Artificial (IA) y Machine Learning (ML)?:
    - ML es una rama específica dentro de la IA -> El Machine Learning o Aprendizaje automático, es una disciplina específica dentro del área de Inteligencia Artficial, que además incluye otras como PLN o Sistemas de recomendación.

- La minería de datos se nutre de las técnicas de Aprendizaje Automático para:
    - Descubrir y describir patrones.

- ¿Qué es de vital necesidad para poder experimentar con técnicas de Aprendizaje Automático?:
    - Modelos de inteligencia artificial adecuados.
    - Un entorno de ejecución que permita correr los modelos.
    - Un conjunto de datos útil y completo.
    - Todas son válidas. -> **Correcto**

- Con respecto a las métricas para la evaluación de los modelos de IA:
    - Cada tipología de problemas comprende una serie de métricas específicas => Cada métrica específica, evalúa la capacidad de nuestro modelo de Inteligencia Artificial de forma bien diferenciada: unas para regresión, otras para clasificación.

- La importancia de los datos para las técnicas de IA estriba en:
    - a.Disponer de un conjunto útil y completo.
    - b.Disponer de un conjunto actualizado.
    - c.Seleccionar técnicas de IA y métricas adecuadas acordes a los datos.
    - d.Todas las anteriores son válidas -> **Correcto**

## Videoclase 2. Aprendizaje supervisado VS Aprendizaje no supervisado

- En el aprendizaje supervisado se realizan predicciones de datos a partir de valores:
    - Conocidos.

- En el aprendizaje no supervisado se descubren patrones de datos a partir de valores:
    - Desconocidos.

- Los modelos de regresión:
    - Predicen un valor de una variable numérica continua.

- Las técnicas de agrupación como el algoritmo K-means permiten resolver problemas:
    - De aprendizaje no supervisado. -> K-means es una técnica de agrupación que permite descubrir patrones ocultos en los datos, por lo que estamos ante problemas de aprendizaje no supervisado.

- Regresión, Clasificación, Agrupamiento y Detección de anomalías son:
    - Técnicas de aprendizaje automático.


## Videoclase 3: 

- En el proceso de generación de conocimiento, la minería de datos:
    - Ocurre después de la transformación y limpieza de los mismos
- En el proceso de generación de conocimiento, la interpretación y evaluación de los datos:
    - Ocurre después de las acciones de minería de datos.
- En el proceso de generación de conocimiento, la valoración de la calidad de los datos recogidos de las fuentes externas:
    - La valoración de la calidad de los datos recogidos de las fuentes externas no está incluida en dicho proceso
- ¿En qué fase del proceso KDD entran los criterios de éxito o métricas específicas para los modelos de IA?:
    - Evaluación de resultados.
- En un caso real, si queremos predecir la cantidad de personal de caja para una hora determinada en una entidad bancaria haciendo uso de un proceso de descubrimiento de conocimiento KDD, ¿cuál de las siguientes fases no estaría incluida en dicho proceso?:
    - Todas podrían formar parte de un proceso KDD.


# Tema 2. Python para la implementación de técnicas de inteligencia artificial

1. Indica la respuesta correcta:
A. Python es un lenguaje fuertemente tipado y de tipado estático.
B. Python es un lenguaje de programación declarativo.
C. Python es un lenguaje de programación imperativo, fuertemente tipado, de
tipado dinámico.  -> **Correcto**
D. Python es un lenguaje de programación multiparadigma y débilmente
tipado.

2. Indica el resultado por pantalla de la siguiente sentencia en Python: print(int(2 +
2j))
A. 2.
B. 2 + 2j.
C. 0.
D. Resultará un error. -> **Correcto**

3. Si en Python la variable x es una cadena str cuyo contenido es "Bienvenidos",
¿cuál será el resultado de la siguiente sentencia? print(x[-4:-2])
A. [-4 -3 -2].
B. Error. 
C. id.-> **Correcto**
D. -6.

4. Indica la respuesta **incorrecta.** Cuando hablamos de Python:
A. Las listas son colecciones ordenadas y cuyos elementos pueden ser
modificados.
B. Las tuplas son colecciones no ordenadas y cuyos elementos no pueden ser
modificados. -> **Correcto**
C. Los conjuntos son colecciones no ordenadas y cuyos elementos no pueden
estar duplicados.
D. Los diccionarios son colecciones no ordenadas de elementos clave-valor
que pueden ser modificados.

5. Si en un programa en Python existe una variable x de tipo tupla y realizamos la
asignación y = x, señala la opción correcta:
A. Al modificar un elemento de y, el mismo elemento en x se verá modificado.
B. Al modificar un elemento de y, el mismo elemento en x no se verá
modificado.
C. No podemos modificar ningún elemento de y, por ser una tupla. -> **Correcto**
D. Ninguna de las anteriores es correcta.

6. Si en un programa en Python existe una variable x de tipo lista y realizamos la
asignación y = x, señala la opción correcta:
A. Al modificar un elemento de y, el mismo elemento en x se verá modificado. -> **Correcto**
B. Al modificar un elemento de y, el mismo elemento en x no se verá
modificado.
C. No podemos modificar ningún elemento de y, por ser una lista.
D. Ninguna de las anteriores es correcta.

7. ¿Cuál de las siguientes preguntas es correcta?
A. TensorFlow fue desarrollada por Google Brain.
B. Pandas permite la carga sencilla de datasets en CSV.
C. Keras es una librería especialmente enfocada para trabajar con redes
neuronales artificiales.
D. Todas las anteriores. -> **Correcto**

8. ¿Con qué función se puede importar un dataset en formato CSV desde un
archivo local o una URL?
A. pandas.importdataset().
B. pandas.readcsv(). -> **Correcto**
C. pandas.readurl().
D. pandas.importcsv().

9. ¿Cuál es el objetivo de TensorFlow Lite?
A. Para el uso de librerías gratuitas.
B. TensorFlow Lite no existe.
C. Para su uso con el lenguaje Go.
D. Para su uso en dispositivos móviles con reducida capacidad de cálculo. -> **Correcto**

10. Para mostrar gráficos por pantalla aplicando técnicas machine learning con
Python, emplearía:
A. Keras.
B. Scikit-learn.
C. Matplotlib. -> **Correcto**
D. SciPy.



## Videoclase 1. Escribiendo en Python
- ¿Se pueden incluir celdas de código y celdas de texto en Jupyter?:
    - Únicamente en trabajos de Inteligencia Artificial.
- Un fichero de salida generado por Jupyter notebook se puede ejecutar:
    - Únicamente en entornos Jupyter notebook. =Los ficheros de salida para Jupyter notebook tienen una extensión específica (IPNYB) para que sean ejecutados únicamente en entornos Jupyter.>
- ¿Se pueden importar librerías de inteligencia artificial en Jupyter notebook?:  
    - Sí, pero añadiendo las necesarias cuando no están incluidas en el entorno Python por defecto, mediante la sentencia pip install.
- Si se necesita cargar en Jupyter Notebook un dataset disponible en Internet podemos:
    - a.Bajarlo a nuestro sistema de archivos y cargarlo con alguna función de pandas como read.
    - b.Cargarlo directamente desde su URL recogida mediante el método get de la librería requests.
    - c.Abrirlo desde una unidad en la nube previamente montada en nuestro entorno Jupyter notebook.
    - d.Todas las anteriores son válidas -> **Correcto**
- La ejecución de código Python en Jupyter notebook puede realizarse:
    - Tanto celda a celda como todas las celdas desde un punto.

## Videoclase 2. Librerías para IA
- Numpy y Scipy son librerías de:
    - Cálculo científico sobre las que se apoyan librerías de Aprendizaje Automático =>
- Keras es una librería de redes neuronales que, apoyada en otras librerías, permite el manejo de arrays o matrices multidimensionales:
    - Verdadero -> Keras es una librería especializada en la creación de arquitecturas de redes neuronales, que a su vez se apoya en otras como NumPy para manejo de matrices multidimensionales.

- Scikit Learn permite:
    - Manejo de estructuras de datos de otras librerías de cálculo científico como Numpy o Scipy.
    - Creación de modelos de aprendizaje automático.
    - Gestión de las diferentes métricas de evaluación de resultados.
    - Todas las anteriores son ciertas -> **Correcto**
    
- Queremos crear una red neuronal convolucional y mostrar sus resultados de entrenamiento y evaluación de forma gráfica, necesitamos incluir:
    - a.Solo Keras.
    - b.Keras y Seaborn.
    - c.Keras, Scikit learn y Seaborn.
    - d. Ninguna de las anteriores -> **Correcto**

    Keras, Scikit learn y Seaborn.
- Matplotlib y Seaborn son librerías:
    - Ninguna de las anteriores

## Videoclase 3. Datasets

- Kaggle es una plataforma:
    - De aprendizaje automático colaborativo que incluye datasets.

-  Google posee una plataforma específica para:
    - Búsqueda de datasets abiertos.

- ¿Quién puede descargar datasets públicos del portal de datos abiertos del Gobierno de España?:
    - Cualquier usuario, siempre y cuando el dataset sea público.

- Mockaroo permite:
    - Ninguna de las anteriores 

- Queremos buscar un conjunto de datos sobre información del COVID-19 en España, ¿dónde podemos acudir?:
    - Todas las anteriores.


# Tema 3: Árboles de decisión

1. Completa esta sentencia con la opción correcta: «La clasificación mediante
árboles de decisión es una tarea de aprendizaje de tipo [...]»:
A. Supervisado. -> **correcto**
B. No-supervisado.
C. Supervisado y no supervisado.
D. Ninguna de las anteriores.

2. Indica cuáles de las siguientes afirmaciones son verdaderas:
A. El algoritmo ID3 permite valores numéricos en los atributos.
B. El algoritmo C4.5 permite valores numéricos en los atributos de salida.
C. Los algoritmos ID3 y C4.5 permiten valores nominales en los atributos de salida. -> **correcto**
D. El algoritmo C4.5 permite valores numéricos y nominales en los atributos de entrada. -> **correcto**

3. Marca de las siguientes opciones aquellas en las que resulta adecuado utilizar un árbol de decisión en la tarea de aprendizaje:
A. No se conoce la clase de las instancias disponibles.
B. La función objetivo tiene valores de salida discretos. -> **correcto**
C. Existen varios atributos de salida.
D. Los datos de entrenamiento contienen errores. -> **correcto**

4. Indica cuál de las siguientes afirmaciones es correcta:
A. El método de selección de los atributos especifica una heurística para
seleccionar el atributo que mejor discrimina los ejemplos para una clase. -> **correcto**
B. Un algoritmo básico de construcción de árboles de decisión recibe como
entrada los datos de entrenamiento y los atributos de las instancias, y obtiene
como salida un método de selección de atributos.
C. El método codicioso es un método de selección de atributos.
D. C4.5 no utiliza un método de selección de atributos.

5. Cuando se tienen atributos con un gran número de posibles valores ¿qué método de selección de atributos conviene utilizar?
A. Ganancia de información.
B. Proporción de ganancia. -> **correcto**
C. Indice Gini.
D. Longitud de descripción mínima.

6. Indica cuáles de las siguientes afirmaciones son correctas respecto a ID3:
A. ID3 se basa en el método codicioso o greedy. -> **correcto**
B. ID3 considera como heurística que el atributo cuyo conocimiento aporta mayor información en la predicción de la clase es el más útil. -> **correcto**
C. ID3 utiliza la medida de proporción de ganancia.
D. ID3 trabaja con un espacio de hipótesis incompleto.

7. Indica las respuestas correctas en relación con los métodos de aprendizaje
integrado:

A. En los métodos stacking se utilizan los mismos datos de entrada a
diferentes algoritmos en paralelo. Finalmente se utiliza un algoritmo decisor
para dar la respuesta final. -> **correcto**. El texto dice: "entrenar diferentes algoritmos (por ejemplo, un k-NN, un árbol de decisión y un SVM... ) utilizando los mismos datos y utilizarlos en paralelo para clasificar la misma entrada. Finalmente, se promedian las salidas de los diferentes algoritmos para obtener un valor de salida final, normalmente utilizando un algoritmo de regresión". El "algoritmo decisor" o "algoritmo de regresión" que promedia las salidas es la forma en que se combinan.

B. En los métodos bagging se utilizan el mismo tipo de algoritmos en paralelo,
a los cuales se pasa como entrada diferentes subconjuntos aleatorios a partir
del dataset inicial. -> **correcto**. El texto afirma: "en los métodos bagging... se utiliza un conjunto de algoritmos en paralelo en los que todos los algoritmos son iguales (por ejemplo, todos son árboles de decisión), pero cada uno de ellos se entrena con un subconjunto aleatorio de datos extraídos del mismo conjunto de datos de entrenamiento".

C. Random forest es un tipo de método boosting utilizando árboles de
decisión en serie.

D. En los métodos boosting se parte de un dataset inicial y se entrenan
diferentes algoritmos uno a uno secuencialmente, introduciendo como entrada
de cada algoritmo un conjunto aleatorio del dataset inicial.

8. Indica cuáles de las siguientes afirmaciones son correctas respecto a C4.5:
A. C4.5 utiliza la medida de proporción de ganancia. -> **correcto**. El texto establece explícitamente: "El método de selección de atributos que utiliza C4.5 es la medida de proporción de ganancia."
B. C4.5 utiliza un método de prepoda.
C. C4.5 poda el árbol utilizando datos de prueba.
D. C4.5 realiza una poda una vez se ha generado el árbol. -> **correcto**. Como se mencionó en la explicación del punto B, el texto dice: "C4.5 realiza una poda tras la generación del árbol (pospoda)... Una vez que el árbol ha sido generado, C4.5 elimina aquellos nodos del árbol..."

9. Indica cuáles de las siguientes afirmaciones son correctas respecto al método de
validación cruzada:
A. Utiliza un conjunto de datos de validación y un conjunto de datos de
entrenamiento. -> **correcto**.
B. La validación cruzada divide los datos disponibles en dos subconjuntos.
C. La validación cruzada no se puede utilizar para evaluar la efectividad de
una poda.
D. Cuando se tienen pocos datos no conviene utilizar la validación cruzada
con k iteraciones.

10. Indica cuáles de las siguientes afirmaciones son correctas respecto a las medidas de precisión en la clasificación:
A. La tasa de error de una muestra es el cociente entre el número de instancias erróneamente clasificadas y el número total de instancias. -> **correcto**. Esta es la definición estándar de la tasa de error (que es 1 menos la precisión). El texto menciona que "la tasa de error tendría un valor terror = e/N, siendo N el número de instancias que lo alcanzan". Aquí, 'e' representa las instancias clasificadas erróneamente.

B. Cuanto mayor sea el número de instancias, el intervalo de confianza será
mayor.

C. C4.5 utiliza los propios datos de entrenamiento para calcular la tasa de error. -> **correcto** El texto lo dice claramente en la sección sobre la poda pesimista de C4.5: "C4.5 no utiliza un conjunto de ejemplos para la validación separado de los datos de entrenamiento, sino que la validación la realiza a partir de los mismos datos de entrenamiento". Y luego añade: "Esta estimación, al ser calculada sobre los mismos datos de entrenamiento, resulta en una estimación claramente optimista...

D. Cuanto mayor nivel de confianza se requiere se obtiene un intervalo de
confianza menor.


## Video Clase 1: El conocimiento representado en un árbol de decisión

- El aprendizaje que podemos experimentar con un árbol de decisión es:
    - Aprendizaje inductivo. => Se trata de un tipo de aprendizaje inductivo mediante el cual podemos extraer conclusiones a partir de premisas o reglas formadas en el propio árbol.

- ¿Mediante qué operador se establecen las divisiones en un árbol de decisión?:
    - Disyunción => En los nodos de decisión del árbol se establecen las sucesivas ramificaciones a partir de la aplicación de un operador OR sobre un atributo determinado.

- ¿Cuáles de las siguientes afirmaciones pueden ser consideradas ventajas de la representación del conocimiento mediante árboles de decisión?
    - Independencia de la distribución de valores.
    - No se requiere conocimiento previo del dominio del problema.
    - Facilidad en la interpretación del árbol.
    - Todas las anteriores => Correcta 

- En un árbol de decisión para un problema de clasificación, las hojas deben ser:
    - Valores categóricos => En un árbol de clasificación, las hojas representan la salida del árbol, quedando esta circunscrita a categorías.

- Supón un problema de predicción del voto en unas elecciones entre cinco candidatos posibles. En base a una serie de características de los votantes como el barrio de residencia, el nivel de estudios y los ingresos mensuales, ¿podríamos hacer uso de un árbol de regresión para generar reglas o premisas que permitan realizar dicha predicción?:
    - No, debería de tratarse de un árbol de clasificación. => Se trata de un problema de predicción de una categoría entre cinco posibles, por lo que estaríamos en un problema de clasificación, cuyas reglas o premisas podrían estar perfectamente representadas mediante un árbol de decisión.


## Video Clase 2:  Evaluación mediante Curvas ROC

- Accuracy, recall, precisión y f1-score son métricas:
    - Para evaluar problemas de clasificación

- La funcionalidad del umbral en los problemas de clasificación es:
    - Fijar un valor entre 0 y 1 que marque la pertenencia de un elemento a una clase u otra en clasificación binaria. => El umbral marca un valor a partir del cual la clasificación de un elemento es considerada para la clase positiva en un problema de clasificación binaria.

- En un clasificador, FP Rate mide exactamente:
    - a capacidad del clasificador para descartar instancias que no pertenecen a una clase, entre instancias de esa misma clase. => FP Rate mide la tasa de falsos positivos sobre el total de instancias en una clase determinada.

- La curva ROC se construye:
    - Sobre la sensibilidad y especificidad del modelo.

- A menor área AUC bajo una curva ROC, tenemos que:
    - El clasificador tendrá un peor desempeño. => AUC mide el desempeño a nivel de discriminación de un clasificador determinado, en la forma que, a mayor área bajo la curva y más cercana su medida a 1, mejor será dicho desempeño.

## Video Clase 3: Ensemble learning

- ¿Qué tipología de aprendizaje proponen los modelos de ensemble?:
- Aprendizaje integrado

- Los métodos de Stacking:
- Proponen la ejecución de varios algoritmos diferentes en paralelo.

- Los métodos de Bagging:
- Proponen la ejecución de varios algoritmos iguales en paralelo.

- Los métodos de Boosting:
- Los métodos de boosting se basan en la ejecución de varios algoritmos de forma secuencial priorizando a la salida de cada clasificador intermedio los peores resultados, de forma iterativa hasta obtener unos resultados óptimos.

- Random Forest es un método de ensemble de la categoría:
- Bagging => Random Forest plantea la ejecución de varios árboles en paralelo y combinando sus salidas para producir un resultado único


# Tema 4:  Reglas

1. Si en un problema se desea identificar los síntomas correspondientes a tres
enfermedades conocidas, las técnicas apropiadas para resolver el problema son
(selecciona las opciones adecuadas):
A. Árboles de decisión. -> **correcto**
B. Algoritmo apriori.
C. Algoritmo de recubrimiento secuencial.  -> **correcto**
D. Algoritmo PRISM.


2. Si en un problema se desea identificar relaciones entre síntomas de personas
que presentan ciertas enfermedades, las técnicas apropiadas son:
A. Árboles de decisión.
B. Algoritmo apriori. -> **correcto**
C. Algoritmo de recubrimiento secuencial.
D. Algoritmo PRISM.


3. Indica cuáles de las siguientes afirmaciones son verdaderas:

A. Las reglas de clasificación predicen la clase. -> **correcto**
B. Las reglas de asociación predicen combinaciones de atributos o la propia
clase. -> **correcto**
C. Los algoritmos que aprenden reglas de asociación buscan combinaciones
de pares atributo-valor que ocurren con cierta frecuencia. -> **correcto**
D. Las reglas de asociación tienen el mismo objetivo que las reglas de
clasificación.


4. Si se quiere conocer el porcentaje de ejemplos que cumplen una regla respecto
del total de ejemplos, se ha de aplicar la medida de:
A. Cobertura.
B. Soporte. -> **correcto**
C. Confianza.
D. Cubierta.


5. Si se quiere conocer el porcentaje de ejemplos que cumplen una regla respecto
de todos los ejemplos que sólo cumplen el antecedente, se ha de aplicar la medida
de:
A. Cobertura.
B. Soporte.
C. Confianza.-> **correcto**
D. Cubierta.


6. ¿Cuáles de los siguientes algoritmos se puede emplear para el aprendizaje de
reglas de clasificación?
A. PRISM.
B. C4.5. -> **correcto**
C. Apriori.
D. ID3. -> **correcto**

**NOTA:**
- B. C4.5: Es un algoritmo muy conocido que se utiliza para construir árboles de decisión. A partir de un árbol de decisión, se pueden extraer fácilmente reglas de clasificación "si-entonces".

- D. ID3: Es otro algoritmo fundamental para la construcción de árboles de decisión, predecesor de C4.5, y también se utiliza para generar modelos de clasificación que pueden ser representados como reglas.


7. Indica cuál de las siguientes afirmaciones es correcta:
A. No es posible mapear árboles de decisión a reglas de clasificación.
B. Los algoritmos de recubrimiento secuencial aprenden una regla en cada
iteración. -> **correcto**
C. En cada iteración, el algoritmo de recubrimiento secuencial exige que la
regla cubra todos los ejemplos positivos.
D. Apriori es un algoritmo de recubrimiento secuencial.


8. Indica cuáles de las siguientes afirmaciones son correctas:
A. El procedimiento básico, para aprender una regla, utilizado en los
algoritmos de recubrimiento secuencial tiene como parámetro el conjunto de
todas las clases.
B. El procedimiento, básico para aprender una regla, utilizado en los
algoritmos de recubrimiento secuencial añade a la regla un único par atributo valor en cada iteración. -> **correcto**
C. El procedimiento de recubrimiento secuencial devuelve una única regla.
D. El algoritmo de recubrimiento secuencial elimina los ejemplos cubiertos por
la regla generada en cada iteración. -> **correcto**


9. Indica cuáles de las siguientes afirmaciones son correctas respecto al algoritmo
PRISM:
A. Es un algoritmo de recubrimiento secuencial. -> **correcto**
B. Utiliza la medida de precisión o confianza para generar las reglas. -> **correcto**
C. Parte de la regla más específica alcanzando la más general.
D. Es un algoritmo de generación de conjuntos de reglas de los más simples -> **correcto**

10. Indica cuáles de las siguientes afirmaciones son verdaderas respecto al
algoritmo apriori:
A. Genera ítem-sets. -> **correcto**
B. Utiliza la medida de confianza para evaluar las reglas obtenidas. -> **correcto**
C. No genera reglas sino ítem-sets.
D. Valora los ítem-sets generados mediante una medida de confianza.

## Videoclase 1. “A priori” y reglas de asociación

- El algoritmo Apriori puede ser considerado:
- Una forma de representación del conocimiento.
- Un modelo de búsqueda de relaciones en los datos.
- Un sistema de generación de reglas.
- Todas las anteriores son válidas. -> **correcto** 

- ¿Qué es un ítem-set?:
- Un conjunto de pares atributo-valor.

- El algoritmo Apriori tiene tres fases, que son:
- El algoritmo Apriori tiene dos fases.


- Al inicio del algoritmo Apriori buscamos que los pares ítem-set cumplan:
- Un nivel de cobertura mínimo.


- ¿Cuál de los siguientes supuestos reales podría ser codificado como un conjunto de reglas de asociación?
- Todos podrían ser codificados como reglas de asociación.

## Videoclase 2. PRISM y reglas de clasificación

- PRISM es un algoritmo de:
- Recubrimiento secuencial.

- PRISM está planteado de forma que pueda resolver:
- Ninguna de las anteriores.

- ¿Qué método utiliza PRISM para seleccionar la mejor restricción?:
- Se selecciona la mejor restricción en base a la confianza y en caso de empate se escoge la restricción de mayor cobertura.


- El algoritmo PRISM termina generando una regla cuando:
- No hay ejemplos negativos cubiertos por la regla.

- De los siguientes casos de uso, ¿cuáles podrían ser modelados por un sistema de generación de reglas de clasificación como PRISM?:
- Ninguno de los anteriores.

## Videoclase 3. Otros algoritmos de clasificación


- ¿En qué paradigma encuadramos los modelos de clasificación Naive Bayes, SVM y KNN?:
- Aprendizaje supervisado.

- Naive Bayes en un modelo de inteligencia artificial:
- Probabilístico => Se trata de un modelo probabilístico basado en la probabilidad condicionada.

- Las máquinas de vectores de soporte o SVM son un modelo de inteligencia artificial:
- De transformación de dimensionalidad.

- En el método de los K-vecinos, el parámetro K indica:
- El número de puntos más cercanos a un punto dado.

- Queremos sobre nuestra base de datos de clientes de una gran tienda de muebles, establecer asociaciones de preferencia de compra entre aquellos que adquieren un sillón motorizado. Podremos modelar nuestro problema mediante:
- Ninguna de las anteriores.

# Tema 5: Redes neuronales artificiales

1. Indica cuáles de las siguientes afirmaciones son correctas:
A. Las neuronas artificiales simulan el comportamiento de las neuronas biológicas. -> **correcto**
B. Las neuronas artificiales pueden tener varias salidas que toman valores diferentes.
C. Las neuronas artificiales pueden tener varias entradas que toman valores diferentes. -> **correcto**
D. Las entradas de las neuronas artificiales se ponderan con un peso. -> **correcto**

2. Selecciona las opciones correctas. En la fase de entrenamiento de una red
neuronal:
A. Se ajusta el número de capas de la red neuronal.
B. Se ajustan los pesos de los enlaces que conectan las neuronas. -> **correcto**
C. Se ajusta el número de neuronas por capa de la red neuronal.
D. Ninguna de las anteriores.

3. Indica cuál de las afirmaciones siguientes son correctas respecto a la regla de
aprendizaje del perceptrón:
A. Se utiliza para calcular las salidas de la red.
B. Utiliza la diferencia entre la salida real y la salida esperada para ajustar los pesos. -> **correcto**
C. Se puede establecer una tasa de aprendizaje en la regla que pondera la relevancia del último peso calculado. -> **correcto**
D. Se utiliza para ajustar los pesos de la red. -> **correcto**

4. Indica cuáles de las siguientes funciones pueden ser utilizadas como funciones
de activación en redes neuronales:
A. Función escalón. 
B. Función sigmoide. 
C. Función tangente hiperbólica.
D. Todas las anteriores son correctas. -> **correcto**

*Notas*: 
- A. Función escalón (Step function): Fue una de las primeras funciones de activación utilizadas, especialmente en el perceptrón original. Produce una salida binaria (por ejemplo, 0 o 1) si la entrada supera un umbral.

- B. Función sigmoide (Sigmoid function): También conocida como función logística, es muy común en redes neuronales, especialmente en las capas de salida para problemas de clasificación binaria, ya que comprime la entrada a un rango entre 0 y 1.

- C. Función tangente hiperbólica (Hyperbolic tangent function - tanh): Similar a la función sigmoide, pero comprime la entrada a un rango entre -1 y 1. A menudo se prefiere sobre la sigmoide en capas ocultas porque su salida está centrada en cero, lo que puede facilitar el entrenamiento.

5. Selecciona la opción más correcta. El funcionamiento de una red neuronal queda
determinado por:
A. El número de capas, número de neuronas y las conexiones entre
neuronas.
B. La función de activación, el número de capas, el número de neuronas y los
pesos entre las neuronas. -> **correcto**
C. El algoritmo de aprendizaje, la regla de aprendizaje, el número de capas,
número de neuronas y las conexiones entre neuronas.
D. El algoritmo de aprendizaje, la función de activación, el número de capas,
número de neuronas y las conexiones entre neuronas.

6. Indica cuáles de las siguientes afirmaciones son correctas:
A. Las redes neuronales multicapa son redes bidireccionales.
B. Las redes neuronales multicapa son redes asociativas.
C. Las redes neuronales multicapa son redes de alimentación hacia adelante. -> **correcto**
D. Las redes neuronales multicapa son redes unidireccionales -> **correcto**

**Notas** 
- C. Las redes neuronales multicapa son redes de alimentación hacia adelante.
    - Verdadero. Este es el tipo más común de red neuronal multicapa, donde la información fluye en una sola dirección, desde la capa de entrada, a través de una o más capas ocultas, hasta la capa de salida, sin bucles ni retroalimentación.

- D. Las redes neuronales multicapa son redes unidireccionales.
    - Verdadero. Esta afirmación es equivalente a la anterior. "Unidireccional" significa que la información solo fluye en una dirección (hacia adelante), lo cual es una característica fundamental de las redes de alimentación hacia adelante.

7. Indica cuáles de las siguientes afirmaciones son correctas respecto de las redes
multicapa de retropropagación:

A. Todas las neuronas de una capa se conectan con todas las neuronas de
las capas posteriores.

B. Para el ajuste de los pesos se utiliza el gradiente del error.  -> **correcto**
=> Verdadero. La retropropagación (backpropagation) es el algoritmo fundamental utilizado para entrenar redes neuronales multicapa. Su función principal es calcular el gradiente de la función de error (o pérdida) con respecto a cada peso de la red. Este gradiente indica la dirección y magnitud en la que los pesos deben ajustarse para minimizar el error, y luego se utiliza un algoritmo de optimización (como el descenso de gradiente) para realizar dicho ajuste.

C. Para el ajuste de los pesos se utiliza el error cuadrático medio.
D. Se utilizan las mismas fórmulas para calcular los pesos relativos a las
neuronas de salida y los relativos a las neuronas ocultas.

8. Indica cuáles de las siguientes afirmaciones son correctas respecto de las redes
recurrentes:
A. Emulan la capacidad de almacenamiento de la memoria humana.
B. Emulan la capacidad de asociación de la memoria humana.
C. Las salidas de la red alimentan las entradas.
D. La red Hopfield es una red recurrente.
*NOTA*
- Puede ser opcion multiple GEMI las marca todas toca investigar mas

9. Indica cuáles de las siguientes afirmaciones son correctas respecto de las redes
Hopfield:
A. El estado de la red viene determinado por los pesos de los enlaces.
B. El objetivo es que la red sea capaz de almacenar unos determinados
estados. -> **correcto**
C. El objetivo es que la red sea capaz de almacenar unas memorias
fundamentales. -> **correcto**
D. No es preciso comprobar que la red sea capaz de almacenar memorias
fundamentales.

**Notas** 
- B. El objetivo es que la red sea capaz de almacenar unos determinados estados.
    - Verdadero. Las redes de Hopfield son un tipo de red neuronal recurrente utilizadas principalmente como sistemas de memoria asociativa. Su objetivo es almacenar un conjunto de patrones (o "estados") como atractores estables en su dinámica, de modo que cuando se presenta una entrada ruidosa o parcial de uno de esos patrones, la red converge al patrón almacenado más cercano.

- C. El objetivo es que la red sea capaz de almacenar unas memorias fundamentales.
    - Verdadero. Esta afirmación es sinónima de la anterior. Los "estados determinados" o "patrones" que una red de Hopfield está diseñada para almacenar y recuperar se conocen comúnmente como "memorias fundamentales".

10. Indica cuáles de las siguientes afirmaciones son correctas respecto de las redes
Hopfield:
A. Son redes bidireccionales asociativas. -> **correcto**
B. Se utilizan en reconocimiento de imágenes. -> **correcto**
C. Siempre alcanzan un estado estable correspondiente a una memoria
fundamental.
D. Con pocas neuronas y conexiones son capaces de almacenar una gran
cantidad de información

**Notas**
- A. Son redes bidireccionales asociativas.
    - Verdadero. Las redes de Hopfield son un tipo de red neuronal recurrente en la que las conexiones entre las neuronas suelen ser simétricas (bidireccionales). Su función principal es actuar como una memoria asociativa, es decir, son capaces de almacenar patrones y recuperarlos a partir de entradas parciales o ruidosas.

- B. Se utilizan en reconocimiento de imágenes.
    - Verdadero. Aunque hoy en día redes más avanzadas (como las CNN) son dominantes, las redes de Hopfield fueron conceptualmente importantes y se aplicaron en el pasado para tareas relacionadas con el reconocimiento de patrones y la compleción de imágenes, donde se busca restaurar una imagen completa a partir de una versión incompleta o ruidosa.


## Videoclase 1. Bioinspiración de las RNA
- ¿Qué implica que las redes neuronales artificiales sean bioinspiradas?:
- Emulan un comportamiento presente en la naturaleza, como el del cerebro humano.

- ¿Qué función realizan las dendritas de las neuronas
- Reciben el impulso nervioso. => Las dendritas son las partes de la neurona encargadas de recibir el impulso nervioso


- ¿Con qué parte de la neurona podríamos identificar la salida de una red neuronal artificial?:
- Axón -> El axón neuronal es el que envía la señal a otras neuronas o a efectores como los músculos, trazando un símil posible con la salida de una red neuronal. 1

- ¿Cuáles de las siguientes afirmaciones no puede ser considerada ventaja de una red neuronal artificial?:
- Necesidad muy escasa de recurso computacional. => Por lo general, las redes neuronales artificiales tienen unos requisitos computacionales considerables.

- ¿Cuáles de las siguientes afirmaciones pueden ser consideradas desventajas de una red neuronal artificial?
- Necesidad de gran cantidad de datos.
- Dificultad de interpretación del proceso para llegar a los resultados.
-  Cierta tendencia al sobreajuste.
-  Todas las anteriores. -> *CORRECTO*

## Videoclase 2. Tipología de RNA
- La red neuronal más longeva es:
- El perceptrón.

- Las funciones de activación en las redes neuronales feedforward pueden ser:
- Todas las anteriores -> Tanto la sigmoide, como la tangente hiperbólica y arco tangente, son funciones que pueden ser usadas en las RNA feedforward.

- El mecanismo de retropropagación transmite el error recogido a la salida de la red neuronal únicamente hacia la capa oculta en conexión directa con la capa de salida:
- Falso. Se redirige a toda la red =>  El error se transmite a toda la red neuronal para provocar una nueva actualización de pesos en función de los resultados obtenidos.

- Si nuestro dataset está formado por series temporales de temperaturas recogidas a lo largo de una semana, un modelo óptimo de red neuronal para resolver un problema de predicción sería:
- Una red neuronal recurrente.

- Una convolución en una red neuronal convolucional es:
- La aplicación de un filtro o máscara para extracción de características en imágenes.

## Videoclase 3. Casos de uso RNA
- ¿En qué paradigma encuadramos las redes neuronales artificiales?:
- Ninguna de las anteriores.

- ¿Qué tipo de problema tendríamos que afrontar para predecir la tensión arterial de un paciente en base a un conjunto de características del mismo?:
- Clasificación.

- ¿Qué tipo de RNA implementaríamos para un vehículo autónomo que necesita soporte a la toma de decisiones mediante reconocimiento de patrones en imágenes en tiempo real captadas en la propia vía?
- Red neuronal convolucional.

- Contamos con una base de clientes etiquetada. El predecir mediante una red neuronal si un cliente de un préstamo bancario amortizará el mismo en tiempo o no podría ser resuelto mediante técnicas de:
- Clasificación.

- Deseamos simular el comportamiento de una máquina de clasificación de monedas mediante una red neuronal, ¿es posible?:
- Sí, mediante una red neuronal feedforward que pueda predecir la clase de una moneda determinada a través de datos aprendidos.

# TEMA 6:  Deep learning

1. ¿Cuáles de las siguientes ramas pertenecen al aprendizaje automático clásico?
A. Aprendizaje supervisado. -> **correcto**
B. Aprendizaje ensemble. -> **correcto**
C. Deep Learning.
D. Aprendizaje por refuerzo. -> **correcto**

**Notas**

A. Aprendizaje supervisado: Es una de las ramas fundamentales y más clásicas del aprendizaje automático, donde el modelo aprende de datos etiquetados (input-output pairs) para hacer predicciones.

B. Aprendizaje ensemble: Las técnicas ensemble (como Random Forest, Bagging o Boosting) combinan múltiples modelos de aprendizaje automático clásico para mejorar la robustez y la precisión. Se consideran una parte importante y avanzada del aprendizaje automático clásico.

D. Aprendizaje por refuerzo: Es una rama principal del aprendizaje automático donde un agente aprende a tomar decisiones a través de la interacción con un entorno para maximizar una recompensa. Sus fundamentos se establecieron hace varias décadas.

2. Indica todas las respuestas correctas. Los autoencoders:
A. Siempre tienen un número par de capas
B. Son redes neuronales asimétricas.
C. Se pueden emplear para la compresión de imágenes. -> **correcto**
D. Son un tipo de redes convolucionales profundas.

3. Señala todas las respuestas correctas. Los clasificadores Naïve Bayes:
A. Son un tipo de redes de creencias. -> **correcto**
B. Son un tipo de redes Bayesianas. -> **correcto**
C. Se basan en que las características son fuertemente dependientes entre sí.
D. Tienen un número impar de capas de neuronas recurrentes.


**Notas** 
- A. Son un tipo de redes de creencias.
    - Verdadero. Las redes de creencias son otro nombre para las redes Bayesianas. Los clasificadores Naïve Bayes son la forma más simple de red Bayesiana, con una estructura de red específica donde todos los nodos de características son hijos de un único nodo de clase y no hay conexiones entre los nodos de características.

- B. Son un tipo de redes Bayesianas.
    - Verdadero. Esta es la clasificación fundamental de los clasificadores Naïve Bayes. Se derivan del teorema de Bayes y representan relaciones probabilísticas condicionales entre variables.

4. Señala todas las respuestas correctas. Las redes generativas antagónicas:
A. Están siempre formadas por una red convolucional y una red deconvolucional.
B. Pueden estar formadas por una red convolucional y una red prealimentada. -> **correcto**
C. Están formadas por una red generativa y una red discriminativa. -> **correcto**
D. No son apropiadas para aplicaciones Deepfake al no ser redes profundas.

**Notas**
- B. Pueden estar formadas por una red convolucional y una red prealimentada.
    - Verdadero. Es posible que una de las redes (generador o discriminador) sea de tipo convolucional (común en tareas de imagen) y la otra sea una red prealimentada (feedforward) más tradicional (que puede ser densa o también convolucional si es profunda). Lo importante es que haya dos redes que desempeñen los roles de generador y discriminador.

- C. Están formadas por una red generativa y una red discriminativa.
    - Verdadero. Esta es la definición fundamental y el principio central de las GANs. Consisten en una red generativa (el "generador") que crea datos sintéticos y una red discriminativa (el "discriminador") que intenta distinguir entre los datos reales y los generados. Ambas redes se entrenan en un juego de suma cero.


5. Señala todas las respuestas incorrectas. Las técnicas de aprendizaje por
refuerzo:
A. Están siempre basadas en algoritmos evolutivos. -> **correcto**
B. Pueden aplicarse en el ámbito de los vehículos autónomos.
C. Nunca requieren un dataset de entrenamiento, pues no necesitan modelos. -> **correcto**
D. Se pueden aplicar para crear software que comercie de forma
automatizada.


6. En un escenario de aprendizaje por refuerzo, un agente actúa con una tasa de
exploración igual a 0.9 en un momento dado. Señala las respuestas incorrectas:

A. En el estado actual, el agente explorará el 90 % del entorno y, tras ello,
dará por finalizada la iteración. -> **correcto**
B. Existe una probabilidad del 10 % de que el agente decida explorar el
entorno. -> **correcto**
C. Existe una probabilidad del 90 % de que el agente no decida explotar las
recompensas existentes en el entorno por medio de sus acciones.
D. Decidirá explorar el entorno con un 90 % de probabilidades solo si esta es
su primera iteración. -> **correcto**


7. Señala las respuestas correctas. Las memorias de largo y corto plazo (LSTM –
long and short-term memories):
A. Surgieron para mejorar los perceptrones multicapa, incrementando el
número de capas ocultas.
B. Tienen celdas especiales en las que un valor puede ser almacenado, leído
o restablecido, por medio de puertas de entrada, salida y olvido. -> **correcto**
C. Son menos expresivas que su variación las Gated recurrent units (GRU).
D. Son apropiadas para aplicaciones de reconocimiento de voz. -> **correcto**

8. Señala todas las respuestas correctas:
A. TensorFlow es una librería de redes neuronales utilizada como alternativa
a Keras.
B. TensorFlow solo puede ser empleado bajo lenguaje Python.
C. TensorFlow Lite permite la aplicación de redes neuronales en dispositivos
móviles. -> **correcto**
D. TensorFlow es una librería específica para resolver problemas de
mecánica mediante análisis numérico.


9. Señala todas las respuestas correctas:
A. El algoritmo Q-Learning puede trabajar con datos de entrenamiento
etiquetados y no etiquetados.
B. El algoritmo Q-Learning presenta un problema de sobreestimación del valor
de la acción en algunos escenarios. -> **correcto**
C. El algoritmo Double Q-Learning utiliza siempre dos redes neuronales con la
misma arquitectura de capas. -> **correcto**
D. El algoritmo Double Q-Learning presenta un problema de sobreestimación
del valor de la acción en todos los escenarios.

**notas**

- B. El algoritmo Q-Learning presenta un problema de sobreestimación del valor de la acción en algunos escenarios.
    - Verdadero. El Q-Learning estándar tiende a sobreestimar los valores de las acciones (Q-values). Esto ocurre porque en la fase de actualización se toma el valor máximo de Q del siguiente estado, lo que introduce un sesgo optimista, especialmente en entornos con recompensas estocásticas o cuando las estimaciones de Q-values son ruidosas.

- C. El algoritmo Double Q-Learning utiliza siempre dos redes neuronales con la misma arquitectura de capas.
    - Verdadero. El Double Q-Learning (y su adaptación a redes neuronales, Double DQN) resuelve el problema de sobreestimación del Q-Learning utilizando dos estimadores de valor de acción (dos redes neuronales o dos tablas Q separadas en el caso tabular). Una se usa para seleccionar la siguiente acción y la otra para evaluar el valor de esa acción. Estas dos redes se mantienen con la misma arquitectura para que representen dos estimaciones independientes pero consistentes de la función Q.

10. Señala todas las respuestas correctas:
A. Las redes deconvolucionales pueden aplicarse para obtener una imagen
sintética a partir de una etiqueta. -> **correcto**
B. Las redes gráficas inversas convolucionales profundas (DCIGN) son
autoencoders variacionales en los que cuales se utilizan dos redes
deconvolucionales.
C. Las redes convolucionales no son aptas para aplicaciones de
reconocimiento facial.
D. En las redes convolucionales la última etapa de convolución se conecta
siempre a una etapa deconvolucionadora para obtener las probabilidades de
que una entrada pertenezca a una clase

**Notas** 
- A. Las redes deconvolucionales pueden aplicarse para obtener una imagen sintética a partir de una etiqueta.
    - Verdadero. Las capas "deconvolucionales" (o más precisamente, capas de convolución transpuesta) se utilizan comúnmente en redes generativas (como los generadores en las GANs o los decodificadores en los Autoencoders Variacionales) para convertir representaciones de baja dimensión (como un vector latente o una etiqueta codificada) en imágenes de mayor resolución. Por ejemplo, se puede entrenar una red para generar la imagen de un "gato" a partir de la etiqueta "gato".


## Videoclase 1. Tipología redes neuronales convolucionales y su aplicación práctica
- La idea de base tras un modelo convolucional es:
- La reducción del tamaño de las imágenes preservando sus características.

- ¿Cuáles de las siguientes capas no se encuentran en un modelo convolucional?:
- Todas se encuentran en una red neuronal convolucional. => La red puede contener capas de muestreo, entrada y salida, así como convolucionales.

- ¿En qué consiste el overfitting?:
- Pérdida de capacidad generalización por parte del modelo. => El overfitting es la pérdida de capacidad de generalización por parte del modelo, que «memoriza» los patrones que encuentra en los datos de entrenamiento.

- Cuál de las siguientes técnicas no es considerada como de regularización en una red neuronal convolucional:
- Reducción del tamaño de la imagen. => Reducir el tamaño de una imagen no es una técnica de regularización válida, además, dificultará al modelo poder extraer características relevantes.

- ¿Qué librería de inteligencia artificial nos permite la configuración de arquitecturas de red neuronal convolucional?:
- TensorFlow.

## Videoclase 2. Autoencoders

- La idea de base tras un autoencoder es:
- La reducción de los datos preservando sus características.  => El planteamiento de los autoencoders se basa en la reducción de la información de entrada para aprender lo fundamental de la misma.

- ¿Qué proporción mantienen las capas de entrada y salida de un autoencoder?:
- Deben ser iguales. => La entrada y la salida de un autoencoder deben ser del mismo tamaño, ya que el proceso de decodificación devuelve el tamaño original a la entrada.

- ¿Cuál de las siguientes tipologías no es considerada para los autoencoders?:
- Integrado. => Las tipologías más comunes de autoencoder son apilado, variacional, disperso y de adición de ruido.

- ¿Cuál de los siguientes casos de uso no podría ser modelado mediante un autoencoder?:
- Predicción del precio de una vivienda sobre un conjunto de datos etiquetados.

- ¿Qué librería de inteligencia artificial nos permite la creación de autoencoders?:
- TensorFlow

## Videoclase 3. Aprendizaje por refuerzo

- ¿Qué cambio de paradigma plantea el aprendizaje por refuerzo?:
- De minimizar el error a maximizar la recompensa => El aprendizaje supervisado plantea como máxima la minimización del error cometido, mientras que el aprendizaje por refuerzo en enfoca en obtener recompensas máximas sobre un entorno.

- ¿Cuáles de los siguientes conceptos no relacionan a agente y ambiente en un entorno de aprendizaje por refuerzo?:
- Función de activación. => La función de activación es propia de redes neuronales, no del paradigma del aprendizaje por refuerzo.

- El aprendizaje por refuerzo sigue un enfoque:
- Model-free. => l aprendizaje por refuerzo no se basa en la interacción con un modelo de datos y predicciones sobre instancias conocidas, si no sobre la relación con el ambiente. 

- Si deseamos optimizar nuestro sistema de aprendizaje por refuerzo, deberemos potenciar:
- El equilibrio entre técnicas de exploración y de explotación =< >

- ¿Cuál de los siguientes supuestos no se podría plantear mediante el paradigma del aprendizaje por refuerzo?:
- Clasificar un automóvil entre varias gamas posibles.




# Tema 7: Clustering. Agrupamiento o clasificación no supervisada
1. Indica cuáles de las siguientes afirmaciones son correctas:
A. El clústering permite agrupar objetos similares entre sí. -> **correcto**
B. El clústering es un método de aprendizaje supervisado.
C. El clústering puede resultar útil como etapa previa a la aplicación de un
método de aprendizaje supervisado. -> **correcto**
D. El clústering da lugar a árboles de decisión.

**Notas** 
- A. El clústering permite agrupar objetos similares entre sí.
    - Verdadero. Esta es la definición fundamental del clustering: organizar un conjunto de objetos en grupos (clusters) de tal manera que los objetos en el mismo grupo sean más similares entre sí que a los de otros grupos.

- C. El clústering puede resultar útil como etapa previa a la aplicación de un método de aprendizaje supervisado.
    - Verdadero. El clustering se utiliza a menudo como un paso de preprocesamiento. Por ejemplo, puede ayudar a segmentar el conjunto de datos en subgrupos homogéneos. Luego, se pueden aplicar modelos de aprendizaje supervisado específicos para cada subgrupo, lo que puede mejorar la precisión y el rendimiento general. También puede usarse para la reducción de dimensionalidad o la detección de anomalías antes de una tarea supervisada.

2. Indica cuál de las siguientes afirmaciones es correcta:
A. Diferentes algoritmos de clústering dan lugar a los mismos agrupamientos
finales.
B. Los algoritmos jerárquicos aglomerativos generan clústeres pequeños que
iterativamente van agrupando entre sí. -> **correcto**
C. Los agrupamientos solapados se obtienen aplicando algoritmos de
clústering jerárquicos.
D. Los algoritmos de clústering no permiten detectar datos anómalos.

3. Si se pretende generar agrupamientos exclusivos se ha de aplicar:
A. Algoritmo Fuzzy C-means.
B. Algoritmo k-means. -> **correcto**
C. Algoritmo EM.
D. Ninguno de los anteriores.

4. Si se pretende crear agrupamientos con formas irregulares se ha de aplicar:
A. Algoritmo k-means.
B. Algoritmos basados en densidad. -> **correcto**
C. Algoritmo Fuzzy C-means.
D. Ninguno de los anteriores

**Notas** 
- Algoritmos basados en densidad (como DBSCAN - Density-Based Spatial Clustering of Applications with Noise): Estos algoritmos definen los clústeres como regiones densas de puntos de datos, separadas por regiones de menor densidad. No asumen formas predefinidas para los clústeres (como esféricas o elípticas), lo que les permite descubrir agrupaciones de formas arbitrarias e irregulares, incluso si están anidadas o entrelazadas.

Analicemos las otras opciones:

A. Algoritmo k-means: K-means tiende a formar clústeres de forma esférica o convexa y de tamaño similar. No es efectivo para identificar clústeres con formas irregulares o no convexas.

C. Algoritmo Fuzzy C-means: Similar a K-means, Fuzzy C-means (que permite la pertenencia a múltiples clústeres) también se basa en centroides y tiende a producir clústeres de formas esféricas o elípticas, por lo que tampoco es adecuado para formas irregulares.

5. Si se pretende modelar los clústeres mediante una función probabilista se ha de
aplicar:
A. Algoritmo Fuzzy C-means.
B. Algoritmo k-means.
C. Algoritmo EM. -> **correcto**
D. Ninguno de los anteriores.

**Notas**
El Algoritmo EM es un algoritmo iterativo que se utiliza comúnmente para encontrar los parámetros de modelos probabilísticos, como los Modelos de Mezcla Gaussiana (GMM). En el clustering basado en GMM, se asume que los datos provienen de una mezcla de varias distribuciones de probabilidad (típicamente gaussianas), y cada distribución representa un clúster. El algoritmo EM estima los parámetros de estas distribuciones (media, covarianza y los pesos de cada componente de la mezcla) y la probabilidad de que cada punto de dato pertenezca a cada clúster. Esto encaja directamente con la idea de modelar clústeres mediante una función probabilista.

6. Si se mide la similitud entre dos clústeres mediante la medida de enlace
completo:
A. Se tiene en cuenta la similitud entre los dos puntos más cercanos de
ambos clústeres.
B. Se tiene en cuenta la similitud entre los dos puntos más lejanos de ambos
clústeres. -> **correcto**
C. Se tiene en cuenta la distancia promedio que existe entre todos los puntos
de ambos clústeres.
D. Se tiene en cuenta la distancia entre los centroides de ambos clústeres.


**Notas** 
El método de enlace completo define la distancia entre dos clústeres como la distancia máxima entre cualquier par de puntos, donde un punto pertenece al primer clúster y el otro punto pertenece al segundo clúster. Esto significa que la distancia entre los clústeres está dominada por los "vecinos más lejanos" de los dos clústeres.

7. Indica cuáles de las siguientes afirmaciones, respecto del algoritmo k-means, son
correctas:
A. El algoritmo k-means asigna los objetos a los clústeres en función de su
cercanía al centroide de cada clúster. -> **correcto**
B. En cada iteración el algoritmo k-means mantiene fijos los centroides.
C. Es un algoritmo basado en densidad.
D. En cada iteración el algoritmo recalcula los centroides -> **correcto**

**Notas**
- A. El algoritmo k-means asigna los objetos a los clústeres en función de su cercanía al centroide de cada clúster.
    - Verdadero. Esta es la primera etapa fundamental de cada iteración del algoritmo k-means: asignar cada punto de datos al clúster cuyo centroide es el más cercano.

- D. En cada iteración el algoritmo recalcula los centroides.
    - Verdadero. Después de la fase de asignación de puntos a los clústeres, el algoritmo k-means recalcula los centroides de cada clúster tomando la media de todos los puntos que han sido asignados a ese clúster en la iteración actual. Este proceso se repite hasta que los centroides ya no cambian significativamente.

8. Indica cuáles de las siguientes afirmaciones, respecto a los algoritmos de
clústering jerárquicos, son correctas:
A. Se utiliza la medida de utilidad de la categoría para realizar particiones.
B. En un algoritmo divisorio inicialmente a cada clúster se le asigna un objeto.
C. Utilizan una matriz de similitud para llevar a cabo la decisión de agrupar
clústeres. -> **correcto**
D. Se puede utilizar la medida de enlace promedio para calcular las distancias
entre clústeres. -> **correcto**

**Notas** 
- C. Utilizan una matriz de similitud para llevar a cabo la decisión de agrupar clústeres.
    - Verdadero. Los algoritmos de clustering jerárquicos, ya sean aglomerativos o divisorios, dependen fundamentalmente de una matriz de distancias o similitudes que contenga las distancias (o similitudes) entre todos los pares de objetos o entre clústeres. Esta matriz se actualiza en cada paso para decidir qué clústeres fusionar o dividir.

- D. Se puede utilizar la medida de enlace promedio para calcular las distancias entre clústeres.
    - Verdadero. El enlace promedio (Average Linkage) es uno de los métodos de "enlace" o "linkage" más comunes utilizados en el clustering jerárquico. Define la distancia entre dos clústeres como la distancia promedio entre todos los pares de puntos de los dos clústeres (donde cada par consiste en un punto de un clúster y un punto del otro). Otros métodos incluyen enlace simple, enlace completo y el método de Ward.


9. Indica cuáles de las siguientes afirmaciones son correctas respecto al algoritmo
EM:
A. Es un algoritmo basado en densidades.
B. Tiene como base el modelo estadístico denominado mezclas finitas. -> **correcto**
C. El objetivo es conocer los parámetros de una función probabilista general
que modela los clústeres. -> **correcto**
D. En la fase de esperanza se calculan las probabilidades de pertenencia de
las instancias a los clústeres. -> **correcto**

**Notas** 
- B. Tiene como base el modelo estadístico denominado mezclas finitas.
    - Verdadero. El algoritmo EM es un método iterativo utilizado para encontrar estimaciones de máxima verosimilitud de los parámetros en modelos estadísticos donde las variables dependen de variables latentes no observadas. Es fundamental para entrenar modelos de mezclas finitas, como los Modelos de Mezcla Gaussiana (GMM), donde se asume que los datos provienen de una combinación de varias distribuciones de probabilidad.

- C. El objetivo es conocer los parámetros de una función probabilista general que modela los clústeres.
    - Verdadero. En el contexto del clustering, el EM busca estimar los parámetros (como las medias, covarianzas y los pesos de mezcla) de las distribuciones de probabilidad que definen cada clúster, de modo que la combinación de estas funciones probabilistas modela la distribución general de los datos.

- D. En la fase de esperanza se calculan las probabilidades de pertenencia de las instancias a los clústeres.
    - Verdadero. La fase de Esperanza (E-step) del algoritmo EM consiste en calcular las probabilidades (o responsabilidades) de que cada punto de dato pertenezca a cada uno de los clústeres, utilizando los parámetros actuales del modelo.

10. Indica cuáles de las siguientes afirmaciones son correctas respecto al algoritmo
Fuzzy C-means:
A. Una instancia puede pertenecer a más de un clúster si se aplica el
algoritmo Fuzzy C-means. -> **correcto**
B. Las variables de entrada son conjuntos difusos.
C. Los clústeres se modelan como conjuntos difusos. -> **correcto**
D. Permite obtener clústeres jerárquicos.

**Notas* 
- A. Una instancia puede pertenecer a más de un clúster si se aplica el algoritmo Fuzzy C-means.
    - Verdadero. Esta es la característica distintiva de Fuzzy C-means. A diferencia de los algoritmos de clustering "duro" (como K-means), Fuzzy C-means asigna a cada punto de dato un grado de pertenencia a cada clúster, lo que permite que una instancia tenga un nivel de membresía en múltiples clústeres simultáneamente.

- C. Los clústeres se modelan como conjuntos difusos.
    - Verdadero. En Fuzzy C-means, los clústeres no son particiones discretas, sino que se interpretan como conjuntos difusos. Cada punto de dato tiene un grado de pertenencia (un valor entre 0 y 1) a cada uno de estos conjuntos difusos, que representan los clústeres.

## Videoclase 1. Descubrimiento de patrones mediante clustering
- ¿En qué paradigma encuadramos las técnicas de clustering?
- Aprendizaje supervisado.

- ¿Cuál es la filosofía de las técnicas de clustering?
- Agrupación de objetos con características comunes.

- ¿Cuáles de las siguientes tipologías no está considerada como de agrupamiento?
- Todas las anteriores. => Las técnicas de agrupamiento se pueden dividir en exclusivas, jerárquicas, aglomerativas, y además solapadas y probabilistas.

- En las técnicas de clustering se asigna un objeto a un clúster determinado cuando
- El valor del objeto coincide con algún valor de objeto dentro del clúster.

- ¿Cuál de los siguientes problemas no podría ser resuelto mediante técnicas de clustering?
- Predecir la longitud de un vídeo que más puede interesar a un usuario.


## Videoclase 2. K-means
- El algoritmo k-means es una técnica
- De agrupamiento exclusivo.

- ¿Qué determina el valor de K en el algoritmo K-means?
- El número de grupos para el algoritmo.

- ¿Cuál de los siguientes conceptos no puede ser considerada una fortaleza de k-means?
- Independencia del dominio.

- ¿Cuál de los siguientes conceptos es considerado una debilidad de k-means?
- Aleatoriedad. => k-means presenta un componente de aleatoriedad que puede suponer el no encontrar el conjunto óptimo de clústeres.

- El algoritmo k-means
- Ninguna de las anteriores. =>  k-means podría, sobre un conjunto de datos no etiquetado, establecer una serie de grupos o categorías que podrían ser consideradas como las clases de salida de un algoritmo de aprendizaje supervisado.

- Metodo Euclidiano => calculo de la distancia de tres puntos solo es el calculo de la hipotenusa de un triangulo  


## Videoclase 3. Agrupamiento jerárquico
- El agrupamiento jerárquico aglomerativo
- Crea grupos de forma ascendente, hasta que incluye todos los elementos en un único grupo.

- El agrupamiento jerárquico divisivo
- Crea grupos de forma descendente, hasta que consigue un único grupo con todos los elementos.

- ¿Cómo se denomina el gráfico que ilustra un agrupamiento jerárquico?
- Histograma.

- En el paso inicial de un algoritmo de agrupamiento jerárquico divisivo
- Se asigna cada elemento a un grupo.

- ¿Qué librería de inteligencia artificial contiene los métodos de agrupamiento jerárquico?
- Scikit Learn.


# Tema 8:Sistemas de recomendación

1. Los sistemas que utilizan valoraciones de los usuarios para recomendar contenidos emplean técnicas de:
A. Filtrado demográfico.
B. Filtrado colaborativo. -> **Correcto**
C. Filtrado basado en contenidos.
D. Filtrado basado en usuarios.

2. Los sistemas que utilizan información descriptiva de los contenidos para
recomendar contenidos emplean técnicas de:
A. Filtrado demográfico.
B. Filtrado colaborativo. -> **Correcto**
C. Filtrado basado en contenidos.
D. Filtrado basado en usuarios.

3. Indica **cuáles** de las siguientes afirmaciones son correctas:
A. Se pueden utilizar árboles de decisión o reglas inducidas para representar
el perfil del usuario en un sistema recomendador. -> **Correcto**
B. Algunos sistemas recomendadores utilizan técnicas de clústering para
generar grupos de usuarios con perfil similar. -> **Correcto**
C. Las técnicas de clústering no son utilizadas por los sistemas
recomendadores.
D. Los sistemas de recomendación nunca solicitan información al usuario de
manera explícita.

4. Indica **cuáles** de las siguientes afirmaciones son correctas:
A. Los sistemas de filtrado colaborativo basado en ítems calculan la similitud
entre ítems.  -> **Correcto**
B. Los sistemas de filtrado colaborativo basado en ítems calculan la similitud
entre usuarios.
C. Los sistemas de filtrado basado en contenidos calculan la similitud entre
ítems.  -> **Correcto**
D. Los sistemas de filtrado colaborativo basado en usuarios calculan la
similitud entre ítems.

5. Slope One es un algoritmo empleado en los sistemas de:
A. Filtrado demográfico.
B. Filtrado colaborativo basado en usuarios.
C. Filtrado basado en contenidos.
D. Filtrado colaborativo basado en ítems. -> **Correcto**

6. La función de predicción de la valoración de un ítem en el algoritmo Slope One se
basa en:
A. La media de valoraciones dadas al ítem por los usuarios.
B. La media de la diferencia de valoraciones entre ítems. -> **Correcto**
C. La mediana de valoraciones dadas al ítem por los usuarios.
D. El valor máximo de la diferencia de valoraciones entre ítems

7. Marca las **frases que son correctas** respecto al algoritmo de filtrado colaborativo
ítem a ítem:
A. Se basa en encontrar ítems similares.-> **Correcto**
B. Se basa en encontrar usuarios similares.
C. Se basa en metadatos de los ítems.
D. Se basa en datos binarios como las adquisiciones o no adquisiciones de
los ítems por parte de los usuarios.-> **Correcto**

8. ¿Qué sistemas presentan problemas para recomendar ítems recientemente
incorporados al sistema?
A. Filtrado colaborativo basado en usuarios.-> **Correcto**
B. Filtrado basado en contenidos.
C. Filtrado colaborativo basado en ítems.-> **Correcto**
D. Ninguno de los anteriores.


9. Indica cuáles de las siguientes afirmaciones son correctas respecto al modelo
TF-IDF.
A. Es un modelo utilizado en los sistemas recomendadores basados en
contenidos. -> **Correcto**
B. Utiliza la similitud del coseno para medir la similitud entre documentos. -> **Correcto**
C. Utiliza la función TF-IDF para calcular la similitud entre documentos.
D. Favorece a los documentos largos frente a los cortos.

10. Algunos problemas que los recomendadores basados en contenido presentan
son:
A. Al usuario no siempre le interesan los ítems similares. -> **Correcto**
B. Cuando un ítem no está valorado no es recomendado.
C. No tienen en cuenta información subjetiva. -> **Correcto**
D. No puede ofrecer información a usuarios atípicos, que no son similares a
otros usuarios.

## Videoclase 1. Sistemas de recomendación colaborativa
- En el filtrado colaborativo basado en usuarios
    - Se recomienda contenido similar a los ítems que han recomendado otros usuarios con características similares. => El filtrado colaborativo establece recomendaciones para un usuario basadas en la similitud con otros usuarios que previamente han recomendado ese contenido.

- Las técnicas de cálculo de similitud, como la del coseno, pueden ser aplicadas a
    - Tanto cálculo de similitud entre ítems como usuarios. => La medida coseno puede ser considerada tanto para cálculo de similitud entre ítems, como para cálculo de similitud entre usuarios.

- En un sistema SLOPE-ONE, si únicamente tenemos dos usuarios y dos ítems, habiendo valorado el usuario 1 el primer ítem 8/10 y el segundo 9/10 ¿Qué valoración haría el usuario 2 del segundo ítem si ha valorado el primero con 7/10?
    - 8/10. => El algoritmo establece el cálculo del valor faltante como el cociente entre la suma de todas las diferencias en valoraciones entre ítem 2 e ítem 1 y el número de usuarios cuya valoración es conocida, sumado a la valoración conocida del usuario.

- El algoritmo ítem a ítem comienza con una tabla donde para cada usuario y una serie de contenidos, tenemos si el usuario recomienda dicho contenido
    - Falso, el algoritmo comienza con una tabla de ítems y los ítems similares. => El primer paso del algoritmo ítem a ítem, es la recogida en una tabla donde para cada usuario y una serie de contenidos, marcamos si el usuario recomienda dicho contenido.

- Los sistemas de recomendación colaborativa:
    - Están dentro del paradigma del aprendizaje difuso. => Podemos considerar los sistemas de recomendación colaborativa dentro del aprendizaje supervisado, ya que contamos con un conjunto de datos etiquetado en base a preferencias de usuario

## Video clase 2: 
- Un sistema de recomendación basada en contenido
- Ubica su foco sobre la representación de los contenidos.
  
- En un sistema de recomendación basada en contenido, ¿qué ítems se recomiendan a un usuario que previamente ha adquirido un ítem?
- Aquellos que hayan adquirido usuarios que adquirieron ítems similares.

- A grandes rasgos, ¿qué plantea la técnica VSM Vector Space Model?
- Estructuración de información a partir de su representación vectorial.

- El método TF-IDF podría ser utilizado para
- Todas las anteriores.

- Los sistemas de recomendación basada en contenidos
- Ninguna de las anteriores.

## Videoclase 3. Sistemas de recomendación híbridos  
- En la actualidad, los sistemas de recomendación híbridos
- Mejoran las características de los sistemas de recomendación colaborativos o basada en contenidos.

- ¿Cuál de las siguientes no es una tipología de hibridación?
- Sistemas entrelazados. =Los sistemas híbridos de recomendación de contenidos se dividen en ponderados, conmutados, mixtos, combinados, en cascada y meta-recomendadores.

- ¿En cuáles de los siguientes tipos de sistema de recomendación híbrida no influye el orden en el que se plantean los distintos sistemas componentes?
- En cascada.

- En un sistema de recomendación mixto
- Se presentan varias recomendaciones al mismo tiempo.

- ¿Qué tienen en común las plataformas como Amazon, Netflix y Spotify?
- Requieren de modelos de alta eficiencia para aportar soluciones rápidas y realistas a sus usuarios. => La eficiencia es la máxima de los sistemas de recomendación de las principales plataformas, para intentar mantener al usuario y establecer recomendaciones óptimas.




## Videoclase 3. Lógica e inferencia difusa
- En la teoría de conjuntos tradicional, la pertenencia de un elemento a un conjunto se modelo como
- Un valor binario pertenece/no pertenece.

- ¿Cuál de las siguientes no es una ventaja que plantea la lógica difusa?
- Todas las anteriores pueden ser consideradas ventajas.

- ¿Qué define un conjunto difuso?
- Una graduación de probabilidad de pertenencia de un valor a un conjunto.

- ¿Cuáles de los siguientes componentes no forma parte del modelo de variables lingüísticas?
- Un conjunto de reglas léxicas.

- Supongamos el sistema de control presente en un aparato de aire acondicionado, que demanda un funcionamiento suave y adaptativo. ¿Tendría sentido modelar su comportamiento mediante un sistema de lógica difusa?
- Sí, mediante reglas y conjuntos difusos que se adapten a los distintos rangos de temperatura susceptibles de ser usados por un ser humano