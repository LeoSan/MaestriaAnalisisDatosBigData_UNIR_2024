# T√©cnicas de Inteligencia Artificial

# Temario 1: Introducci√≥n a la IA 

## Resumen del Diagrama: Descubrimiento del Conocimiento y Aprendizaje Autom√°tico

La imagen presenta un diagrama que ilustra dos conceptos principales interrelacionados: **Descubrimiento del Conocimiento en Bases de Datos (KDD)** y el **Aprendizaje Autom√°tico (Machine Learning)**.

**Descubrimiento del Conocimiento en Bases de Datos (KDD):**

## Pasos 
- Paso 1: Recopilamos informaci√≥n 
- Paso 2: 

Este proceso se describe como una secuencia de pasos que transforma datos brutos en conocimiento √∫til. Las etapas son:

1.  **Datos:** Se inicia con una base de datos (BD) como fuente de informaci√≥n.
2.  **Selecci√≥n:** Se eligen los datos relevantes para el objetivo del descubrimiento.
3.  **Pre-procesamiento:** Los datos seleccionados se limpian y preparan para el an√°lisis.
4.  **Transformaci√≥n:** Los datos pre-procesados se transforman a un formato adecuado para la miner√≠a de datos.
5.  **Miner√≠a de Datos:** Se aplican t√©cnicas de aprendizaje autom√°tico para extraer patrones y descubrir conocimiento valioso a partir de grandes cantidades de datos.
6.  **Interpretaci√≥n y Evaluaci√≥n de Resultados:** Los patrones descubiertos se interpretan y eval√∫an para determinar su utilidad y relevancia.
7.  **Conocimiento:** El resultado final es el conocimiento extra√≠do de los datos.

**Aprendizaje Autom√°tico (Machine Learning):**

El aprendizaje autom√°tico se presenta como un subcampo de la **Inteligencia Artificial (IA)** y el **Aprendizaje Autom√°tico (Autom√°tico)**.

* **Inteligencia Artificial (IA):** Se define como la ciencia que estudia la creaci√≥n de agentes computacionales que, bas√°ndose en unos est√≠mulos externos y un conocimiento almacenado, producen acciones que maximizan su rendimiento. Se mencionan √°reas como la Rob√≥tica, Sistemas Expertos y el Procesamiento del Lenguaje Natural.

* **Aprendizaje Autom√°tico (Autom√°tico):** Se describe como una rama de la IA que se dedica a la construcci√≥n de programas computacionales que autom√°ticamente mejoran su rendimiento en una tarea determinada con la experiencia.

    * **Elementos que intervienen en el aprendizaje autom√°tico:**
        * **Clase (concepto que se aprende)**
        * **Instancias con sus atributos**
        * **Ejemplos y no ejemplos (datos de entrenamiento)**

    * **Tipos de Aprendizaje Autom√°tico:**
        * **Aprendizaje Supervisado:** Se basa en la descripci√≥n de un concepto o clase a partir de datos etiquetados. 
        * **Aprendizaje No Supervisado:** Busca la formaci√≥n de un nuevo concepto (clase desconocida) a partir de datos sin etiquetas.
        * **Aprendizaje Visto como B√∫squeda de Hip√≥tesis (bias y sobreajuste):** Se enfoca en la b√∫squeda del mejor modelo o hip√≥tesis a partir de los datos, considerando el sesgo y el riesgo de sobreajuste.

**Relaci√≥n entre KDD y Aprendizaje Autom√°tico:**

El diagrama muestra que la **Miner√≠a de Datos** dentro del proceso de KDD **utiliza** t√©cnicas de **Aprendizaje Autom√°tico** para descubrir patrones y extraer conocimiento de los datos. Por lo tanto, el aprendizaje autom√°tico es una herramienta fundamental dentro del proceso m√°s amplio de descubrimiento del conocimiento.

## 1.2. Aproximaci√≥n a los conceptos de inteligencia artificial, aprendizaje autom√°tico y miner√≠a de datos. Inter√©s y aplicaciones


> Lengua Espa√±ola de la Real Academia Espa√±ola podemos
- ¬´Disciplina cient√≠fica que se ocupa de crear programas inform√°ticos que ejecutan operaciones comparables a las que realiza la mente humana, como el aprendizaje o el razonamiento l√≥gico¬ª.

- El objetivo de la IA, desde el punto de vista de la investigaci√≥n y de la ciencia, es
comprender los principios que hacen posible el comportamiento inteligente en
sistemas artificiales. Para ello, se deben analizar agentes naturales y artificiales,
formular y testear hip√≥tesis sobre lo que implica construir un sistema artificial que
realice tareas que requieren inteligencia, as√≠ como dise√±ar y desarrollar el sistema
inteligente emp√≠rico, esto es, experimentando y comprobando las distintas hip√≥tesis
planteadas (Poole & Mackworth, 2010).

- Alan Turing con t√≠tulo ¬´Computing machinery and intelligence¬ª publicado en el a√±o 1950 (Turing, 1950). 
    - Principio : Turing propone un juego de imitaci√≥n en el que un juez humano debe interrogar a otro humano y a un ordenador remotamente y conseguir adivinar qui√©n es el ordenador de sus dos interlocutores. 



## Inteligencia artificial
Es una rama de la inform√°tica que estudia la creaci√≥n de agentes computacionales que reciben est√≠mulos externos y en base a ellos y a un conocimiento almacenado en dicho agente, producen resultados o acciones que maximizan una medida de rendimiento. El conocimiento almacenado puede ser aprendido por el mismo agente utilizando t√©cnicas de aprendizaje autom√°tico o puede ser incorporado por un humano experto en el dominio espec√≠fico.


## Miner√≠a de datos
Es un proceso que utiliza t√©cnicas de inteligencia artificial sobre grandes cantidades de datos con el objetivo de descubrir y describir patrones en los datos, a partir de los cuales se pueda obtener un beneficio.

## Aprendizaje autom√°tico, 
Es una rama de la IA, se refiere a la construcci√≥n de programas computacionales que autom√°ticamente mejoran su rendimiento en una
tarea determinada con la experiencia.


## 1.3. Definici√≥n de aprendizaje, tareas b√°sicas y ejemplos


La siguiente frase define el aprendizaje por parte de un ordenador:
Un programa de ordenador aprende de la experiencia E con respecto a
una clase de tareas T y una medida de rendimiento P, si su rendimiento
en las tareas T, medido en base a la medida P, mejora con la
experiencia E. (Mitchell, 1997).
Para ilustrar esta definici√≥n y los elementos E, P y T, se exponen a continuaci√≥n
algunos ejemplos de tareas de aprendizaje:
Ejemplo 1: Aprender a detectar robos de tarjetas de cr√©dito.
T: detectar robos de tarjetas de cr√©dito.
P: porcentaje de robos detectados.
E: base de datos de h√°bitos de compra con la tarjeta de cr√©dito.
Ejemplo 2: Aprender a reconocer la escritura manual.
T: reconocer y clasificar palabras escritas en im√°genes.
P: porcentaje de palabras correctamente clasificadas.
E: base de datos de im√°genes de palabras manuscritas clasificadas.
Ejemplo 3: Aprender a aparcar un coche utilizando sensores de visi√≥n.
T: aparcar un coche utilizando sensores de visi√≥n.
P: porcentaje de aparcamientos correctos.
E: secuencias de im√°genes y comandos de guiados registrados.


## ¬øQu√© contenidos se pueden aprender?
De acuerdo con la teor√≠a de instrucci√≥n de Merril denominada ¬´Teor√≠a de
presentaci√≥n de componentes¬ª, ¬´Component display theory¬ª (Merril et al., 1994), las
personas pueden aprender cuatro tipos de contenido:

- Hechos: simples afirmaciones de una verdad, que puede ser una asociaci√≥n entre
una fecha y un hecho, o un nombre y un objeto.

- Conceptos: conjunto de objetos, s√≠mbolos o eventos agrupados porque comparten
ciertas caracter√≠sticas y que pueden ser referenciados por un nombre en particular o
un s√≠mbolo. Los objetos existen en el espacio y tiempo como puede ser una persona,
una mesa; los s√≠mbolos se refieren a tipos de palabras, n√∫meros, marcas, como
puede ser un predicado o una fracci√≥n; los eventos son interacciones espec√≠ficas de
objetos en un periodo de tiempo como puede ser la digesti√≥n o la fotos√≠ntesis.

- Procedimientos: conjunto de acciones realizadas en pasos consecutivos para
alcanzar un objetivo.

- Principios: relaciones causa-efecto, verdades generales o leyes b√°sicas para
afirmar otras verdades.

## ¬øQu√© elementos intervienen en el aprendizaje de un concepto?

Una instancia es una ilustraci√≥n espec√≠fica de un objeto, s√≠mbolo, evento, proceso o
procedimiento

## ¬øEn qu√© consiste aprender un concepto?

p√°gina 19 


# Aprendizaje Supervizado
- Tiene etiquetas
    - Regresi√≥n 
    - Clasificaci√≥n 

# Aprendizaje NO Supervizado
- NO Tiene etiquetas
    - Agrupaci√≥n  
    - Detenci√≥n de anomal√≠as  
    
## 1.4. Etapas en el descubrimiento de conocimiento

# Temario 2: Python para la implementaci√≥n de t√©cnicas de inteligencia artificial

## 2.3. El lenguaje Python: conceptos b√°sicos e instalaci√≥n
 - Fue creado por Guido van Rossum
 - Lanzado en 1991 
 - Tiene su nombre por un comediante Monty Python
 - Multiplataforma 
 - Es un lenguaje interpretado no compilado 
 - Multiparadigma
    - Programaci√≥n orientada a objetos,
    - Programaci√≥n imperativa
    - programaci√≥n procedural,
    - Programaci√≥n funcional, basado en el c√°lculo lambda
- Maneja dos tipos de tipado
    - Fuertemente tipado
    - De tipado din√°mico

## Instalaci√≥n 
-  con estos comando en Linux podemos instalarlo 
```bash
sudo apt-get update
sudo apt-get install python
sudo apt-get install pip
```


## 2.4. La sintaxis de Python

## Indentaci√≥n y comentarios
> A diferencia de otros lenguajes, en los cuales no es importante y solo se hace por legibilidad del c√≥digo, en Python es importante el sangrado (indentaci√≥n) a la hora de definir los distintos bloques de ejecuci√≥n. Hemos de usar siempre el mismo nivel de sangrado para cada bloque y el deshacerlo hace que se cierre dicho bloque.

## Variables, tipos de datos y casting
- En Python no es necesario declarar una variable (a diferencia de lenguajes de tipado
est√°tico como C/C++)
- Esta se crea en el momento de utilizarla por primera vez,
momento en el cual se define su tipo, que adem√°s puede cambiar con el tiempo con
una nueva asignaci√≥n de la variable a un tipo nuevo
- Python son case-sensitive (debemos respetar uso de may√∫sculas y min√∫sculas)
- pueden contener letras, n√∫meros y el car√°cter de subrayado, pero no pueden comenzar por un n√∫mero
- Por defecto, una variable definida fuera de una funci√≥n es global, y cuando es
definida dentro de una funci√≥n es local, a no ser que utilicemos la palabra clave global
 para modificar este comportamiento. Una variable global puede ser empleada desde
cualquier punto del programa, pero una variable local solo puede ser empleada
dentro de la funci√≥n que la define.

## Tipos de Variables 
- Texto      -> str 
- N√∫mericos  -> int, float, complex
- Secuencias -> list, tuple, range
- Mapas      -> dict 
- Conjuntos  -> set, frozenset
- Booleanos  -> bool 
- Binarios   -> bytes, bytarray, memoryview 

## Cadenas

- Las cadenas funcionan como el resto de los arrays en cuanto a que son iterables y
cada elemento es accesible mediante el uso de corchetes. Cada elemento es un
car√°cter Unicode, pero no existe un tipo char como en otros lenguajes. Un car√°cter
es una cadena de tama√±o 1. 

- Podemos acceder a los elementos de la cadena de forma selectiva. 

## Operadores
> En Python existen los siguientes tipos de operadores (que nos interesen):
- Aritm√©ticos.
- Asignaci√≥n.
- Comparaci√≥n.
- L√≥gicos.
- Identidad.
- Membres√≠a.


## 2.5. Listas, tuplas, conjuntos y diccionarios

## Listas
- Las listas son colecciones de objetos ordenadas y modificables. 
- Se escriben utilizando corchetes con los elementos separados por comas. 
- Podemos acceder a los diferentes elementos empleando el operador corchete y acceder a un rango de
elementos, al igual que hac√≠amos con las cadenas. 
- Asimismo, podemos utilizar la funci√≥n len() y el m√©todo append() para a√±adir nuevos elementos.


## Tuplas
- Las tuplas son colecciones ordenadas pero inmutables, es decir, no podemos alterar
su valor. 
- Las tuplas funcionan de forma muy similar a las listas a la hora de acceder a
sus elementos, iterarlas, comprobar si un elemento se encuentra en ellas, etc. 
- Sin embargo, no podemos a√±adir o eliminar elementos o modificar el valor de uno de sus
elementos. 
- Para hacer esto, tendr√≠amos que copiar su valore en una lista, realizar las
modificaciones y asignar su contenido completo a la tupla original.

## Conjuntos
- Los conjuntos (set) son colecciones de datos no ordenadas y que no permiten
elementos duplicados. 
- Es decir, no podemos predecir en qu√© orden se mostrar√°n
(print) o iterar√°n sus elementos (for ‚Ä¶ in). 
- De hecho, cada vez que realicemos una ejecuci√≥n de este tipo el orden puede ser distinto. 
- Tampoco podemos utilizar el operador corchete para acceder a un elemento determinado, puesto que no tienen orden alguno. 
- No pueden contener dos elementos con el mismo valor.
- Una vez que creamos un conjunto, no podemos alterar el valor de uno de sus
elementos. Lo que s√≠ podemos hacer es a√±adir nuevos elementos o eliminar los
existentes

## Diccionarios
- Los diccionarios son el equivalente a mapas o hashes en otros lenguajes de
programaci√≥n. 
- Son un conjunto de elementos clave-valor sin orden y en los cuales se
puede modificar el contenido de los elementos. 
- Son tambi√©n similares a los objetos nativos de JavaScript que pueden ser convertidos a y desde JSON. Sin embargo son mucho m√°s flexibles y una clave no tiene por qu√© ser s√≥lo de tipo cadena, sino que puede ser cualquier objeto, incluso un entero, un flotante o un complejo, por

## 2.6. Librer√≠as √∫tiles para el an√°lisis de datos
> NumPy 
Es una librer√≠a muy popular para el procesamiento de grandes matrices y
matrices multidimensionales, con la ayuda de una gran colecci√≥n de funciones
matem√°ticas de alto nivel. Es muy √∫til para los c√°lculos cient√≠ficos fundamentales en
machine learning. Es particularmente √∫til para el √°lgebra lineal, la transformaci√≥n de
Fourier y las capacidades de n√∫meros aleatorios. Otras librer√≠as de alto nivel como
TensorFlow utilizan NumPy internamente para la manipulaci√≥n de tensores

> SciPy
Es una biblioteca muy popular entre los ingenieros de machine learning, ya que
contiene diferentes m√≥dulos para la optimizaci√≥n, el √°lgebra lineal, la integraci√≥n y la
estad√≠stica. Hay una diferencia entre la biblioteca de SciPy y la pila de SciPy (SciPy
stack). La librer√≠a SciPy es uno de los paquetes centrales que componen la pila de
SciPy. SciPy tambi√©n es muy √∫til para la manipulaci√≥n de im√°genes.

> Scikit-learn.
Es una de las librer√≠as de machine learning m√°s populares para los
algoritmos de machine learning cl√°sico. Est√° construida sobre dos bibliotecas
b√°sicas de Python, NumPy y SciPy. Scikit-learn soporta la mayor√≠a de los algoritmos
de aprendizaje supervisado y no supervisado

> Theano.
El machine learning es b√°sicamente matem√°ticas y estad√≠stica. Theano es una
popular librer√≠a que se utiliza para definir, evaluar y optimizar las expresiones
matem√°ticas que implican conjuntos multidimensionales de manera eficiente. 

Se consigue optimizando la utilizaci√≥n de la CPU y la GPU. Se utiliza ampliamente para
pruebas unitarias y autoverificaci√≥n para detectar y diagnosticar diferentes tipos de
errores. Theano es una biblioteca muy potente que se ha utilizado en proyectos
cient√≠ficos de gran escala e intensivos en computaci√≥n durante mucho tiempo, pero
es lo suficientemente sencilla y accesible para que peque√±os desarrolladores la
utilicen en sus propios proyectos.

> Keras.
Es una de las librer√≠as de Machine Learning m√°s populares para Python. Es
una API de redes neuronales de alto nivel capaz de funcionar sobre TensorFlow,
CNTK, o Theano. Puede funcionar sin problemas en la CPU y la GPU. Keras permite
que sea realmente sencillo construir y dise√±ar redes neuronales para los
principiantes en el machine learning. Una de las mejores caracter√≠sticas de Keras es
que permite la creaci√≥n de prototipos de forma f√°cil y r√°pida.

> TensorFlow.
TensorFlow es una biblioteca de c√≥digo abierto muy popular para el c√°lculo num√©rico
de alto rendimiento, desarrollada por el equipo de Google Brain en Google. Como su
nombre lo sugiere, TensorFlow es un marco de trabajo que implica la definici√≥n y ejecuci√≥n de c√°lculos que implican tensores.

> PyTorch
Es otra de las librer√≠as m√°s populares de machine learning de c√≥digo abierto
para Python basada en Torch, que es una biblioteca de machine learning de c√≥digo
abierto que se implementa en C con un wrapper en Lua. Tiene una extensa selecci√≥n
de herramientas y librer√≠as que incluye visi√≥n artificial (Computer Vision) o
Procesamiento de Lenguaje Natural (NLP), entre otros. Permite a los desarrolladores
realizar c√°lculos tensoriales con aceleraci√≥n en la GPU y tambi√©n es de ayuda en la

> Pandas.
Pandas es una popular librer√≠a de Python para el an√°lisis de datos. No est√°
directamente relacionada con el machine learning. Como sabemos, los dataset han
ser preparados antes del entrenamiento. En este caso, Pandas es muy √∫til, ya que
fue desarrollada espec√≠ficamente para la extracci√≥n y preparaci√≥n de datos.
Proporciona estructuras de datos de alto nivel y una amplia variedad de herramientas
para el an√°lisis de datos. Asimismo, proporciona muchos m√©todos incorporados para
tantear, combinar y filtrar datos. 

> Matplotlib.
Es una biblioteca de Python muy popular para la visualizaci√≥n de datos. Al
igual que Pandas, no est√° directamente relacionada con el machine learning. Es
particularmente √∫til cuando un programador quiere visualizar los patrones de los
datos. Es una librer√≠a de ploteo en 2D usada para crear gr√°ficos y diagramas en 2D.


## 2.7. La librer√≠a NumPy para el manejo de datos

## Conceptos b√°sicos y arrays en NumPy

Tal y como hemos visto, la librer√≠a NumPy nos permite trabajar con arrays de forma
muy eficiente, as√≠ como √°lgebra lineal, transformadas de Fourier y matrices. Aunque
Python dispone de listas que permiten trabajar con arrays, estas son muy lentas.

NumPy proporciona arrays 50 veces m√°s r√°pidos, en parte porque los elementos
est√°n todos almacenados en posiciones contiguas de memoria y en parte porque
parte de NumPy est√° escrita en C/C++

Podemos trabajar con escalares, vectores, matrices, arrays tridimensionales o
cualquier otra dimensi√≥n diferente. El m√©todo ndim nos permite obtener la dimensi√≥n
del array, mientras que con el operador corchete podemos acceder a los diferentes
elementos seg√∫n los √≠ndices en cada dimensi√≥n

## Array Slicing

Al igual que con los tipos built-in datos (cadenas, listas, etc.), en los arrays NumPy se
puede hacer un slicing de los arrays utilizando notaci√≥n de corchetes y dos puntos,
pero, con mucha mayor flexibilidad:

## Tipos de datos en NumPy
NumPy nos permite especificar con mucho mayor detalle los tipos de datos de los
elementos en nuestros arrays:
- i ‚Äì integer
- b ‚Äì boolean
- u - unsigned integer
- f ‚Äì float
- c - complex float
- m ‚Äì timedelta
- M ‚Äì datetime
- O ‚Äì object
- S ‚Äì string
- U - unicode string
- V - chunk o trozo de memoria para otro tipo de dato ( void )

- En los tipos de datos i, u, f, S, U podemos especificar el tama√±o en bytes, adem√°s.
- Esto se especifica con la propiedad dtype:
- Si un valor no puede ser convertido, se lanzar√° una excepci√≥n de tipo ValueError.
- Si queremos convertir el tipo de datos de un array existente, usaremos el m√©todo 

## Copy y view
La principal diferencia entre una copia (obtenida con el m√©todo copy() ) y una vista
(obtenida con el m√©todo view() ) de un array NumPy es que la copia es un nuevo
array, mientras que la vista es una vista, valga la redundancia, del array original. Es similar al concepto de asignaci√≥n por referencia o de clonado de los datos en Python

## La forma (shape) de un array
Con el atributo shape podemos obtener una tupla indicando en cada √≠ndica el
n√∫mero de elementos en cada dimensi√≥n. Si hemos definido una dimensi√≥n m√≠nima
con ndmin en la creaci√≥n del array, esta ser√° una forma de visualizarlo. El m√©todo
reshape() nos permite redimensionar un array (cambios entre 1-D y 2-D o 3D). Dicho
m√©todo devuelve una vista, no una copia. Con reshape(-1) podemos aplanar un
array multidimensional en un array unidimensiona

## Operaciones con varios arrays
Podemos concatenar arrays uno a continuaci√≥n del otro con concatenate(),
especificando sobre qu√© eje (si no se especifica, se considerar√° el eje 0):

## B√∫squedas en arrays
Podemos utilizar el m√©todo where() para realizar b√∫squedas de los elementos que
cumplan con una condici√≥n pasado como argumento a dicho m√©todo. Algunos
sencillos ejemplos de su uso incluyen la b√∫squeda de un valor espec√≠fico o buscar
todos los elementos pares del array:

## Ordenando arrays
Con el m√©todo sort() obtenemos una copia del array, manteniendo el original
inalterado. Si ordenamos un array 2-D, el orden se har√° fila a fila:

## Filtrado de arrays
Para ello, se usa un array de booleanos que permiten indicar mediante valores True o
False si el elemento correspondiente se mantendr√° o no tras el filtrado.

## 2.8. Importaci√≥n de datos

Aunque ya hemos visto algunas en los ejemplos en la secci√≥n de librer√≠as, vamos a
ver las diferentes formas que tenemos para importar datos en Python a la hora de
aplicar m√©todos machine learning 


- Importaci√≥n de archivos en formato .txt.
- Importaci√≥n de archivos planos CSV mediante la librer√≠a est√°ndar de Python.
- Importaci√≥n de archivos planos CSV mediante NumPy.
- Importaci√≥n de archivos planos CSV mediante Pandas.
- Importaci√≥n desde una URL.
- Importaci√≥n desde otras librer√≠as (toy datasets).

## Importaci√≥n de archivos en formato .txt
- En todos los casos en los que manejemos ficheros, nos interesa asegurarnos
primero de que estamos en el directorio correcto, a no ser que queramos utilizar una
ruta absoluta

## Importaci√≥n de archivos planos CSV mediante la librer√≠a est√°ndar de Python
- En el caso de que trabajemos con archivos CSV, hemos de tener en cuenta, no solo
la ubicaci√≥n, sino detalles como:
- Si tiene cabecera (header).
- Si tiene comentarios (incluidos con #).
- Qu√© tipo de delimitador utiliza el fichero (coma, punto y coma, espacios en blanco,
etc.)

## Importaci√≥n de archivos planos CSV mediante Pandas

- Esta forma es muy popular dadas las ventajas que ofrece Pandas en este sentido.
- Usaremos la funci√≥n readcsv() para la carga, la cual nos ofrece una gran versatilidad
a la hora de importar los datos. Con una √∫nica l√≠nea permite:

- Detectar autom√°ticamente los headers sin que se lo tengamos que especificar.
Saltar l√≠neas con el modificador skiprow.

- Detectar autom√°ticamente el tipo de datos (entero, flotante, cadenas, etc.)
- Identificar campos err√≥neos o vac√≠os.
- Convertir los datos CSV en un dataframe de Pandas, que son estructuras de datos
especialmente dise√±adas para aplicar t√©cnicas de ciencia de datos, siendo posible
su uso como tablas o series temporales.
- Emplear la opci√≥n chunksize para cargar los datos en fragmentos de tama√±o
configurable en lugar de cargar todos los datos en un √∫nico espacio de memoria. De
este modo, se mejora la eficiencia.

## Importaci√≥n desde una URL
- Tambi√©n podemos cargar directamente los datos desde una URL usando Pandas:


## Importaci√≥n desde otras librer√≠as
(toy datasets)
Como ya hemos visto con anterioridad, existen datasets que vienen incluidos ¬´de
serie¬ª en las librer√≠as de machine learning. Lo hemos visto en los ejemplos de scikitlearn, pero tambi√©n los hay incluidos en paquetes como statsmodels o seaborn. Este
tipo de conjuntos de datos para hacer pruebas se conocen como ¬´toy datasets¬ª


## 2.9. Introducci√≥n a Machine Learning con librer√≠as en Python

## Medias, medianas, modas, desviaci√≥n est√°ndar, varianza y percentiles
Como hemos visto con anterioridad, podemos dividir los tipos de datos de nuestro
dataset en:

Medidas de Tendencia Central
Estas medidas nos dicen d√≥nde est√° el "centro" o el valor m√°s t√≠pico de un conjunto de datos.

## Media (Promedio)
La media es lo que com√∫nmente conocemos como promedio. Se calcula sumando todos los valores de un conjunto de datos y dividiendo el resultado entre el n√∫mero total de valores.

¬øC√≥mo recordarla? Piensa en tu promedio de calificaciones. Sumas todas tus notas y divides entre el n√∫mero de materias.
Ejemplo: Si tus edades son 10, 12, 11, 13, 14. La media es (10+12+11+13+14)/5=60/5=12. La edad promedio es 12 a√±os.

## Mediana
La mediana es el valor que se encuentra justo en el medio de un conjunto de datos cuando estos est√°n ordenados de menor a mayor (o de mayor a menor). Si hay un n√∫mero par de datos, la mediana es el promedio de los dos valores centrales.

¬øC√≥mo recordarla? Piensa en la "l√≠nea media" de una carretera; es el punto central.
Ejemplo:
Datos impares: 10, 11, 12, 13, 14. La mediana es 12.
Datos pares: 10, 11, 12, 13, 14, 15. La mediana es (12+13)/2=12.5.

### Moda
La moda es el valor que aparece con mayor frecuencia en un conjunto de datos. Puede haber una moda (unimodal), varias modas (multimodal) o ninguna moda si todos los valores son √∫nicos.

¬øC√≥mo recordarla? Piensa en la "moda" en la ropa; es lo que "m√°s se usa" o "m√°s se repite".
Ejemplo:
10, 11, 12, 13, 12, 14. La moda es 12.
10, 11, 12, 13, 14. No hay moda.


## Medidas de Dispersi√≥n
Estas medidas nos dicen qu√© tan dispersos o separados est√°n los datos entre s√≠.

## Desviaci√≥n Est√°ndar
La desviaci√≥n est√°ndar mide el promedio de qu√© tan lejos est√°n los datos de la media. Un valor bajo indica que los datos est√°n cerca de la media, mientras que un valor alto indica que est√°n m√°s dispersos.

¬øC√≥mo recordarla? Piensa que te dice qu√© tan "desviados" o "apartados" est√°n los datos de su centro (la media) en promedio. Es una medida clave de la "variabilidad" de los datos.
Concepto clave: Es la ra√≠z cuadrada de la varianza.

## Varianza
La varianza mide la dispersi√≥n total de los datos alrededor de la media. Es el promedio de los cuadrados de las diferencias de cada dato con la media. Se usa para calcular la desviaci√≥n est√°ndar.

¬øC√≥mo recordarla? Piensa que te dice qu√© tanta "variaci√≥n" o "diferencia" hay en tus datos con respecto a la media. Es el paso previo a la desviaci√≥n est√°ndar.
Concepto clave: La varianza est√° en unidades cuadradas de los datos originales, por eso se le saca ra√≠z cuadrada para obtener la desviaci√≥n est√°ndar y que est√© en las mismas unidades que los datos.

## Medidas de Posici√≥n
Estas medidas nos dicen la posici√≥n de un valor espec√≠fico dentro de un conjunto de datos ordenado.

## Percentiles
Los percentiles dividen un conjunto de datos ordenado en 100 partes iguales. Un percentil indica el porcentaje de datos que caen por debajo de un valor espec√≠fico. Por ejemplo, si sacaste 85 en un examen y eso te pone en el percentil 90, significa que el 90% de los estudiantes sacaron menos de 85.

¬øC√≥mo recordarlos? Piensa en "por ciento" (parte de cien). Te dice qu√© porcentaje de los datos est√°n por debajo de un valor.
Ejemplo: El percentil 25 (P25) es el valor por debajo del cual cae el 25% de los datos. El percentil 50 (P50) es la mediana, ya que el 50% de los datos est√°n por debajo de este valor.

## Resumen para memorizar:
- Media: Promedio, el "centro" aritm√©tico.
- Mediana: El valor de en medio cuando los datos est√°n ordenados.
- Moda: El valor que m√°s se repite (el que est√° de "moda").
- Desviaci√≥n Est√°ndar: Qu√© tan alejados est√°n los datos de la media, en promedio (en las mismas unidades que los datos).
- Varianza: La dispersi√≥n total de los datos respecto a la media (la desviaci√≥n est√°ndar al cuadrado).
- Percentiles: Dividen los datos en 100 partes, indicando el porcentaje de datos por debajo de un valor.


- Num√©ricos:
    - Discretos (el n√∫mero de hijos por mujer).
    - Continuos (la longitud del p√©talo de una flor).
- Categ√≥ricos (perro, gato, loro).
- Ordinales (suspenso, aprobado, notable, sobresaliente).

NumPy y SciPy nos ofrecen m√©todos r√°pidos para calcular diferentes medidas de un
conjunto de datos, como la media, la mediana, la moda, la desviaci√≥n est√°ndar, la
varianza y determinados percentiles, por ejemplo, el percentil 75:

## Distribuci√≥n de los datos
Podemos generar una gran cantidad de datos aleatorios con NumPy y mostrar el
histograma representando la distribuci√≥n de los datos usando Matplotlib.

## Regresiones
Una forma cl√°sica de aprendizaje supervisado cuando se tienen datos continuos es
la regresi√≥n, que puede ser lineal o polin√≥mica, adem√°s de otros muchos m√°s tipos
m√°s complejos

## TensorFlow 2.0 Crash Course
 2  horas de tensorFlow 
https://www.youtube.com/watch?v=6g4O5UOH304&ab_channel=freeCodeCamp.org 

Fundamentos de Machine Learning
1. Regresi√≥n Lineal con Python
üîó https://youtu.be/1CGbP0l0iqo?si=DZnQW4ClqyZaOJhJ
üìå Explicaci√≥n de la regresi√≥n lineal y su implementaci√≥n en Python.

2. Codificaci√≥n de Datos Categ√≥ricos
https://youtu.be/KUEsLv8EaVY?si=ER1EN3ZutSwN9kCx
üìå M√©todos para transformar variables categ√≥ricas en datos num√©ricos para modelos de ML.

3. Escalamiento, Normalizaci√≥n y Estandarizaci√≥n de Datos
https://youtu.be/-VuR14Qyl7E?si=sfjLg1Zg4rlXXn6q
üìå T√©cnicas para preparar datos antes de alimentar un modelo de aprendizaje autom√°tico.


Algoritmos de Aprendizaje Autom√°tico
4. Random Forest (Bosque Aleatorio
https://youtu.be/yOCJQLf_YFI?si=qj_tImJhBxBLxHI1
üìå Explicaci√≥n de este m√©todo de ensamblado basado en √°rboles de decisi√≥n.

5. Entrop√≠a en √Årboles de Decisi√≥n
https://youtu.be/GWX2YcnaELg?si=KrWBYM5uRI1EHKyk
üìå Concepto clave en la divisi√≥n de nodos dentro de √°rboles de decisi√≥n.

6. Impureza GINI en √Årboles de Decisi√≥n
https://youtu.be/PFn31_hzQ2Y?si=ZUOD5-ejUK3zICWB
üìå Otro criterio fundamental en la construcci√≥n de √°rboles de decisi√≥n.

Evaluaci√≥n y Optimizaci√≥n de Modelos
7. Matriz de Confusi√≥n: Precisi√≥n, Accuracy, Recall y F1-Score
https://youtu.be/uaGMk43XTOw?si=EdxWX8czQOzQpaQR
üìå C√≥mo evaluar el rendimiento de los modelos de clasificaci√≥n.

8. Curva ROC y AUC
https://youtu.be/Uyfcqn3Nidc?si=1ubow-pNmcaQlEB5
üìå An√°lisis de la capacidad discriminativa de un modelo de clasificaci√≥n.

9. Optimizaci√≥n de Modelos: Hiperpar√°metros
https://youtu.be/YAfS8-BXp8Q?si=wmuqpBY0sCIkGfqD
üìå T√©cnicas para mejorar el rendimiento de los modelos de ML mediante el ajuste de hiperpar√°metros.



# Tema 3. √Årboles de decisi√≥n

## 3.3. Descripci√≥n de la tarea de inducci√≥n

### Resumen: Descripci√≥n de la tarea de inducci√≥n en √°rboles de decisi√≥n

El objetivo de la **inducci√≥n** en el aprendizaje autom√°tico es tomar informaci√≥n espec√≠fica (observaciones, experiencias) y usarla para encontrar conocimiento general o patrones ocultos. En el caso de los **√°rboles de decisi√≥n**, esto significa construir un √°rbol que pueda clasificar nuevos datos bas√°ndose en ejemplos que ya han sido clasificados.

#### ¬øC√≥mo se construye un √°rbol de decisi√≥n?

Un √°rbol de decisi√≥n se construye **seleccionando atributos** que ayuden a dividir los datos en grupos cada vez m√°s homog√©neos (es decir, que contengan ejemplos de la misma clase).

* **Selecci√≥n del atributo**: Este es un paso crucial. El algoritmo elige el "mejor" atributo para hacer la primera divisi√≥n. Por ejemplo, si estamos clasificando si se puede jugar al tenis, podr√≠a ser el "ambiente".
* **Creaci√≥n de ramas**: Una vez que se selecciona un atributo, se crean ramas a partir de ese punto.
    * Si el atributo tiene valores **discretos** (como "soleado", "nublado", "lluvioso"), se crea una rama para cada valor.
    * Si el atributo es **num√©rico** (como la temperatura), se establece un punto de corte (por ejemplo, si la temperatura es "mayor a X" o "menor a X").
* **Proceso iterativo**: Este proceso de seleccionar un atributo y ramificar el √°rbol se repite para cada subconjunto de datos hasta que se cumplen ciertas condiciones:
    * Todos los ejemplos en un nodo pertenecen a la misma clase (¬°√©xito, llegamos a una "hoja" del √°rbol!).
    * No quedan m√°s atributos para dividir los datos. En este caso, el nodo se convierte en una hoja y se etiqueta con la clase m√°s com√∫n entre los ejemplos que llegaron a ese punto.
    * No hay ejemplos para una rama (lo que se maneja etiquetando la hoja con la clase mayoritaria del conjunto original de datos).

#### Ejemplo pr√°ctico: ¬øSe puede jugar al aire libre?

El texto usa un ejemplo cl√°sico para ilustrar esto: clasificar si es un buen d√≠a para jugar al aire libre (como al tenis) bas√°ndose en factores como el ambiente, la temperatura, la humedad y el viento. El algoritmo "aprende" de ejemplos pasados para decidir, por ejemplo, que si el "Ambiente" es "nublado", ¬°siempre se puede jugar!

#### Es un algoritmo "Divide y Vencer√°s" (y "Codicioso")

Este tipo de algoritmo se conoce como **"divide y vencer√°s"** porque rompe un problema grande en problemas m√°s peque√±os y manejables. Tambi√©n se le llama **"codicioso"** (greedy) porque en cada paso toma la mejor decisi√≥n en ese momento sin "mirar hacia atr√°s" para ver si una decisi√≥n anterior podr√≠a haberse mejorado.

En resumen, los √°rboles de decisi√≥n aprenden a clasificar datos construyendo una serie de "preguntas" (basadas en atributos) que, al seguir las respuestas, te llevan a una clasificaci√≥n final.


## 3.4. Algoritmo b√°sico de aprendizaje de √°rboles de decisi√≥n: ID3

## Algoritmo ID3: C√≥mo los √°rboles de decisi√≥n aprenden a clasificar

El **algoritmo ID3** es una forma espec√≠fica y popular de construir un **√°rbol de decisi√≥n**. Imagina que est√°s construyendo un √°rbol geneal√≥gico, pero en lugar de personas, son decisiones. ID3 hace esto de **arriba hacia abajo**, empezando por la "ra√≠z" y ramific√°ndose.

### La clave: La ganancia de informaci√≥n

ID3 tiene un truco principal para decidir qu√© atributo usar en cada "ramificaci√≥n" del √°rbol: la **ganancia de informaci√≥n**. Este concepto viene de la **teor√≠a de la informaci√≥n** y b√°sicamente busca el atributo que nos d√© la *mayor claridad* o *la mejor pista* para clasificar los ejemplos.

Piensa as√≠: si tienes un mont√≥n de datos mezclados (algunos "s√≠", algunos "no"), la ganancia de informaci√≥n te dice qu√© pregunta (qu√© atributo) te va a ayudar a separar esos datos de la forma m√°s efectiva, haciendo que los grupos resultantes sean lo m√°s "puros" posible (es decir, que todos en un grupo sean "s√≠" o todos sean "no").

### ¬øC√≥mo mide ID3 esta "claridad" o "pureza"?

Para entender la ganancia de informaci√≥n, primero necesitamos entender la **entrop√≠a**:

* **Entrop√≠a**: Es una medida de la **heterogeneidad** o **mezcla** de un conjunto de ejemplos.
    * Si todos los ejemplos en un grupo son de la misma clase (por ejemplo, todos son "s√≠"), la entrop√≠a es **cero (0)**. ¬°Perfecta pureza!
    * Si los ejemplos est√°n perfectamente mezclados (por ejemplo, la mitad son "s√≠" y la mitad son "no" en una clasificaci√≥n de dos clases), la entrop√≠a es **uno (1)**. ¬°M√°xima mezcla!
    * Si est√°n parcialmente mezclados, el valor de la entrop√≠a estar√° entre 0 y 1.

    Matem√°ticamente, la entrop√≠a ($H(E)$) se calcula con la siguiente f√≥rmula:
    $$H(E) = - \sum_{i=1}^{n} p_i \log_2(p_i)$$
    donde $p_i$ es la proporci√≥n de ejemplos que pertenecen a la clase $i$.

* **Ganancia de Informaci√≥n (Gain)**: Una vez que entendemos la entrop√≠a, la ganancia de informaci√≥n se vuelve sencilla. Mide **cu√°nto se reduce la entrop√≠a** si dividimos los ejemplos usando un atributo espec√≠fico. Es decir, qu√© tan efectivo es ese atributo para "limpiar" la mezcla.

    La f√≥rmula para calcular la ganancia de informaci√≥n de un atributo A en un conjunto de ejemplos E es:
    $$Gain(E, A) = H(E) - \sum_{v \in Values(A)} \frac{|E_v|}{|E|} H(E_v)$$
    donde:
    * $H(E)$ es la entrop√≠a del conjunto original.
    * $Values(A)$ son los posibles valores del atributo A.
    * $E_v$ es el subconjunto de ejemplos donde el atributo A toma el valor $v$.
    * $|E_v|$ y $|E|$ son el n√∫mero de ejemplos en los subconjuntos.

### Pasos del Algoritmo ID3 en acci√≥n

1.  **Inicio**: Se empieza con todos los datos en la "ra√≠z" del √°rbol.
2.  **Calcular Ganancia**: Para cada atributo disponible, ID3 calcula su ganancia de informaci√≥n.
3.  **Seleccionar el Mejor Atributo**: Se elige el atributo que tiene la **mayor ganancia de informaci√≥n**. Este ser√° el que mejor "clasifique" o separe los ejemplos.
4.  **Ramificar**: Se crea una rama por cada posible valor de ese atributo. Los ejemplos se distribuyen por estas ramas seg√∫n el valor de ese atributo que tengan.
5.  **Repetir**: Este proceso se repite para cada rama (cada "nodo hijo") con los ejemplos que llegaron a esa rama, y con los atributos que a√∫n no se han utilizado en ese camino del √°rbol.
6.  **Parada**: El proceso se detiene en una rama cuando:
    * Todos los ejemplos en esa rama pertenecen a la misma clase (¬°Ya se clasificaron!).
    * Ya no quedan atributos para dividir (en este caso, el nodo se convierte en una hoja y se etiqueta con la clase m√°s com√∫n entre los ejemplos que llegaron all√≠).
    * No hay ejemplos en una rama espec√≠fica.

### Ejemplo del "Problema del Tiempo"

El texto menciona que, para el problema de si jugar al aire libre, el algoritmo ID3 probablemente seleccionar√≠a el atributo "**ambiente**" como el primero para ramificar el √°rbol. Esto se debe a que, al calcular la ganancia de informaci√≥n, "ambiente" es el que ofrece la mayor reducci√≥n de entrop√≠a. Por ejemplo, todos los d√≠as "nublados" resultan en "s√≠" (jugar al aire libre), lo que hace que esa rama sea pura y se convierta en una hoja de inmediato.

En esencia, ID3 es un m√©todo **"codicioso"** (greedy) que siempre busca el mejor atributo en el momento actual para dividir los datos, construyendo el √°rbol paso a paso sin retroceder.

## 3.5. Espacio de b√∫squeda y bias inductivo

### La B√∫squeda de ID3 en el Espacio de Posibles Soluciones

Imagina que existen much√≠simos √°rboles de decisi√≥n posibles que podr√≠an explicar tus datos. El **ID3** tiene la tarea de encontrar el √°rbol "correcto" que se ajuste a tus **ejemplos de entrenamiento** (los datos que ya conoces y est√°n clasificados).

* **B√∫squeda en Escalada (Hill Climbing)**: ID3 busca esta soluci√≥n subiendo una "colina". Empieza con √°rboles sencillos y va construyendo √°rboles m√°s complejos paso a paso. Se gu√≠a por la **ganancia de informaci√≥n**; cada paso que da es hacia el √°rbol que, hasta ese momento, clasifica mejor los datos.
* **Espacio de Hip√≥tesis Completo**: Una gran ventaja de ID3 es que explora un conjunto **completo** de posibles √°rboles. Esto significa que **nunca se quedar√° sin una soluci√≥n** dentro del rango de lo que puede construir.
* **Un Camino a la Vez**: Sin embargo, ID3 solo se concentra en **una √∫nica soluci√≥n posible** a la vez. No compara m√∫ltiples √°rboles "buenos" simult√°neamente. Esto es como tener solo un camino en la colina; si ese camino te lleva a una cima que no es la m√°s alta de todas (una **√≥ptima local**), te quedar√°s ah√≠ sin saber que hay una mejor cima en otro lugar.
* **Sin Marcha Atr√°s (Greedy)**: Una vez que ID3 toma una decisi√≥n (elegir un atributo para un nodo), **no retrocede** para reconsiderar esa elecci√≥n. Esta es la naturaleza "codiciosa" (greedy) del algoritmo. Puede llevar a construir un √°rbol que funciona bien para los datos de entrenamiento, pero que quiz√°s no sea el mejor √°rbol posible a nivel global.
* **Robusto a Errores y Coste Computacional**: ID3 es bueno para manejar datos con errores porque usa **todos los ejemplos** en cada c√°lculo de ganancia de informaci√≥n. Esto lo hace robusto, pero tambi√©n significa que puede ser **computacionalmente m√°s costoso** que otros m√©todos que solo usan una parte de los ejemplos en cada paso.

---

### El "Bias" (Sesgo) Inductivo de ID3: ¬øPor qu√© elige ciertos √°rboles?

El **bias inductivo** de un algoritmo se refiere a los **criterios o preferencias** que usa para seleccionar una soluci√≥n (una hip√≥tesis) entre muchas posibles. En el caso de ID3, su sesgo se basa en dos premisas principales:

1.  **Preferencia por √Årboles Cortos**: ID3 tiende a preferir los **√°rboles m√°s cortos** (con menos nodos y ramas) sobre los √°rboles m√°s largos. Aunque no siempre garantiza que encontrar√° el √°rbol m√°s corto *absoluto* (porque no hace una b√∫squeda exhaustiva de todos los posibles √°rboles), su enfoque de "b√∫squeda en escalada" y "codicioso" lo inclina hacia la simplicidad.

2.  **Atributos con Mayor Ganancia de Informaci√≥n Cerca de la Ra√≠z**: ID3 siempre colocar√° los atributos que proporcionan la **mayor ganancia de informaci√≥n** (los que mejor dividen los datos) **m√°s cerca de la ra√≠z** del √°rbol. Esto tiene sentido, ya que si un atributo es muy bueno para clasificar, es l√≥gico usarlo al principio para hacer las divisiones m√°s importantes.

#### ¬øPor qu√© es importante preferir √°rboles cortos?

Preferir √°rboles cortos es crucial para la **generalizaci√≥n**. Un √°rbol m√°s corto y simple a menudo puede **clasificar correctamente nuevos datos** (instancias que no se usaron para entrenar el √°rbol) de manera m√°s efectiva. Los √°rboles muy complejos pueden "memorizar" los datos de entrenamiento perfectamente, pero luego fallan al aplicarse a datos nuevos que nunca han visto. Esto se conoce como **sobreajuste (overfitting)**, y preferir √°rboles cortos es una estrategia para evitarlo.

En resumen, ID3 busca un √°rbol que clasifique bien los datos de entrenamiento, gui√°ndose por la ganancia de informaci√≥n. Su "prejuicio" lo lleva a favorecer √°rboles m√°s simples y a usar los atributos m√°s informativos al principio, lo cual es beneficioso para que el √°rbol funcione bien no solo con los datos que ya conoce, sino tambi√©n con datos completamente nuevos.

## 3.6. M√©todos de selecci√≥n de atributos

## M√©todos de Selecci√≥n de Atributos: Diferentes Formas de Ramificar un √Årbol

Cuando construyes un √°rbol de decisi√≥n, una de las decisiones m√°s importantes es **qu√© atributo usar** para dividir tus datos en cada paso. Hay varios "m√©todos de selecci√≥n de atributos" que los algoritmos de √°rboles de decisi√≥n pueden emplear para tomar esta decisi√≥n crucial. La elecci√≥n del m√©todo depender√° del algoritmo que uses, de tus datos, y de lo que esperas del √°rbol final.

### 1. Ganancia de Informaci√≥n (ID3)

Como ya vimos, el algoritmo **ID3** utiliza la **ganancia de informaci√≥n**. Esta mide cu√°nto "clarifica" un atributo la clasificaci√≥n de tus datos al reducir la **entrop√≠a** (la mezcla o impureza de las clases). El atributo con la mayor ganancia de informaci√≥n es el elegido para la divisi√≥n.

### 2. √çndice Gini (CART)

Otro m√©todo popular es el **√≠ndice Gini**, t√≠picamente usado en algoritmos **CART (Classification and Regression Trees)**. A diferencia de la entrop√≠a, que mide la incertidumbre, el √≠ndice Gini mide la **impureza** de un conjunto de datos.

* **¬øC√≥mo se calcula?** Se basa en la proporci√≥n de cada clase en un conjunto de ejemplos ($p_i$). La f√≥rmula es:
    $$Gini(E) = 1 - \sum_{i=1}^{n} p_i^2$$
    Donde $n$ es el n√∫mero de clases y $p_i$ es la proporci√≥n de ejemplos que pertenecen a la clase $i$.

* **¬øC√≥mo se usa?** El objetivo es **minimizar el √≠ndice Gini**. Esto significa que el atributo que produce los subconjuntos con el Gini m√°s bajo (menos impureza) es el que se selecciona para la divisi√≥n. Es decir, buscas la mayor **reducci√≥n de impureza**.

### 3. Proporci√≥n de Ganancia (C4.5)

El algoritmo **C4.5** (una mejora de ID3) utiliza la **proporci√≥n de ganancia**. Este m√©todo es una adaptaci√≥n de la ganancia de informaci√≥n y es especialmente √∫til cuando tienes atributos con **muchos valores diferentes**.

* **El Problema de la Ganancia de Informaci√≥n:** La ganancia de informaci√≥n tiende a favorecer atributos que tienen un gran n√∫mero de valores √∫nicos. Por ejemplo, si tienes un atributo que es un "n√∫mero de identificaci√≥n" (ID), cada ejemplo tendr√° un ID √∫nico. La ganancia de informaci√≥n de este atributo ser√≠a alt√≠sima porque lo divide perfectamente, pero no ser√≠a √∫til para clasificar nuevas instancias porque un nuevo ID no estar√≠a en el √°rbol.

* **La Soluci√≥n de la Proporci√≥n de Ganancia:** La proporci√≥n de ganancia compensa esto. Toma la **ganancia de informaci√≥n** y la **divide** por una medida llamada **informaci√≥n de la divisi√≥n**. La informaci√≥n de la divisi√≥n castiga a los atributos que distribuyen los ejemplos de manera muy uniforme entre muchos valores. La f√≥rmula es:
    $$SplitInformation(E, A) = - \sum_{v \in Values(A)} \frac{|E_v|}{|E|} \log_2(\frac{|E_v|}{|E|})$$
    Y luego la proporci√≥n de ganancia se calcula como:
    $$GainRatio(E, A) = \frac{Gain(E, A)}{SplitInformation(E, A)}$$
    Al dividir por la informaci√≥n de la divisi√≥n, se penaliza a los atributos que generan muchas ramas, haciendo que los atributos con menos valores o con valores m√°s concentrados sean m√°s atractivos si su ganancia de informaci√≥n sigue siendo alta.

### 4. Longitud de Descripci√≥n M√≠nima (MDL - Minimum Description Length)

El m√©todo MDL es un principio m√°s general que se puede aplicar a la construcci√≥n de √°rboles. Busca el √°rbol de decisi√≥n que es m√°s **simple** de describir.

* **La Idea:** Considera el "mejor" √°rbol como aquel que requiere el menor n√∫mero de "bits" (informaci√≥n) para codificar dos cosas:
    1.  El propio √°rbol de decisi√≥n (su estructura y reglas).
    2.  Los errores de clasificaci√≥n que comete el √°rbol (casos que el √°rbol no clasifica correctamente).
* **El Objetivo:** La meta es encontrar la opci√≥n m√°s simple y concisa que explique los datos.

### Consideraciones Clave

* **"Bias" o Sesgo:** Cada uno de estos m√©todos tiene su propio **sesgo inductivo** (como vimos antes). Por ejemplo, ID3 prefiere √°rboles cortos y atributos informativos cerca de la ra√≠z. CART, con el √≠ndice Gini, tambi√©n busca la simplicidad.

* **Complejidad vs. Precisi√≥n:** Hay un equilibrio. Un √°rbol m√°s profundo y complejo puede ser muy preciso en los datos de entrenamiento (potencialmente sobreajust√°ndose), pero puede cometer m√°s errores en datos nuevos. Los √°rboles m√°s cortos son a menudo mejores para **generalizar**, aunque podr√≠an no ser perfectos en los datos de entrenamiento.

* **No Hay un "Mejor" M√©todo Universal:** No existe un m√©todo de selecci√≥n de atributos que sea universalmente superior a todos los dem√°s. La elecci√≥n depende del contexto, los datos y los objetivos espec√≠ficos del problema de clasificaci√≥n.


## 3.7. Sobreajuste y poda de √°rboles

¬°Perfecto! Este es un tema crucial en el aprendizaje autom√°tico. Comprender el **sobreajuste** y c√≥mo **podar √°rboles** es fundamental para construir modelos √∫tiles y no solo "memoriones".

## Sobreajuste y Poda de √Årboles de Decisi√≥n: Evitando el "Memori√≥n"

Como ya vimos, el algoritmo **ID3** (y otros similares) tienen como objetivo clasificar los datos de entrenamiento a la perfecci√≥n. Sin embargo, esto puede ser contraproducente. Cuando un modelo clasifica **demasiado bien** los datos de entrenamiento, a menudo significa que se ha vuelto excesivamente complejo, ha "memorizado" cada detalle (incluido el ruido o las particularidades de la muestra) y, por lo tanto, no es bueno para **generalizar** con datos nuevos. Esto es lo que llamamos **sobreajuste (overfitting)**.

### ¬øQu√© es exactamente el Sobreajuste?

El sobreajuste ocurre cuando un √°rbol de decisi√≥n (o cualquier modelo) es **demasiado complejo** y se ajusta muy bien a los **datos de entrenamiento**, pero falla al aplicarse a **nuevas instancias** (datos que no ha visto antes). Es como un estudiante que memoriza cada palabra del libro, pero no entiende los conceptos, por lo que le va mal en el examen si las preguntas cambian un poco.

* **Ejemplo del problema del tiempo:** Si un dato en tu tabla de entrenamiento (como el Ejemplo 7) est√° mal clasificado, ID3 intentar√° aprender a clasificarlo correctamente. Esto podr√≠a llevar a que el √°rbol se ramifique m√°s y se vuelva m√°s complejo de lo necesario solo para "explicar" ese dato err√≥neo, en lugar de generar un nodo hoja simple. El resultado es un √°rbol que es perfecto para tus datos actuales, pero que es muy probable que cometa errores con datos futuros.

### Estrategias para Evitar el Sobreajuste: La Poda del √Årbol

El sobreajuste es un problema com√∫n, y se necesitan estrategias para **mitigarlo**. La m√°s importante en los √°rboles de decisi√≥n es la **poda**. Podar un √°rbol es como cortar las ramas que no son realmente √∫tiles o que hacen que el √°rbol sea demasiado complicado.

Existen dos enfoques principales para la poda:

1.  **Poda Directa del √Årbol:**
    * Despu√©s de que el √°rbol se ha generado completamente, se eval√∫an sus ramas.
    * Se eliminan las ramificaciones que parecen ser menos fiables o que no aportan una mejora significativa a la clasificaci√≥n.
    * Cuando se poda un nodo, se convierte en una **hoja** y se le asigna la clase mayoritaria de los ejemplos que ca√≠an en ese nodo antes de la poda.
    * Es dif√≠cil saber cu√°ndo parar de podar, pero la idea es simplificar el √°rbol para mejorar su capacidad de generalizaci√≥n.

2.  **Poda Basada en Reglas (Mapeado a Reglas):**
    * Primero, se construye el √°rbol de decisi√≥n a partir de los datos de entrenamiento.
    * Luego, cada camino desde la ra√≠z hasta una hoja del √°rbol se convierte en una **regla**. Por ejemplo: `SI (Ambiente = Soleado) Y (Humedad = Alta) ENTONCES (Clase = No Jugar)`.
    * **Poda de cada regla:** Se revisa cada regla individualmente. Si eliminar una condici√≥n (una parte del `AND`) en la regla mejora la precisi√≥n de la clasificaci√≥n, esa condici√≥n se elimina.
    * Finalmente, las reglas se ordenan por su precisi√≥n, y cuando se clasifica un nuevo ejemplo, se usan las reglas en ese orden.
    * **Ventaja:** Este m√©todo permite podar decisiones de forma m√°s **aislada** porque trabajas con reglas individuales, no con nodos que pueden afectar a m√∫ltiples reglas. No importa si la condici√≥n est√° cerca de la ra√≠z o de la hoja; la poda se hace por regla.

### ¬øC√≥mo Saber el Tama√±o Adecuado del √Årbol? (Validaci√≥n Cruzada)

Determinar el tama√±o √≥ptimo de un √°rbol (cu√°ndo dejar de crecerlo o hasta d√≥nde podarlo) es complicado. Una t√©cnica fundamental para hacer esto es la **validaci√≥n cruzada (cross-validation)**.

La validaci√≥n cruzada te permite estimar qu√© tan bien funcionar√≠a tu modelo con **datos nuevos** (datos de prueba) cuando no tienes un conjunto de datos de prueba separado.

* **Proceso B√°sico:**
    1.  **Dividir los Datos:** Tomas tu conjunto de datos disponible y lo divides en dos partes:
        * **Datos de Entrenamiento:** Se usan para construir el √°rbol de decisi√≥n. (Ej. 2/3 de los datos).
        * **Datos de Validaci√≥n:** Se usan para **evaluar la precisi√≥n** del √°rbol podado o en crecimiento, simulando c√≥mo clasificar√≠a datos futuros. (Ej. 1/3 de los datos).
    2.  **Evaluar la Poda:** Mientras podas el √°rbol (o decides cu√°ndo detener su crecimiento), usas los datos de validaci√≥n para ver si el √°rbol resultante mejora o mantiene su precisi√≥n. Si podar un nodo mejora la clasificaci√≥n en los datos de validaci√≥n, ¬°lo podas! Esto ayuda a eliminar las ramas que se crearon por el ruido en los datos de entrenamiento.
    3.  **Desventaja:** Necesitas suficientes datos para que tanto el conjunto de entrenamiento como el de validaci√≥n sean estad√≠sticamente significativos.

* **Validaci√≥n Cruzada de K-Iteraciones (K-fold Cross-Validation):**
    * Cuando no tienes muchos datos, esta t√©cnica es muy √∫til.
    * **Divisi√≥n:** Tus datos se dividen en "k" subconjuntos (o "folds") de igual tama√±o.
    * **Iteraciones:** El proceso se repite "k" veces. En cada repetici√≥n:
        * Un subconjunto se usa como **datos de validaci√≥n (prueba)**.
        * Los **"k-1" subconjuntos restantes** se usan como **datos de entrenamiento**.
    * **Resultado Final:** Al final, se promedian los resultados obtenidos en cada una de las "k" iteraciones para tener una estimaci√≥n m√°s robusta del rendimiento del modelo.
    * **Com√∫n:** Un valor com√∫n para "k" es 10 (validaci√≥n cruzada de 10 iteraciones) ya que suele dar buenos resultados.

En resumen, el sobreajuste es un problema de "memorizaci√≥n" que hace que el √°rbol sea in√∫til con datos nuevos. La **poda** es la soluci√≥n, simplificando el √°rbol para que **generalice** mejor. La **validaci√≥n cruzada** es la herramienta clave para saber cu√°ndo y cu√°nto podar, ayud√°ndonos a encontrar el equilibrio perfecto entre un modelo que aprende bien y uno que funciona bien en el mundo real.



## 3.8. Medidas de la precisi√≥n de la clasificaci√≥n. Curva ROC
## 3.9. Simplificaci√≥n de √°rboles de decisi√≥n mediante poda: algoritmo C4.5
## 3.10. Ensemble Learning y Random Forest
## 3.11. Aplicaciones y ejemplos de implementaci√≥n



# Tabla Comparativa de T√©cnicas de Preprocesamiento de Datos

| T√©cnica                                 | Concepto                                                                                                         | ¬øCu√°ndo usar?                                                                                                                                                                                                                                                                                                         | Ventajas                                                                                                  | Desventajas                                                                                                                                                                                                                                                                                                     |
| :-------------------------------------- | :--------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **I. T√©cnicas de Codificaci√≥n de Variables Categ√≥ricas** |                                                                                                                  |                                                                                                                                                                                                                                                                                                                       |                                                                                                           |                                                                                                                                                                                                                                                                                                                   |
| **1. Codificaci√≥n One-Hot** | Crea una nueva columna binaria (0 o 1) para cada categor√≠a √∫nica en la variable original.                       | Cuando las categor√≠as son **nominales** (sin orden) y el n√∫mero de categor√≠as no es excesivamente grande. Ideal para algoritmos que asumen independencia de caracter√≠sticas (ej., regresi√≥n lineal, SVM).                                                                                                              | Evita asumir un orden o relaci√≥n num√©rica artificial. F√°cil de entender. Compatible con la mayor√≠a de los algoritmos. | Puede generar un gran n√∫mero de columnas (alta dimensionalidad) si hay muchas categor√≠as. Aumenta la complejidad computacional y de almacenamiento. |
| **2. Codificaci√≥n Dummy** | Similar a One-Hot, pero crea `N-1` columnas para `N` categor√≠as. Una categor√≠a es la de referencia (inferida).  | Para evitar la **multicolinealidad perfecta** en modelos sensibles como la regresi√≥n lineal o log√≠stica, mientras se manejan categor√≠as nominales.                                                                                                                                                                      | Resuelve el problema de multicolinealidad. Mantiene las ventajas de One-Hot para categor√≠as nominales.   | A√∫n puede generar muchas columnas.                                                                                                                                                                                                                                                                    |
| **3. Codificaci√≥n Ordinal** | Asigna un n√∫mero entero a cada categor√≠a basado en un orden predefinido por el usuario.                         | Cuando las categor√≠as tienen un **orden intr√≠nseco o jerarqu√≠a** (variables ordinales).                                                                                                                                                                                                                               | Reduce la dimensionalidad a una sola columna. Mantiene la informaci√≥n del orden si es significativo.    | Si las categor√≠as no tienen un orden real, impone uno artificial que puede confundir al modelo (implicando distancias num√©ricas arbitrarias). |
| **4. LabelEncoder** | Asigna un valor num√©rico entero secuencial √∫nico a cada categor√≠a √∫nica en la variable. (Es una forma de Codificaci√≥n Ordinal arbitraria). | Principalmente para codificar la **variable objetivo (y)** en clasificaci√≥n. Tambi√©n para caracter√≠sticas (X) si el n√∫mero de categor√≠as es peque√±o y el algoritmo puede manejar el orden artificial (ej., √°rboles de decisi√≥n, Random Forest, GBT) o si hay un orden real. | Simple y f√°cil de usar. Reduce la dimensionalidad a una sola columna.                                     | Impone un orden num√©rico arbitrario a las categor√≠as, lo que puede ser problem√°tico para algoritmos que interpretan distancias (ej., K-NN, SVM, regresi√≥n lineal).                                                                                                                                     |
| **5. Codificaci√≥n por Frecuencia/Conteo** | Reemplaza cada categor√≠a con la frecuencia (o el conteo) de su aparici√≥n en el conjunto de datos.                  | Cuando la frecuencia de una categor√≠a es un predictor potencialmente importante para el modelo. Para variables categ√≥ricas con alta cardinalidad.                                                                                                                                                              | Reduce la dimensionalidad a una sola columna. Captura informaci√≥n sobre la popularidad de la categor√≠a.   | Categor√≠as con la misma frecuencia reciben el mismo valor, perdiendo su distinci√≥n. No es √∫til si la frecuencia no es relevante para la predicci√≥n. |
| **6. Codificaci√≥n por Media/Objetivo** | Reemplaza cada categor√≠a con la media de la variable objetivo (o alguna otra estad√≠stica) para esa categor√≠a.       | Para variables categ√≥ricas con **alta cardinalidad** en problemas de regresi√≥n o clasificaci√≥n.                                                                                                                                                                                                                       | Reduce la dimensionalidad dr√°sticamente. Captura informaci√≥n predictiva directamente de la variable objetivo. | Puede introducir *data leakage* (fuga de datos) si no se implementa cuidadosamente (usar solo datos de entrenamiento). Susceptible a *overfitting* en categor√≠as con pocos ejemplos. Necesita t√©cnicas de suavizado. |
| **7. Codificaci√≥n Hash** | Transforma categor√≠as en un espacio de dimensiones m√°s bajas usando una funci√≥n hash, mapeando a un √≠ndice fijo.     | Para variables con **cardinalidad muy alta** donde One-Hot no es factible. En escenarios donde la eficiencia computacional y de memoria son cr√≠ticas.                                                                                                                                                            | Dimensionalidad fija y controlable. No requiere almacenar el mapeo. Puede manejar categor√≠as nuevas.       | Posibilidad de **colisiones** (diferentes categor√≠as mapeadas al mismo √≠ndice), lo que puede reducir el rendimiento. No es reversible.                                                                                                                                              |
| **8. Codificaci√≥n Binaria** | Convierte categor√≠as a n√∫meros enteros, luego esos enteros a su representaci√≥n binaria, creando una columna para cada bit. | Cuando el n√∫mero de categor√≠as es grande, pero no tan extremo como para necesitar hashing, buscando un compromiso entre One-Hot y Ordinal.                                                                                                                                                                    | Reduce la dimensionalidad en comparaci√≥n con One-Hot.                                                     | Las nuevas columnas tienen una relaci√≥n artificial que el modelo debe aprender. Menos interpretable que One-Hot.                                                                                                                                                                    |
| **II. Otras T√©cnicas de Preprocesamiento de Datos Relevantes** |                                                                                                                  |                                                                                                                                                                                                                                                                                                                       |                                                                                                           |                                                                                                                                                                                                                                                                                                                   |
| **1. Escalado de Caracter√≠sticas** | Ajusta la escala de las caracter√≠sticas num√©ricas para que tengan un rango similar.                                | Para algoritmos sensibles a la escala de las caracter√≠sticas (ej., K-NN, SVM, redes neuronales, regresi√≥n, clustering basado en distancia).                                                                                                                                                                          | Mejora el rendimiento y la estabilidad de muchos algoritmos. Acelera la convergencia de algoritmos basados en gradientes. | Puede dificultar la interpretabilidad directa de las caracter√≠sticas originales.                                                                                                                                                                                                    |
| **2. Manejo de Valores Faltantes** | Rellena los valores ausentes (NaN) en el conjunto de datos.                                                    | Siempre que haya valores faltantes en el dataset, ya que la mayor√≠a de los algoritmos no pueden procesarlos directamente.                                                                                                                                                                                             | Permite usar el dataset completo sin eliminar filas o columnas.                                           | Una imputaci√≥n incorrecta puede introducir sesgos o distorsiones en los datos. La elecci√≥n del m√©todo de imputaci√≥n es crucial.                                                                                                                                              |
| **3. Discretizaci√≥n / Binning** | Convierte variables num√©ricas continuas en categor√≠as o "bins" (intervalos).                                      | Para algoritmos que prefieren datos categ√≥ricos o rangos (ej., algunas implementaciones de √°rboles de decisi√≥n, reglas de asociaci√≥n para datos num√©ricos). Para reducir el ruido en datos continuos.                                                                                                             | Puede mejorar la robustez a los outliers. Permite usar t√©cnicas de miner√≠a de reglas en datos continuos.   | P√©rdida de informaci√≥n detallada de la variable num√©rica. La elecci√≥n de los l√≠mites de los bins puede ser arbitrante o cr√≠tica.                                                                                                                                          |
| **4. Reducci√≥n de Dimensionalidad** | Reduce el n√∫mero de caracter√≠sticas (columnas), conservando la mayor cantidad de informaci√≥n posible.             | Cuando hay un n√∫mero excesivo de caracter√≠sticas (especialmente despu√©s de One-Hot Encoding), para combatir la "maldici√≥n de la dimensionalidad", reducir el tiempo de entrenamiento y mejorar el rendimiento.                                                                                                | Reduce la complejidad del modelo. Acelera el entrenamiento. Puede mejorar la interpretabilidad (si las componentes son claras). | Puede llevar a una p√©rdida de informaci√≥n (aunque se busca minimizarla). Las nuevas caracter√≠sticas (componentes) a menudo son menos interpretables que las originales.                                                                                                     |
| **5. Generaci√≥n de Caracter√≠sticas (Feature Engineering)** | Crea nuevas caracter√≠sticas a partir de las existentes que pueden ayudar al modelo a aprender patrones.                      | Siempre que se pueda extraer informaci√≥n adicional relevante de los datos brutos que no sea directamente evidente para el modelo.                                                                                                                                                                           | Puede mejorar significativamente el rendimiento del modelo. Aporta conocimiento de dominio al proceso.   | Requiere creatividad, conocimiento del dominio y a menudo es un proceso iterativo y que consume mucho tiempo. Puede introducir *overfitting* si no se valida bien.                                                                                                        |


