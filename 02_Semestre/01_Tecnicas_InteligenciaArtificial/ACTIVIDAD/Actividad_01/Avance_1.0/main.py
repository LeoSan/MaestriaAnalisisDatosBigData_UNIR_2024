import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder


#ImportaciÃ³n del dataset De Vehiculos
print("\nðŸŽ¯ Paso 0: ----------------- Importamos el DataSet Vehiculos :------------------ ðŸŽ¯")
url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1jY1JAwakImo53OxBA0oiJTlAH9G5vi3d'
df = pd.read_csv(url_descarga_directa, sep=';')

#CaracterizaciÃ³n del dataset
print("\nðŸ“‹ Primeras 5 filas del dataset:")
print(df.head())

print("\nðŸ“‹ INFORMACIÃ“N DETALLADA:")
print(df.info())

## Preprocesamiento de Datos
print("\nðŸŽ¯ Paso 1: ------------ Preprocesamiento de Datos ------------------------ ðŸŽ¯")
df_encoded = df.copy()
#print("\nðŸŽ¯ DISTRIBUCIÃ“N DE LA VARIABLE OBJETIVO (class):")
# Columnas a codificar
# 'class' es la columna objetivo

features = ['Buying', 'Maintenance', 'Doors', 'Person', 'lug_boot', 'safety']
target = 'class'

# Aplicamos LabelEncoder a cada columna categÃ³rica, incluyendo la columna objetivo
for col in features + [target]:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    print(f" ðŸ” Mapeo de {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}")

print("\n ðŸ“‹ Primeras 5 filas del dataset codificado:")
print(df_encoded.head())

#CaracterizaciÃ³n del Dataset
print("\nðŸŽ¯ Paso 2: ------------ CaracterizaciÃ³n del Dataset ------------------------ ðŸŽ¯")

print(f"\n ðŸ“‹ NÃºmero total de instancias: {df_encoded.shape[0]}")
print(f"\n ðŸ“‹ NÃºmero de atributos de entrada: {df_encoded.shape[1] - 1}") # Excluyendo la columna 'class'
print(f"\n ðŸ“‹ Dataset Vehiculos con {df_encoded.shape[0]} filas y {df_encoded.shape[1]} columnas")
print("\n ðŸ“‹ DescripciÃ³n de atributos de entrada y su tipo:")

columan_desc = {"Buying":"Precio de compra del vehÃ­culo, clasificado en categorÃ­as como vhigh (muy alto), high (alto), med (medio) y low (bajo)."
                , "Maintenance":"Costo de mantenimiento del vehÃ­culo, con la misma categorizaciÃ³n que buying."
                , "Doors":"NÃºmero de puertas del automÃ³vil, expresado en valores numÃ©ricos como '2', '3', '4', o '5more' (5 o mÃ¡s)."
                , "Person":"Capacidad de ocupantes del automÃ³vil, con valores como '2', '4' y 'more (mÃ¡s de 4)."
                , "lug_boot":"TamaÃ±o del maletero, categorizado como small (pequeÃ±o), med (medio) o big (grande)"
                , "safety":"Nivel de seguridad del automÃ³vil, clasificado como low (bajo), med (medio) o high (alto)"}

for col in features:
    print(f" ðŸ” Atributo: {col}, DescripciÃ³n: [{columan_desc[col]}], Tipo: [categÃ³rico]") # Agrega el significado real
    print(f" Valores Ãºnicos (antes de codificar): {df[col].unique()}")
    
print("\n ðŸ“‹ InformaciÃ³n de la clase objetivo:")
print(f"\n - Columna de clase: '{target}'")
print(f"\n - NÃºmero de clases: {df_encoded[target].nunique()}")

print("\n ðŸ“‹ RepresentaciÃ³n de las clases y su conteo:")
print(df[target].value_counts()) # Mostrar conteo de valores originales antes de codificar para mayor claridad
print(f"\n ðŸ“‹ Porcentajes:")
print((df[target].value_counts() / len(df) * 100).round(2))

print(f"\n ðŸ“‹ Tipo de valor de la clase (despuÃ©s de codificaciÃ³n): {df_encoded[target].dtype}")
#print(f"\n ðŸ“‹ Memoria utilizada: {df_encoded.memory_usage(deep=True).sum()} bytes")

# Verificar valores desconocidos (nulos)
print("\n ðŸ“‹ Valores nulos por columna:")
print(df_encoded.isnull().sum())

print("\n ðŸ“‹ ESTADÃSTICAS DESCRIPTIVAS:")
print(df_encoded.describe(include='all'))

##DescripciÃ³n GrÃ¡fica datos Originales
print("\nðŸŽ¯ Paso 3: ------------ DescripciÃ³n GrÃ¡fica datos originales------------------------ ðŸŽ¯")
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15, 10))

# Histograma de la distribuciÃ³n de las clases
plt.subplot(2, 2, 1)
sns.countplot(x=target, data=df)
plt.title('DistribuciÃ³n de la Clase de Aceptabilidad de Coches')
plt.xlabel('Clase (original)')
plt.ylabel('Conteo')

# Histograma de algunas caracterÃ­sticas de entrada (despuÃ©s de codificaciÃ³n)
plt.subplot(2, 2, 2)
sns.countplot(x='Buying', data=df) # O df_encoded si prefieres los valores numÃ©ricos
plt.title('DistribuciÃ³n de Costo de Compra')

plt.subplot(2, 2, 3)
sns.countplot(x='Doors', data=df)
plt.title('DistribuciÃ³n de NÃºmero de Puertas')

plt.tight_layout()
plt.show()

## Entrenamiento y EvaluaciÃ³n de Modelos
print("\nðŸŽ¯ Paso 4: ------------ Procesasamiento del dataset Transformaciones previas necesarias para la modelaciÃ³n------------------------ ðŸŽ¯")
## DivisiÃ³n del Dataset en Entrenamiento y Prueba
# Definimos las caracterÃ­sticas de entrada (X) y la variable objetivo (y)   
X = df_encoded[features]
y = df_encoded[target]
# Divido el dataset en conjuntos de entrenamiento y prueba
# utilizo una proporciÃ³n de 70-30% o 80-20%
# Aseguramos que la divisiÃ³n mantenga la proporciÃ³n de clases utilizando stratify=y
# stratify=y es importante para mantener la misma proporciÃ³n de clases en los conjuntos de entrenamiento y prueba

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,      # 30% para prueba
    random_state=42,    # Para reproducibilidad
    stratify=y          # Mantener proporciÃ³n de clases
)
print("\n ðŸ“‹ Divido el dataset en conjuntos de entrenamiento y prueba. Una proporciÃ³n comÃºn es 70-30% o 80-20% ")
print(f"\n âœ… Dimensiones de X_train: {X_train.shape}")
print(f"\n âœ… Dimensiones de X_test: {X_test.shape}")

## SelecciÃ³n y Entrenamiento de Modelos
print("\n ðŸ“‹ SelecciÃ³n y Entrenamiento de Modelos ")
print("\n ðŸ“‹ Decision Tree Classifier ")

from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(
    random_state=42,
    max_depth=5,           # Profundidad mÃ¡xima
    min_samples_split=4,   # MÃ­nimo de muestras para dividir
    min_samples_leaf=2     # MÃ­nimo de muestras en hoja
)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

##Random Forest Classifier:
print("\n ðŸ“‹ Random Forest Classifier: ")

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(
    n_estimators=100
    , random_state=42
)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

## Entrenamiento y EvaluaciÃ³n de Modelos
print("\nðŸŽ¯ Paso 5: ------------ Entrenamiento y EvaluaciÃ³n de Modelos------------------------ ðŸŽ¯")
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay 

print("\n ðŸ§  ------- MÃ©tricas de ClasificaciÃ³n -------")
print("\n ðŸ§  EvaluaciÃ³n del Modelo Decision Tree ---")
print(f"\n ðŸ§  Accuracy Decision Tree: {accuracy_score(y_test, y_pred_dt):.4f}")
print("\n ðŸ§  Matriz de ConfusiÃ³n Decision Tree:")
print(confusion_matrix(y_test, y_pred_dt))
print("\n ðŸ§  Reporte de ClasificaciÃ³n Decision Tree:")
print(classification_report(y_test, y_pred_dt, target_names=[str(cls) for cls in le.inverse_transform(sorted(y.unique()))]))

print("\n ðŸ§  EvaluaciÃ³n del Modelo Random Forest ---")
print(f"\n ðŸ§  Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\n ðŸ§  Matriz de ConfusiÃ³n Random Forest:")
print(confusion_matrix(y_test, y_pred_rf))
print("\n ðŸ§  Reporte de ClasificaciÃ³n Random Forest:")
print(classification_report(y_test, y_pred_rf, target_names=[str(cls) for cls in le.inverse_transform(sorted(y.unique()))]))

## EvaluaciÃ³n y ComparaciÃ³n de Resultados
print("\nðŸŽ¯ Paso 6: ------------  EvaluaciÃ³n y ComparaciÃ³n de Resultados ------------------------ ðŸŽ¯")

print("\n ðŸ“ˆ -------ComparaciÃ³n GrÃ¡fica de Resultados: -------")
   
# Ejemplo de comparaciÃ³n de accuracy
models = ['Decision Tree', 'Random Forest']
accuracies = [accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_rf)]

plt.figure(figsize=(8, 5))
sns.barplot(x=models, y=accuracies)
plt.title('ComparaciÃ³n de Accuracy entre Modelos')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

# VisualizaciÃ³n de matrices de confusiÃ³n
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Matriz de ConfusiÃ³n: Decision Tree')
axes[0].set_xlabel('Predicho')
axes[0].set_ylabel('Real')

sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title('Matriz de ConfusiÃ³n: Random Forest')
axes[1].set_xlabel('Predicho')
axes[1].set_ylabel('Real')

plt.tight_layout()
plt.show()

# --- Para el Modelo Decision Tree ---
print("\n ðŸ“ˆ --- MÃ©tricas del Modelo Decision Tree ---")

# 1. Instancias clasificadas correctamente e incorrectamente
correct_dt = accuracy_score(y_test, y_pred_dt) * len(y_test)
incorrect_dt = len(y_test) - correct_dt

print(f"\n ðŸ§  Instancias clasificadas correctamente (Decision Tree): {int(correct_dt)}")
print(f"\n ðŸ§  Instancias clasificadas incorrectamente (Decision Tree): {int(incorrect_dt)}")

# 2. Matriz de ConfusiÃ³n
cm_dt = confusion_matrix(y_test, y_pred_dt)

print("\n Matriz de ConfusiÃ³n (Decision Tree):")
print(cm_dt)

# Visualizar la Matriz de ConfusiÃ³n
disp_dt = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=le.inverse_transform(sorted(y.unique()))) # Usa las etiquetas originales
disp_dt.plot(cmap=plt.cm.Blues)
plt.title('Matriz de ConfusiÃ³n: Decision Tree')
plt.show()

# 3. TP Rate y FP Rate (usando classification_report o calculÃ¡ndolos manualmente desde la CM)
# El classification_report te da Precision, Recall (TP Rate), F1-Score y Support
report_dt = classification_report(y_test, y_pred_dt, output_dict=True, target_names=le.inverse_transform(sorted(y.unique())))

print("\n Reporte de ClasificaciÃ³n (Decision Tree):")
for class_label, metrics in report_dt.items():
    if class_label in le.inverse_transform(sorted(y.unique())): # Solo para las clases reales
        recall = metrics['recall'] # TP Rate
        # Para FP Rate, es un poco mÃ¡s complejo y depende de si es binario o multiclase
        # FP = Suma de la columna - True Positives para esa clase
        # TN = Suma de las filas y columnas excepto la fila y columna de esa clase
        # FP Rate = FP / (FP + TN)

        print(f"Clase '{class_label}':")
        print(f"  TP Rate (Recall): {recall:.4f}")
        # Para FP Rate por clase:
        # True Negatives (TN) for a class 'i': sum of all cells NOT in row 'i' AND NOT in column 'i'
        # False Positives (FP) for a class 'i': sum of column 'i' cells MINUS True Positives of class 'i'
        TP_dt = cm_dt[le.transform([class_label])[0], le.transform([class_label])[0]] # True Positive for this class
        FN_dt = np.sum(cm_dt[le.transform([class_label])[0], :]) - TP_dt # False Negatives for this class
        FP_dt = np.sum(cm_dt[:, le.transform([class_label])[0]]) - TP_dt # False Positives for this class
        TN_dt = np.sum(cm_dt) - (TP_dt + FN_dt + FP_dt) # True Negatives for this class

        # Manejar la divisiÃ³n por cero si FP + TN es 0
        fp_rate_dt = FP_dt / (FP_dt + TN_dt) if (FP_dt + TN_dt) > 0 else 0
        print(f"  FP Rate: {fp_rate_dt:.4f}")
        print("-" * 20)

print("\n")

# --- Para el Modelo Random Forest ---
print("\n ðŸ§  MÃ©tricas del Modelo Random Forest ---")

# 1. Instancias clasificadas correctamente e incorrectamente
correct_rf = accuracy_score(y_test, y_pred_rf) * len(y_test)
incorrect_rf = len(y_test) - correct_rf

print(f"\n ðŸ§ Instancias clasificadas correctamente (Random Forest): {int(correct_rf)}")
print(f"\n ðŸ§ Instancias clasificadas incorrectamente (Random Forest): {int(incorrect_rf)}")

# 2. Matriz de ConfusiÃ³n
cm_rf = confusion_matrix(y_test, y_pred_rf)
print("\n ðŸ§  Matriz de ConfusiÃ³n (Random Forest):")
print(cm_rf)

# Visualizar la Matriz de ConfusiÃ³n
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=le.inverse_transform(sorted(y.unique())))
disp_rf.plot(cmap=plt.cm.Blues)
plt.title('Matriz de ConfusiÃ³n: Random Forest')
plt.show()

# 3. TP Rate y FP Rate
report_rf = classification_report(y_test, y_pred_rf, output_dict=True, target_names=le.inverse_transform(sorted(y.unique())))

print("\n ðŸ§  Reporte de ClasificaciÃ³n (Random Forest):")
for class_label, metrics in report_rf.items():
    if class_label in le.inverse_transform(sorted(y.unique())):
        recall = metrics['recall'] # TP Rate

        print(f"Clase '{class_label}':")
        print(f"  TP Rate (Recall): {recall:.4f}")

        # Para FP Rate por clase:
        TP_rf = cm_rf[le.transform([class_label])[0], le.transform([class_label])[0]]
        FN_rf = np.sum(cm_rf[le.transform([class_label])[0], :]) - TP_rf
        FP_rf = np.sum(cm_rf[:, le.transform([class_label])[0]]) - TP_rf
        TN_rf = np.sum(cm_rf) - (TP_rf + FN_rf + FP_rf)

        fp_rate_rf = FP_rf / (FP_rf + TN_rf) if (FP_rf + TN_rf) > 0 else 0
        print(f"  FP Rate: {fp_rate_rf:.4f}")
        print("-" * 20)