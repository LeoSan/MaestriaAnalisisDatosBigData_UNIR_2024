{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1406ba",
   "metadata": {},
   "source": [
    "<img src=\"https://www.unir.net/wp-content/uploads/2019/11/Unir_2021_logo.svg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f603c",
   "metadata": {},
   "source": [
    "<center><h1>T√©cnicas de Inteligencia Artificial</header1></center>\n",
    "<left><h1>Actividad 1. Laboratorio: √Årboles de decisi√≥n, reglas y ensemble learning</header1></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1aaac",
   "metadata": {},
   "source": [
    "Presentado por: Leonard Jose Cuenca Roa  <br>\n",
    "Fecha: 20/06/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec299b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:14:04.930713Z",
     "start_time": "2022-03-14T15:14:04.921682Z"
    }
   },
   "source": [
    "## Importaci√≥n de librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1abf7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:14:46.228059Z",
     "start_time": "2022-03-14T15:14:46.223108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44b924",
   "metadata": {},
   "source": [
    "## Cargar el Dataset\n",
    "\n",
    "**Se establece la descripci√≥n del dataset:**\n",
    "\n",
    "**üéØDescripci√≥n:** Este conjunto de datos tiene la evaluacion de autom√≥viles validando los siguientes cirterios: \n",
    "- üí∞ buying: Precio de compra del veh√≠culo, clasificado en categor√≠as como vhigh (muy alto), high (alto), med (medio) y low (bajo).\n",
    "- üßëüèª‚Äçüîß maintenance: Costo de mantenimiento del veh√≠culo, con la misma categorizaci√≥n que buying.\n",
    "- üö™doors: N√∫mero de puertas del autom√≥vil, expresado en valores num√©ricos como \"2\", \"3\", \"4\", o \"5more\" (5 o m√°s).\n",
    "- üë™ person: Capacidad de ocupantes del autom√≥vil, con valores como \"2\", \"4\" y \"more\" (m√°s de 4).\n",
    "- üéílug_boot: Tama√±o del maletero, categorizado como small (peque√±o), med (medio) o big (grande).\n",
    "- ü¶∫ safety: Nivel de seguridad del autom√≥vil, clasificado como low (bajo), med (medio) o high (alto).\n",
    "- üìä class: Categor√≠a del autom√≥vil basada en la combinaci√≥n de caracter√≠sticas anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset De Vehiculos\n",
    "df = pd.read_csv('C:/Users/LeonardJos√©CuencaRoa/Desktop/Personal/Maestria/Actividad_TIA/data/Laboratorio_dataset_car.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f868eab",
   "metadata": {},
   "source": [
    "## Explique el problema a resolver. \n",
    "Descripci√≥n del problema. Tipo de problema (justifique). Variable objetivo, variables de entrada. Utilidad de su posible soluci√≥n. Elementos adicionales que considere relevantes:\n",
    "\n",
    "Objetivo: Clasificar la aceptabilidad de coches basado en sus caracter√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b719c1",
   "metadata": {},
   "source": [
    "## Caracterizaci√≥n del Dataset\n",
    "\n",
    "Se incorpor√° una descripci√≥n (EDA) del conjunto de datos utilizado. Se analiza el dataset proporcionando, se muestra al menos algunas de sus caracter√≠sticas mediante tablas y al menos algunas de ellas en modo gr√°fico (p.ej., histogramas, diagramas de dispersi√≥n, diagramas de cajas y bigotes, etc.)\n",
    "\n",
    "Como primer paso como an√°lista de datos valido el dataset proporcionado, considero las siguientes premisas afirmativas: \n",
    "\n",
    "- Debo identificar los atributos:\n",
    "    - Todas las columnas son categ√≥ricas, ya que no menciona valores recurrentes, progresivos, datos tipo tiempo o algun dato para ser calculado o resumido. \n",
    "- Existen valores desconocidos: \n",
    "    - Luego de correr un script para validar si existe valores nulos, vacios o incompletos se da por afirmativo que no hay valores nulos. \n",
    "        - Flujo alterno en caso que si existiera se tomar√≠a una estrategia como (eliminarlos, imputarlos √≥ proyectarlos con una tecnica probabilistica para sacar una media). Pero aplica para este caso\n",
    "- Se decice la codificaci√≥n de caracter√≠sticas como: \n",
    "    - Se uso scikit-learn ya que trabaja con datos num√©ricos. Para variables ordinales (como vhigh, high, med, low, small, big), \n",
    "    - Se us√≥ LabelEncoder consider√© ser adecuado ya que hay un orden inherente\n",
    "    - Para los atributos Doors y Person a pesar que son valores n√∫mericos los trat√© como categ√≥ricos ya que no representa un valor para ser calculado o valores reales.  \n",
    "    - El atributo class es mi variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ed5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Caracterizaci√≥n del Dataset\n",
    "print(\"\\nüéØ Paso 2: ------------ Caracterizaci√≥n del Dataset ------------------------ üéØ\")\n",
    "\n",
    "print(f\"\\n üìã N√∫mero total de instancias: {df_encoded.shape[0]}\")\n",
    "print(f\"\\n üìã N√∫mero de atributos de entrada: {df_encoded.shape[1] - 1}\") # Excluyendo la columna 'class'\n",
    "print(f\"\\n üìã Dataset Vehiculos con {df_encoded.shape[0]} filas y {df_encoded.shape[1]} columnas\")\n",
    "print(\"\\n üìã Descripci√≥n de atributos de entrada y su tipo:\")\n",
    "\n",
    "columan_desc = {\"Buying\":\"Precio de compra del veh√≠culo, clasificado en categor√≠as como vhigh (muy alto), high (alto), med (medio) y low (bajo).\"\n",
    "                , \"Maintenance\":\"Costo de mantenimiento del veh√≠culo, con la misma categorizaci√≥n que buying.\"\n",
    "                , \"Doors\":\"N√∫mero de puertas del autom√≥vil, expresado en valores num√©ricos como '2', '3', '4', o '5more' (5 o m√°s).\"\n",
    "                , \"Person\":\"Capacidad de ocupantes del autom√≥vil, con valores como '2', '4' y 'more (m√°s de 4).\"\n",
    "                , \"lug_boot\":\"Tama√±o del maletero, categorizado como small (peque√±o), med (medio) o big (grande)\"\n",
    "                , \"safety\":\"Nivel de seguridad del autom√≥vil, clasificado como low (bajo), med (medio) o high (alto)\"}\n",
    "\n",
    "for col in features:\n",
    "    print(f\" üîç Atributo: {col}, Descripci√≥n: [{columan_desc[col]}], Tipo: [categ√≥rico]\") # Agrega el significado real\n",
    "    print(f\" Valores √∫nicos (antes de codificar): {df[col].unique()}\")\n",
    "    \n",
    "print(\"\\n üìã Informaci√≥n de la clase objetivo:\")\n",
    "print(f\"\\n - Columna de clase: '{target}'\")\n",
    "print(f\"\\n - N√∫mero de clases: {df_encoded[target].nunique()}\")\n",
    "\n",
    "print(\"\\n üìã Representaci√≥n de las clases y su conteo:\")\n",
    "print(df[target].value_counts()) # Mostrar conteo de valores originales antes de codificar para mayor claridad\n",
    "print(f\"\\n üìã Porcentajes:\")\n",
    "print((df[target].value_counts() / len(df) * 100).round(2))\n",
    "\n",
    "print(f\"\\n üìã Tipo de valor de la clase (despu√©s de codificaci√≥n): {df_encoded[target].dtype}\")\n",
    "#print(f\"\\n üìã Memoria utilizada: {df_encoded.memory_usage(deep=True).sum()} bytes\")\n",
    "\n",
    "# Verificar valores desconocidos (nulos)\n",
    "print(\"\\n üìã Valores nulos por columna:\")\n",
    "print(df_encoded.isnull().sum())\n",
    "\n",
    "print(\"\\n üìã ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "print(df_encoded.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo que responde a la descripci√≥n anterior (incorpore las lineas de code necesarias. Describa cadas sentencia de c√≥digo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab5e48",
   "metadata": {},
   "source": [
    "En un par de p√°rrafos haga un resumen de los principales hallazagos encontrados:    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5beca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:52:20.156185Z",
     "start_time": "2022-03-14T15:52:20.150187Z"
    }
   },
   "source": [
    "## Preprocesamiento del dataset. Transformaciones previas necesarias para la modelaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo que realice las transformaciones necesarias para poder realizar los procesos de modelaci√≥n. Ej.One hot enconding\n",
    "\n",
    "## Entrenamiento y Evaluaci√≥n de Modelos\n",
    "print(\"\\nüéØ Paso 4: ------------ Procesasamiento del dataset Transformaciones previas necesarias para la modelaci√≥n------------------------ üéØ\")\n",
    "## Divisi√≥n del Dataset en Entrenamiento y Prueba\n",
    "# Definimos las caracter√≠sticas de entrada (X) y la variable objetivo (y)   \n",
    "X = df_encoded[features]\n",
    "y = df_encoded[target]\n",
    "# Divido el dataset en conjuntos de entrenamiento y prueba\n",
    "# utilizo una proporci√≥n de 70-30% o 80-20%\n",
    "# Aseguramos que la divisi√≥n mantenga la proporci√≥n de clases utilizando stratify=y\n",
    "# stratify=y es importante para mantener la misma proporci√≥n de clases en los conjuntos de entrenamiento y prueba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\n üìã Divido el dataset en conjuntos de entrenamiento y prueba. Una proporci√≥n com√∫n es 70-30% o 80-20% \")\n",
    "print(f\"\\n ‚úÖ Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"\\n ‚úÖ Dimensiones de X_test: {X_test.shape}\")\n",
    "\n",
    "\n",
    "## Selecci√≥n y Entrenamiento de Modelos\n",
    "print(\"\\n üìã Selecci√≥n y Entrenamiento de Modelos \")\n",
    "print(\"\\n üìã Decision Tree Classifier \")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=5,           # Profundidad m√°xima\n",
    "    min_samples_split=4,   # M√≠nimo de muestras para dividir\n",
    "    min_samples_leaf=2     # M√≠nimo de muestras en hoja\n",
    ")\n",
    "# Par√°metros relevantes a explicar:\n",
    "# criterion: funci√≥n para medir la calidad de una divisi√≥n (gini o entropy)\n",
    "# max_depth: profundidad m√°xima del √°rbol\n",
    "# min_samples_split: n√∫mero m√≠nimo de muestras requeridas para dividir un nodo interno\n",
    "# min_samples_leaf: n√∫mero m√≠nimo de muestras requeridas para estar en un nodo hoja\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "##Random Forest Classifier:\n",
    "print(\"\\n üìã Random Forest Classifier: \")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "# Par√°metros relevantes a explicar:\n",
    "# n_estimators: n√∫mero de √°rboles en el bosque\n",
    "# criterion: igual que Decision Tree\n",
    "# max_depth: igual que Decision Tree\n",
    "# min_samples_split: igual que Decision Tree\n",
    "# min_samples_leaf: igual que Decision Tree\n",
    "# bootstrap: si se utilizan muestras de arranque al construir los √°rboles\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49815fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:56:34.366469Z",
     "start_time": "2022-03-14T15:56:34.358471Z"
    }
   },
   "source": [
    "## Divisi√≥n del dataset en datos de entrenamiento y datos de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo que realice la divisi√≥n en entrenamiento y test, de acuerdo con la estretgia de evluaci√≥n planeada. Describa cu√°l es.\n",
    "\n",
    "X = df_encoded[features]\n",
    "y = df_encoded[target]\n",
    "# Divido el dataset en conjuntos de entrenamiento y prueba\n",
    "# utilizo una proporci√≥n de 70-30% o 80-20%\n",
    "# Aseguramos que la divisi√≥n mantenga la proporci√≥n de clases utilizando stratify=y\n",
    "# stratify=y es importante para mantener la misma proporci√≥n de clases en los conjuntos de entrenamiento y prueba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,      # 30% para prueba\n",
    "    random_state=42,    # Para reproducibilidad\n",
    "    stratify=y          # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(\"\\n üìã Divido el dataset en conjuntos de entrenamiento y prueba. Una proporci√≥n com√∫n es 70-30% o 80-20% \")\n",
    "print(f\"\\n ‚úÖ Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"\\n ‚úÖ Dimensiones de X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91e96b",
   "metadata": {},
   "source": [
    "## Ajuste de los modelos de clasificaci√≥n propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552bc64",
   "metadata": {},
   "source": [
    "Justifique la selecci√≥n de las dos propuestas de modelaci√≥n seleccionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo de ajuste del modelo de clasificaci√≥n 1\n",
    "## Entrenamiento y Evaluaci√≥n de Modelos\n",
    "print(\"\\nüéØ Paso 5: ------------ Entrenamiento y Evaluaci√≥n de Modelos------------------------ üéØ\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    " \n",
    "print(\"\\n üß† ------- M√©tricas de Clasificaci√≥n -------\")\n",
    "print(\"\\n üß† Evaluaci√≥n del Modelo Decision Tree ---\")\n",
    "print(f\"\\n üß† Accuracy Decision Tree: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(\"\\n üß† Matriz de Confusi√≥n Decision Tree:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"\\n üß† Reporte de Clasificaci√≥n Decision Tree:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=[str(cls) for cls in le.inverse_transform(sorted(y.unique()))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo de ajuste del modelo de clasificaci√≥n 2\n",
    "print(\"\\n üß† Evaluaci√≥n del Modelo Random Forest ---\")\n",
    "print(f\"\\n üß† Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"\\n üß† Matriz de Confusi√≥n Random Forest:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\n üß† Reporte de Clasificaci√≥n Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[str(cls) for cls in le.inverse_transform(sorted(y.unique()))]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b8461",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n de cada modelo\n",
    "\n",
    "Al menos incluya:\n",
    "\n",
    "+ Instancias clasificadas correctamente\n",
    "+ Instancias clasificadas incorrectamente\n",
    "+ TP Rate\n",
    "+ FP Rate\n",
    "+ Matriz de confusi√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e675b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo para mostrar la evaluaci√≥n del modelo de clasificaci√≥n 1\n",
    "# --- Para el Modelo Decision Tree ---\n",
    "print(\"\\n--- M√©tricas del Modelo Decision Tree ---\")\n",
    "\n",
    "# 1. Instancias clasificadas correctamente e incorrectamente\n",
    "correct_dt = accuracy_score(y_test, y_pred_dt) * len(y_test)\n",
    "incorrect_dt = len(y_test) - correct_dt\n",
    "\n",
    "print(f\"Instancias clasificadas correctamente (Decision Tree): {int(correct_dt)}\")\n",
    "print(f\"Instancias clasificadas incorrectamente (Decision Tree): {int(incorrect_dt)}\")\n",
    "\n",
    "# 2. Matriz de Confusi√≥n\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"\\nMatriz de Confusi√≥n (Decision Tree):\")\n",
    "print(cm_dt)\n",
    "\n",
    "# Visualizar la Matriz de Confusi√≥n\n",
    "disp_dt = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=le.inverse_transform(sorted(y.unique()))) # Usa las etiquetas originales\n",
    "disp_dt.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusi√≥n: Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# 3. TP Rate y FP Rate (usando classification_report o calcul√°ndolos manualmente desde la CM)\n",
    "# El classification_report te da Precision, Recall (TP Rate), F1-Score y Support\n",
    "report_dt = classification_report(y_test, y_pred_dt, output_dict=True, target_names=le.inverse_transform(sorted(y.unique())))\n",
    "\n",
    "print(\"\\nReporte de Clasificaci√≥n (Decision Tree):\")\n",
    "for class_label, metrics in report_dt.items():\n",
    "    if class_label in le.inverse_transform(sorted(y.unique())): # Solo para las clases reales\n",
    "        recall = metrics['recall'] # TP Rate\n",
    "        # Para FP Rate, es un poco m√°s complejo y depende de si es binario o multiclase\n",
    "        # FP = Suma de la columna - True Positives para esa clase\n",
    "        # TN = Suma de las filas y columnas excepto la fila y columna de esa clase\n",
    "        # FP Rate = FP / (FP + TN)\n",
    "\n",
    "        print(f\"Clase '{class_label}':\")\n",
    "        print(f\"  TP Rate (Recall): {recall:.4f}\")\n",
    "        # Para FP Rate por clase:\n",
    "        # True Negatives (TN) for a class 'i': sum of all cells NOT in row 'i' AND NOT in column 'i'\n",
    "        # False Positives (FP) for a class 'i': sum of column 'i' cells MINUS True Positives of class 'i'\n",
    "        TP_dt = cm_dt[le.transform([class_label])[0], le.transform([class_label])[0]] # True Positive for this class\n",
    "        FN_dt = np.sum(cm_dt[le.transform([class_label])[0], :]) - TP_dt # False Negatives for this class\n",
    "        FP_dt = np.sum(cm_dt[:, le.transform([class_label])[0]]) - TP_dt # False Positives for this class\n",
    "        TN_dt = np.sum(cm_dt) - (TP_dt + FN_dt + FP_dt) # True Negatives for this class\n",
    "\n",
    "        # Manejar la divisi√≥n por cero si FP + TN es 0\n",
    "        fp_rate_dt = FP_dt / (FP_dt + TN_dt) if (FP_dt + TN_dt) > 0 else 0\n",
    "        print(f\"  FP Rate: {fp_rate_dt:.4f}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad219a0c",
   "metadata": {},
   "source": [
    "Construya un p√°rrafo con los principales hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo  para mostrarla evaluaci√≥n del modelo de clasificaci√≥n 2\n",
    "\n",
    "# --- Para el Modelo Random Forest ---\n",
    "print(\"\\n--- M√©tricas del Modelo Random Forest ---\")\n",
    "\n",
    "# 1. Instancias clasificadas correctamente e incorrectamente\n",
    "correct_rf = accuracy_score(y_test, y_pred_rf) * len(y_test)\n",
    "incorrect_rf = len(y_test) - correct_rf\n",
    "\n",
    "print(f\"Instancias clasificadas correctamente (Random Forest): {int(correct_rf)}\")\n",
    "print(f\"Instancias clasificadas incorrectamente (Random Forest): {int(incorrect_rf)}\")\n",
    "\n",
    "# 2. Matriz de Confusi√≥n\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"\\nMatriz de Confusi√≥n (Random Forest):\")\n",
    "print(cm_rf)\n",
    "\n",
    "# Visualizar la Matriz de Confusi√≥n\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=le.inverse_transform(sorted(y.unique())))\n",
    "disp_rf.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusi√≥n: Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# 3. TP Rate y FP Rate\n",
    "report_rf = classification_report(y_test, y_pred_rf, output_dict=True, target_names=le.inverse_transform(sorted(y.unique())))\n",
    "\n",
    "print(\"\\nReporte de Clasificaci√≥n (Random Forest):\")\n",
    "for class_label, metrics in report_rf.items():\n",
    "    if class_label in le.inverse_transform(sorted(y.unique())):\n",
    "        recall = metrics['recall'] # TP Rate\n",
    "\n",
    "        print(f\"Clase '{class_label}':\")\n",
    "        print(f\"  TP Rate (Recall): {recall:.4f}\")\n",
    "\n",
    "        # Para FP Rate por clase:\n",
    "        TP_rf = cm_rf[le.transform([class_label])[0], le.transform([class_label])[0]]\n",
    "        FN_rf = np.sum(cm_rf[le.transform([class_label])[0], :]) - TP_rf\n",
    "        FP_rf = np.sum(cm_rf[:, le.transform([class_label])[0]]) - TP_rf\n",
    "        TN_rf = np.sum(cm_rf) - (TP_rf + FN_rf + FP_rf)\n",
    "\n",
    "        fp_rate_rf = FP_rf / (FP_rf + TN_rf) if (FP_rf + TN_rf) > 0 else 0\n",
    "        print(f\"  FP Rate: {fp_rate_rf:.4f}\")\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a7cec",
   "metadata": {},
   "source": [
    "Construya un p√°rrafo con los principales hallazgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df4eb5",
   "metadata": {},
   "source": [
    "## Comparaci√≥n del desempe√±o de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4acd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo para mostrar la comparaci√≥n de m√©tricas de desempe√±o de las dos propuestas en tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b644946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo para mostrar la comparaci√≥n de m√©tricas de desempe√±o de las dos propuestas en gr√°fica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d5ab4",
   "metadata": {},
   "source": [
    "Construya un p√°rrafo con los principales hallazgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810fb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:16:57.134093Z",
     "start_time": "2022-03-14T16:16:57.117129Z"
    }
   },
   "source": [
    "## Discusi√≥n de los resultados obtenidos y argumentos sobre c√≥mo se podr√≠an mejorar de dichos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b3044",
   "metadata": {},
   "source": [
    "Realice en este espacio todo el an√°lsis de resultados final incluyendo: ventajas y desventajas de cada modelo propuesto, Resultados comparados. Conclusiones objetivas y significantes con base a las diferentes m√©tricas escogidas. Recomendaciones de mejora de las propuestas: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "337.597px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
