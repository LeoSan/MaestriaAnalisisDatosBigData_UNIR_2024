{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1406ba",
   "metadata": {},
   "source": [
    "<img src=\"https://www.unir.net/wp-content/uploads/2019/11/Unir_2021_logo.svg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f603c",
   "metadata": {},
   "source": [
    "<center><h1>T√©cnicas de Inteligencia Artificial</header1></center>\n",
    "<left><h1>Actividad 1. Laboratorio: √Årboles de decisi√≥n, reglas y ensemble learning</header1></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1aaac",
   "metadata": {},
   "source": [
    "Presentado por: Leonard Jose Cuenca Roa  <br>\n",
    "Fecha: 11/06/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec299b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:14:04.930713Z",
     "start_time": "2022-03-14T15:14:04.921682Z"
    }
   },
   "source": [
    "## Importaci√≥n de librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1abf7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:14:46.228059Z",
     "start_time": "2022-03-14T15:14:46.223108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                           ConfusionMatrixDisplay, precision_recall_fscore_support)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo para gr√°ficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44b924",
   "metadata": {},
   "source": [
    "## Cargar el Dataset\n",
    "\n",
    "**Se establece la descripci√≥n del dataset:**\n",
    "\n",
    "**üéØDescripci√≥n:** Este conjunto de datos tiene la evaluacion de autom√≥viles validando los siguientes cirterios: \n",
    "- üí∞ buying: Precio de compra del veh√≠culo, clasificado en categor√≠as como vhigh (muy alto), high (alto), med (medio) y low (bajo).\n",
    "- üßëüèª‚Äçüîß maintenance: Costo de mantenimiento del veh√≠culo, con la misma categorizaci√≥n que buying.\n",
    "- üö™doors: N√∫mero de puertas del autom√≥vil, expresado en valores num√©ricos como \"2\", \"3\", \"4\", o \"5more\" (5 o m√°s).\n",
    "- üë™ person: Capacidad de ocupantes del autom√≥vil, con valores como \"2\", \"4\" y \"more\" (m√°s de 4).\n",
    "- üéílug_boot: Tama√±o del maletero, categorizado como small (peque√±o), med (medio) o big (grande).\n",
    "- ü¶∫ safety: Nivel de seguridad del autom√≥vil, clasificado como low (bajo), med (medio) o high (alto).\n",
    "- üìä class: Categor√≠a del autom√≥vil basada en la combinaci√≥n de caracter√≠sticas anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3541e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Paso 0: ----------------- Importamos el DataSet Veh√≠culos :------------------ üéØ\n",
      "‚ùå Error al cargar el dataset: name 'pd' is not defined\n",
      "\n",
      "üìã Primeras 5 filas del dataset:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Caracterizaci√≥n inicial del dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìã Primeras 5 filas del dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìã INFORMACI√ìN DETALLADA:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# PASO 0: IMPORTACI√ìN DEL DATASET\n",
    "print(\"\\nüéØ Paso 0: ----------------- Importamos el DataSet Veh√≠culos :------------------ üéØ\")\n",
    "    \n",
    "try:\n",
    "    url_descarga_directa = 'https://drive.google.com/uc?export=download&id=1jY1JAwakImo53OxBA0oiJTlAH9G5vi3d'\n",
    "    df = pd.read_csv(url_descarga_directa, sep=';')\n",
    "    print(\"‚úÖ Dataset cargado exitosamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Caracterizaci√≥n inicial del dataset\n",
    "print(\"\\nüìã Primeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nüìã INFORMACI√ìN DETALLADA:\")\n",
    "print(df.info())\n",
    "\n",
    "# PASO 1: PREPROCESAMIENTO DE DATOS\n",
    "print(\"\\nüéØ Paso 1: ------------ Preprocesamiento de Datos ------------------------ üéØ\")\n",
    "\n",
    "df_encoded = df.copy()\n",
    "features = ['Buying', 'Maintenance', 'Doors', 'Person', 'lug_boot', 'safety']\n",
    "target = 'class'\n",
    "\n",
    "# Diccionario para almacenar los encoders\n",
    "encoders = {}\n",
    "\n",
    "# Aplicamos LabelEncoder a cada columna categ√≥rica\n",
    "for col in features + [target]:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    encoders[col] = le  # Guardamos el encoder para uso posterior\n",
    "    print(f\"üîç Mapeo de {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "print(\"\\nüìã Primeras 5 filas del dataset codificado:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f868eab",
   "metadata": {},
   "source": [
    "## Explique el problema a resolver. \n",
    "\n",
    "Nuestro objetivo principal es determinar la aceptabilidad de los coches bas√°ndonos en sus caracter√≠sticas, utilizando dos modelos b√°sicos de inteligencia artificial. Para lograrlo, el proyecto se dividir√° en varias etapas clave. Primero, validaremos y analizaremos el dataset de veh√≠culos aplicando m√©todos de librer√≠as como sklearn. Posteriormente, entrenaremos un modelo de clasificaci√≥n de √°rboles y un modelo de clasificaci√≥n de bosque aleatorio para comparar su efectividad. Adicionalmente, emplearemos las librer√≠as matplotlib y seaborn para visualizar los resultados, y finalmente, generaremos una narrativa que explique los hallazgos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b719c1",
   "metadata": {},
   "source": [
    "## Caracterizaci√≥n del Dataset\n",
    "\n",
    "Se incorpor√° una descripci√≥n (EDA) del conjunto de datos utilizado. Se analiza el dataset proporcionando, se muestra al menos algunas de sus caracter√≠sticas mediante tablas y al menos algunas de ellas en modo gr√°fico (p.ej., histogramas, diagramas de dispersi√≥n, diagramas de cajas y bigotes, etc.)\n",
    "\n",
    "Como primer paso como an√°lista de datos valido el dataset proporcionado, considero las siguientes premisas afirmativas: \n",
    "\n",
    "- Debo identificar los atributos:\n",
    "    - Todas las columnas son categ√≥ricas, ya que no menciona valores recurrentes, progresivos, datos tipo tiempo o algun dato para ser calculado o resumido. \n",
    "- Existen valores desconocidos: \n",
    "    - Luego de correr un script para validar si existe valores nulos, vacios o incompletos se da por afirmativo que no hay valores nulos. \n",
    "        - Flujo alterno en caso que si existiera se tomar√≠a una estrategia como (eliminarlos, imputarlos √≥ proyectarlos con una tecnica probabilistica para sacar una media). Pero aplica para este caso\n",
    "- Se decice la codificaci√≥n de caracter√≠sticas como: \n",
    "    - Se uso scikit-learn ya que trabaja con datos num√©ricos. Para variables ordinales (como vhigh, high, med, low, small, big), \n",
    "    - Se us√≥ LabelEncoder consider√© ser adecuado ya que hay un orden inherente\n",
    "    - Para los atributos Doors y Person a pesar que son valores n√∫mericos los trat√© como categ√≥ricos ya que no representa un valor para ser calculado o valores reales.  \n",
    "    - El atributo class es mi variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ed5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 2: CARACTERIZACI√ìN DEL DATASET\n",
    "print(\"\\nüéØ Paso 2: ------------ Caracterizaci√≥n del Dataset ------------------------ üéØ\")\n",
    "\n",
    "print(f\"\\nüìã N√∫mero total de instancias: {df_encoded.shape[0]}\")\n",
    "print(f\"üìã N√∫mero de atributos de entrada: {df_encoded.shape[1] - 1}\")\n",
    "print(f\"üìã Dataset Veh√≠culos con {df_encoded.shape[0]} filas y {df_encoded.shape[1]} columnas\")\n",
    "\n",
    "# Descripci√≥n mejorada de atributos\n",
    "column_desc = {\n",
    "    \"Buying\": \"Precio de compra del veh√≠culo, clasificado en categor√≠as como vhigh (muy alto), high (alto), med (medio) y low (bajo).\",\n",
    "    \"Maintenance\": \"Costo de mantenimiento del veh√≠culo, con la misma categorizaci√≥n que buying.\",\n",
    "    \"Doors\": \"N√∫mero de puertas del autom√≥vil, expresado en valores num√©ricos como '2', '3', '4', o '5more' (5 o m√°s).\",\n",
    "    \"Person\": \"Capacidad de ocupantes del autom√≥vil, con valores como '2', '4' y 'more' (m√°s de 4).\",\n",
    "    \"lug_boot\": \"Tama√±o del maletero, categorizado como small (peque√±o), med (medio) o big (grande)\",\n",
    "    \"safety\": \"Nivel de seguridad del autom√≥vil, clasificado como low (bajo), med (medio) o high (alto)\"\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Descripci√≥n de atributos de entrada y su tipo:\")\n",
    "for col in features:\n",
    "    print(f\"üîç Atributo: {col}\")\n",
    "    print(f\"   Descripci√≥n: {column_desc[col]}\")\n",
    "    print(f\"   Tipo: categ√≥rico\")\n",
    "    print(f\"   Valores √∫nicos: {sorted(df[col].unique())}\")\n",
    "    print()\n",
    "\n",
    "# Informaci√≥n de la clase objetivo\n",
    "print(\"üìã Informaci√≥n de la clase objetivo:\")\n",
    "print(f\"- Columna de clase: '{target}'\")\n",
    "print(f\"- N√∫mero de clases: {df_encoded[target].nunique()}\")\n",
    "\n",
    "print(\"\\nüìã Distribuci√≥n de las clases:\")\n",
    "class_counts = df[target].value_counts()\n",
    "class_percentages = (class_counts / len(df) * 100).round(2)\n",
    "\n",
    "for clase, count in class_counts.items():\n",
    "    percentage = class_percentages[clase]\n",
    "    print(f\"   {clase}: {count} instancias ({percentage}%)\")\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nüìã Valores nulos por columna:\")\n",
    "null_counts = df_encoded.isnull().sum()\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"‚úÖ No hay valores nulos en el dataset\")\n",
    "else:\n",
    "    print(null_counts)\n",
    "\n",
    "print(\"\\nüìã ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "print(df_encoded.describe(include='all'))\n",
    "\n",
    "\n",
    "# PASO 3: VISUALIZACI√ìN DE DATOS\n",
    "print(\"\\nüéØ Paso 3: ------------ Descripci√≥n Gr√°fica datos originales ------------------------ üéØ\")\n",
    "\n",
    "# Crear figura con subplots mejorados\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('An√°lisis Exploratorio del Dataset de Veh√≠culos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Distribuci√≥n de la clase objetivo\n",
    "sns.countplot(data=df, x=target, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribuci√≥n de Clases de Aceptabilidad')\n",
    "axes[0, 0].set_xlabel('Clase')\n",
    "axes[0, 0].set_ylabel('Conteo')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Distribuciones de caracter√≠sticas\n",
    "characteristics = ['Buying', 'Maintenance', 'Doors', 'safety', 'lug_boot']\n",
    "\n",
    "for i, char in enumerate(characteristics):\n",
    "    row = (i + 1) // 3\n",
    "    col = (i + 1) % 3\n",
    "    sns.countplot(data=df, x=char, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Distribuci√≥n de {char}')\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo que responde a la descripci√≥n anterior (incorpore las lineas de code necesarias. Describa cadas sentencia de c√≥digo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5f871",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ab5e48",
   "metadata": {},
   "source": [
    "En un par de p√°rrafos haga un resumen de los principales hallazagos encontrados:    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5beca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:52:20.156185Z",
     "start_time": "2022-03-14T15:52:20.150187Z"
    }
   },
   "source": [
    "## Preprocesamiento del dataset. Transformaciones previas necesarias para la modelaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 4: PREPARACI√ìN PARA MODELADO\n",
    "print(\"\\nüéØ Paso 4: ------------ Preparaci√≥n del dataset para modelado ------------------------ üéØ\")\n",
    "\n",
    "# Definir caracter√≠sticas y variable objetivo\n",
    "X = df_encoded[features]\n",
    "y = df_encoded[target]\n",
    "\n",
    "# Divisi√≥n del dataset con validaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,      #   Caracter√≠sticas de entrada \n",
    "    y,      #   Variable objetivo\n",
    "    test_size=0.3,      # 30% para prueba\n",
    "    random_state=42,    # Para reproducibilidad\n",
    "    stratify=y          # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(\"üìã Divisi√≥n del dataset completada:\")\n",
    "print(f\"‚úÖ Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"‚úÖ Dimensiones de X_test: {X_test.shape}\")\n",
    "print(f\"‚úÖ Proporci√≥n de entrenamiento: {X_train.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}\")\n",
    "print(f\"‚úÖ Proporci√≥n de prueba: {X_test.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49815fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:56:34.366469Z",
     "start_time": "2022-03-14T15:56:34.358471Z"
    }
   },
   "source": [
    "## Divisi√≥n del dataset en datos de entrenamiento y datos de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a91e96b",
   "metadata": {},
   "source": [
    "## Ajuste de los modelos de clasificaci√≥n propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552bc64",
   "metadata": {},
   "source": [
    "Justifique la selecci√≥n de las dos propuestas de modelaci√≥n seleccionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 5: ENTRENAMIENTO DE MODELOS\n",
    "print(\"\\nüéØ Paso 5: ------------ Entrenamiento de Modelos ------------------------ üéØ\")\n",
    "\n",
    "# Decision Tree con par√°metros optimizados\n",
    "print(\"üå≥ Entrenando Arbol de Decisi√≥n...\")\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42,         # Semilla para reproducibilidad    \n",
    "    max_depth=10,            # Profundidad m√°xima del √°rbol\n",
    "    min_samples_split=5,     # M√≠nimo de muestras para dividir un nodo   \n",
    "    min_samples_leaf=2,      # M√≠nimo de muestras en una hoja\n",
    "    criterion='gini'         # Criterio de divisi√≥n\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "print(\"üå≤ Entrenando Bosque Aleatorio...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,    # N√∫mero de √°rboles en el bosque\n",
    "    random_state=42,     # Semilla para reproducibilidad\n",
    "    max_depth=10,        # Profundidad m√°xima de los √°rboles\n",
    "    min_samples_split=5, # M√≠nimo de muestras para dividir un nodo\n",
    "    min_samples_leaf=2   # M√≠nimo de muestras en una hoja \n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b8461",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n de cada modelo\n",
    "\n",
    "Al menos incluya:\n",
    "\n",
    "+ Instancias clasificadas correctamente\n",
    "+ Instancias clasificadas incorrectamente\n",
    "+ TP Rate\n",
    "+ FP Rate\n",
    "+ Matriz de confusi√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e675b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 6: EVALUACI√ìN DE MODELOS\n",
    "print(\"\\nüéØ Paso 6: ------------ Evaluaci√≥n de Modelos ------------------------ üéØ\")\n",
    "\n",
    "# Funci√≥n para evaluar modelo\n",
    "def evaluate_model(y_true, y_pred, model_name, encoder):\n",
    "    \"\"\"Funci√≥n para evaluar un modelo de clasificaci√≥n\"\"\"\n",
    "    print(f\"\\nüß† ------- Evaluaci√≥n del Modelo {model_name} -------\")\n",
    "    \n",
    "    # efectividad\n",
    "    efectividad = accuracy_score(y_true, y_pred)\n",
    "    print(f\"üéØ Efectividad: {efectividad:.4f} ({efectividad*100:.2f}%)\")\n",
    "\n",
    "    \n",
    "    # Instancias correctas e incorrectas\n",
    "    correct = int(efectividad * len(y_true))\n",
    "    incorrect = len(y_true) - correct\n",
    "    print(f\"‚úÖ Instancias clasificadas correctamente: {correct}\")\n",
    "    print(f\"‚ùå Instancias clasificadas incorrectamente: {incorrect}\")\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\nüìä Matriz de Confusi√≥n:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Reporte de clasificaci√≥n\n",
    "    class_names = encoder.inverse_transform(sorted(np.unique(y_true)))\n",
    "    print(f\"\\nüìà Reporte de Clasificaci√≥n:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    return efectividad, cm, class_names\n",
    "\n",
    "# Evaluar ambos modelos\n",
    "target_encoder = encoders[target]\n",
    "\n",
    "dt_efectividad, dt_cm, class_names = evaluate_model(y_test, y_pred_dt, \"√Årbol decisi√≥n\", target_encoder)\n",
    "rf_efectividad, rf_cm, class_names = evaluate_model(y_test, y_pred_rf, \"Bosque Aleatorio\", target_encoder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad219a0c",
   "metadata": {},
   "source": [
    "Construya un p√°rrafo con los principales hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec0bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf3a7cec",
   "metadata": {},
   "source": [
    "Construya un p√°rrafo con los principales hallazgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df4eb5",
   "metadata": {},
   "source": [
    "## Comparaci√≥n del desempe√±o de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4acd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 7: COMPARACI√ìN Y VISUALIZACI√ìN DE RESULTADOS\n",
    "print(\"\\nüéØ Paso 7: ------------ Comparaci√≥n de Resultados ------------------------ üéØ\")\n",
    "\n",
    "# Comparaci√≥n de accuracies\n",
    "models = ['√Årbol decisi√≥n', 'Bosque Aleatorio']\n",
    "accuracies = [dt_efectividad, rf_efectividad]\n",
    "\n",
    "# Gr√°fico de comparaci√≥n\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Comparaci√≥n de efectividad\n",
    "bars = axes[0].bar(models, accuracies, color=['skyblue', 'red'])\n",
    "axes[0].set_title('Comparaci√≥n de efectividad entre Modelos', fontweight='bold')\n",
    "axes[0].set_ylabel('efectividad')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Matrices de confusi√≥n\n",
    "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "axes[1].set_title('Matriz de Confusi√≥n: √Årbol decisi√≥n', fontweight='bold')\n",
    "axes[1].set_xlabel('Predicho')\n",
    "axes[1].set_ylabel('Real')\n",
    "\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Reds', ax=axes[2],\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "axes[2].set_title('Matriz de Confusi√≥n: Bosque Aleatorio', fontweight='bold')\n",
    "axes[2].set_xlabel('Predicho')\n",
    "axes[2].set_ylabel('Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\nüèÜ RESUMEN FINAL:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üå≥ √Årbol decisi√≥n - efectividad: {dt_efectividad:.4f} ({dt_efectividad*100:.2f}%)\")\n",
    "print(f\"üå≤ Bosque Aleatorio - efectividad: {rf_efectividad:.4f} ({rf_efectividad*100:.2f}%)\")\n",
    "\n",
    "best_model = \"Bosque Aleatorio\" if rf_efectividad > dt_efectividad else \"√Årbol decisi√≥n\"\n",
    "best_efectividad = max(rf_efectividad, dt_efectividad)\n",
    "print(f\"\\nü•á Mejor modelo: {best_model} con {best_efectividad:.4f} de efectividad\")\n",
    "\n",
    "# Importancia de caracter√≠sticas para Bosque Aleatorio\n",
    "if rf_efectividad >= dt_efectividad:\n",
    "    print(f\"\\nüìä Importancia de caracter√≠sticas ({best_model}):\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    for _, row in feature_importance.iterrows():\n",
    "        print(f\"   {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b644946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√≥digo para mostrar la comparaci√≥n de m√©tricas de desempe√±o de las dos propuestas en gr√°fica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d5ab4",
   "metadata": {},
   "source": [
    "El an√°lisis exploratorio del dataset, evidenciado en las gr√°ficas de distribuci√≥n, revel√≥ patrones importantes. La Distribuci√≥n de la Clase de Aceptabilidad de Coches muestra un claro desequilibrio, donde la clase 'unacc' (inaceptable) es la m√°s prevalente con aproximadamente 1200 instancias, seguida por 'acc' (aceptable) con cerca de 400. En contraste, las clases 'vgood' (muy bueno) y 'good' (bueno) son minoritarias, cada una apenas superando las 50 instancias. Por otro lado, las gr√°ficas de Distribuci√≥n de Costo de Compra ('Buying') y Distribuci√≥n de N√∫mero de Puertas ('Doors') indican una distribuci√≥n uniforme en sus respectivas categor√≠as, con aproximadamente 430 instancias por cada nivel de costo o n√∫mero de puertas, lo que sugiere consistencia en estas caracter√≠sticas.\n",
    "\n",
    "En cuanto a los Resultados Obtenidos por los Diferentes Algoritmos, la comparaci√≥n de efectividad entre modelos ilustra un desempe√±o ligeramente superior del √Årbol de Decisi√≥n, con una precisi√≥n aproximada del 0.950, superando al Bosque aleatorio que alcanz√≥ alrededor del 0.941. Se debe reflejar que ambos algoritmos lograron su desempe√±o en clasificar el dataset de veh√≠culos, ambos reflejan porcentajes muy altos, pero el que tuvo mejor resultado fue el de √Årbol de decisi√≥n bien sea por su simplicidad, pero no descarto ninguno de los dos ya que uno de los modelos es mas usado por su poca complejidad en comparaci√≥n con el de Bosque aleatorio agregando que ambos tienen su impacto durante la ejecuci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810fb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:16:57.134093Z",
     "start_time": "2022-03-14T16:16:57.117129Z"
    }
   },
   "source": [
    "## Discusi√≥n de los resultados obtenidos y argumentos sobre c√≥mo se podr√≠an mejorar de dichos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b3044",
   "metadata": {},
   "source": [
    "Como resultado y reflexi√≥n del an√°lisis comparativo de los modelos de clasificaci√≥n, se puedo mencionar varias conclusiones significativas. El √Årbol de Decisi√≥n (Decision Tree Classifier), aunque destaca por su flexibilidad, facilidad de interpretaci√≥n y bajo requerimiento de preparaci√≥n de datos, demostr√≥ un margen ligeramente alto, en comparaci√≥n con Bosque aleatorio (Random Forest Classifier). En contraste, el modelo Random Forest Classifier exhibi√≥ un rendimiento ligeramente inferior. Su naturaleza de ensemble learning lo hace intr√≠nsecamente menos propenso al sobreajuste y considerablemente m√°s robusto en sus operaciones, manejando de forma efectiva datos no lineales. Las m√©tricas obtenidas confirmaron que Random Forest esta un poco por debajo en comparaci√≥n con Decision Tree en precisi√≥n general y crucialmente, en la capacidad de clasificar correctamente clases minoritarias como ‚Äògood‚Äô, se debe resaltar que considero que ninguno es mejor que el otro ambos se complementan para llegar a una conclusi√≥n sobre el estudio principal el dataset de veh√≠culos gracias a estos modelos puedo conformar la siguiente premisas. \n",
    "\n",
    "El an√°lisis del conjunto de datos revel√≥ que la seguridad (Safety) es el factor m√°s cr√≠tico para los usuarios, aportando un 35% de importancia. Los niveles bajos de seguridad son rara vez aceptables. En segundo lugar, la capacidad de personas (Person) tiene un 25% de importancia; los veh√≠culos con capacidad para dos personas son inaceptables, mientras que aquellos con capacidad para \"m√°s\" personas son mejor valorados. El precio de compra (Buying) contribuye con un 20% de importancia, siendo los precios \"muy altos\" fuertemente penalizados y los precios \"bajos\" asociados a clasificaciones positivas. Finalmente, el mantenimiento (Maintenance) representa un 15% de importancia. Otros atributos como el tama√±o del maletero (lug_boot) y el n√∫mero de puertas (Doors) tienen una importancia m√≠nima (3% y 2% respectivamente), lo que sugiere que son menos relevantes para los usuarios en la toma de decisiones\n",
    "\t\n",
    "Se menciona algunas t√©cnicas para mejorar los resultados obtenidos en ambos algoritmos considero lo siguiente: Aumento del Volumen de Datos; Considerar la posibilidad de obtener o generar m√°s datos para el entrenamiento de los modelos, especialmente para las clases minoritarias. T√©cnicas de Balanceo de Clases; Dada la clara identificaci√≥n de un desequilibrio significativo de clases en el dataset (donde algunas clases tienen muchas m√°s instancias que otras, como 'unacc' frente a 'good' o 'vgood'), la aplicaci√≥n de t√©cnicas de balanceo es crucial. En particular, la t√©cnica SMOTE (Synthetic Minority Over-sampling Technique) es altamente recomendable, ya que puede generar instancias sint√©ticas para las clases minoritarias, ayudando a los modelos a aprender sus patrones de manera m√°s efectiva y a mejorar su rendimiento global.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "337.597px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
